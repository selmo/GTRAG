"""
ì„¤ì • í˜ì´ì§€
"""
import streamlit as st
import sys
from pathlib import Path
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))

from ui.utils.api_client import APIClient

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„¤ì • - GTOne RAG",
    page_icon="âš™ï¸",
    layout="wide"
)

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
api_client = APIClient()

# í—¤ë”
st.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
st.markdown("GTOne RAG ì‹œìŠ¤í…œì˜ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")

# ì„¤ì • íƒ­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ¤– AI ì„¤ì •",
    "ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ",
    "ğŸ”§ ê³ ê¸‰ ì„¤ì •",
    "ğŸ’¾ ë°±ì—…/ë³µì›",
    "â„¹ï¸ ì •ë³´"
])

with tab1:
    st.header("ğŸ¤– AI ì„¤ì •")
    
    # LLM ì„¤ì •
    st.subheader("LLM (ì–¸ì–´ ëª¨ë¸) ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ëª¨ë¸ ì„ íƒ
        available_models = [
            "llama3:8b-instruct",
            "llama3:70b-instruct",
            "mistral:7b-instruct",
            "mixtral:8x7b-instruct",
            "phi:2.7b",
            "gemma:7b"
        ]
        
        selected_model = st.selectbox(
            "ì‚¬ìš©í•  ëª¨ë¸",
            available_models,
            index=0,
            help="ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  LLM ëª¨ë¸"
        )
        
        # Temperature
        temperature = st.slider(
            "Temperature (ì°½ì˜ì„±)",
            min_value=0.0,
            max_value=2.0,
            value=0.3,
            step=0.1,
            help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€"
        )
        
        # Max tokens
        max_tokens = st.number_input(
            "ìµœëŒ€ í† í° ìˆ˜",
            min_value=100,
            max_value=4000,
            value=1000,
            step=100,
            help="ìƒì„±í•  ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´"
        )
    
    with col2:
        # Top P
        top_p = st.slider(
            "Top P",
            min_value=0.0,
            max_value=1.0,
            value=0.9,
            step=0.05,
            help="í™•ë¥  ë¶„í¬ ìƒìœ„ P%ë§Œ ê³ ë ¤"
        )
        
        # Frequency penalty
        frequency_penalty = st.slider(
            "Frequency Penalty",
            min_value=0.0,
            max_value=2.0,
            value=0.0,
            step=0.1,
            help="ë°˜ë³µ ë‹¨ì–´ ì‚¬ìš© ì–µì œ"
        )
        
        # System prompt
        system_prompt = st.text_area(
            "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
            value="ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.",
            height=100,
            help="AIì˜ ê¸°ë³¸ í–‰ë™ ì§€ì¹¨"
        )
    
    st.divider()
    
    # RAG ì„¤ì •
    st.subheader("RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
        rag_top_k = st.slider(
            "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜",
            min_value=1,
            max_value=20,
            value=3,
            help="ë‹µë³€ ìƒì„± ì‹œ ì°¸ì¡°í•  ë¬¸ì„œì˜ ê°œìˆ˜"
        )
        
        # ìµœì†Œ ìœ ì‚¬ë„
        min_similarity = st.slider(
            "ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¬¸ì„œë§Œ ì‚¬ìš©"
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
        context_window = st.number_input(
            "ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°",
            min_value=500,
            max_value=8000,
            value=3000,
            step=500,
            help="LLMì— ì œê³µí•  ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´"
        )
    
    with col2:
        # ì²­í¬ ì„¤ì •
        chunk_size = st.number_input(
            "ì²­í¬ í¬ê¸°",
            min_value=100,
            max_value=2000,
            value=500,
            step=100,
            help="ë¬¸ì„œë¥¼ ë¶„í• í•˜ëŠ” ê¸°ë³¸ í¬ê¸°"
        )
        
        chunk_overlap = st.number_input(
            "ì²­í¬ ì¤‘ì²©",
            min_value=0,
            max_value=500,
            value=50,
            step=50,
            help="ì²­í¬ ê°„ ì¤‘ì²©ë˜ëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´"
        )
        
        # ì„ë² ë”© ëª¨ë¸
        embedding_model = st.selectbox(
            "ì„ë² ë”© ëª¨ë¸",
            ["intfloat/multilingual-e5-large-instruct", "intfloat/e5-large-v2"],
            help="ë¬¸ì„œ ë²¡í„°í™”ì— ì‚¬ìš©í•  ëª¨ë¸"
        )
    
    # ì„¤ì • ì €ì¥ ë²„íŠ¼
    if st.button("ğŸ’¾ AI ì„¤ì • ì €ì¥", type="primary"):
        settings = {
            "llm": {
                "model": selected_model,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": top_p,
                "frequency_penalty": frequency_penalty,
                "system_prompt": system_prompt
            },
            "rag": {
                "top_k": rag_top_k,
                "min_similarity": min_similarity,
                "context_window": context_window,
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "embedding_model": embedding_model
            }
        }
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.ai_settings = settings
        st.success("âœ… AI ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

with tab2:
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", type="primary"):
        with st.spinner("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘..."):
            try:
                health_data = api_client.health_check()
                st.session_state.last_health_check = health_data
                st.session_state.health_check_time = datetime.now()
            except Exception as e:
                st.error(f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
    
    # ìƒíƒœ í‘œì‹œ
    if 'last_health_check' in st.session_state:
        health_data = st.session_state.last_health_check
        check_time = st.session_state.health_check_time
        
        st.caption(f"ë§ˆì§€ë§‰ í™•ì¸: {check_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì „ì²´ ìƒíƒœ
        overall_status = health_data.get('status', 'unknown')
        if overall_status == 'healthy':
            st.success("âœ… ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘")
        else:
            st.error("âŒ ì‹œìŠ¤í…œ ë¬¸ì œ ê°ì§€")
        
        # ì„œë¹„ìŠ¤ë³„ ìƒíƒœ
        services = health_data.get('services', {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ—„ï¸ Qdrant")
            qdrant = services.get('qdrant', {})
            if qdrant.get('status') == 'connected':
                st.success("ì—°ê²°ë¨")
                collections = qdrant.get('collections', [])
                st.write(f"ì»¬ë ‰ì…˜: {len(collections)}ê°œ")
                for coll in collections:
                    st.caption(f"â€¢ {coll}")
            else:
                st.error("ì—°ê²° ì‹¤íŒ¨")
        
        with col2:
            st.subheader("ğŸ¤– Ollama")
            ollama = services.get('ollama', {})
            if ollama.get('status') == 'connected':
                st.success("ì—°ê²°ë¨")
                st.write(f"í˜¸ìŠ¤íŠ¸: {ollama.get('host', 'N/A')}")
                models = ollama.get('models', [])
                st.write(f"ëª¨ë¸: {len(models)}ê°œ")
                for model in models[:3]:
                    st.caption(f"â€¢ {model}")
            else:
                st.error("ì—°ê²° ì‹¤íŒ¨")
        
        with col3:
            st.subheader("ğŸ“¨ Celery")
            celery = services.get('celery', {})
            if celery.get('status') == 'connected':
                st.success("ì—°ê²°ë¨")
                st.write("ì›Œì»¤ í™œì„±")
            else:
                st.error("ì—°ê²° ì‹¤íŒ¨")
    
    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    st.divider()
    st.subheader("ğŸ’» ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë”ë¯¸ ë°ì´í„°)
        memory_usage = 45.2
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory_usage}%", "2.1%")
        st.progress(memory_usage / 100)
    
    with col2:
        # CPU ì‚¬ìš©ëŸ‰ (ë”ë¯¸ ë°ì´í„°)
        cpu_usage = 23.5
        st.metric("CPU ì‚¬ìš©ë¥ ", f"{cpu_usage}%", "-5.2%")
        st.progress(cpu_usage / 100)
    
    with col3:
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ (ë”ë¯¸ ë°ì´í„°)
        disk_usage = 67.8
        st.metric("ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ", f"{disk_usage}%", "0.5%")
        st.progress(disk_usage / 100)

with tab3:
    st.header("ğŸ”§ ê³ ê¸‰ ì„¤ì •")
    
    # ë²¡í„° DB ì„¤ì •
    st.subheader("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Qdrant ì„¤ì •
        qdrant_host = st.text_input(
            "Qdrant í˜¸ìŠ¤íŠ¸",
            value="qdrant",
            help="Qdrant ì„œë²„ ì£¼ì†Œ"
        )
        
        qdrant_port = st.number_input(
            "Qdrant í¬íŠ¸",
            value=6333,
            help="Qdrant ì„œë²„ í¬íŠ¸"
        )
        
        collection_name = st.text_input(
            "ì»¬ë ‰ì…˜ ì´ë¦„",
            value="chunks",
            help="ë¬¸ì„œë¥¼ ì €ì¥í•  ì»¬ë ‰ì…˜"
        )
    
    with col2:
        # ì¸ë±ì‹± ì„¤ì •
        vector_size = st.number_input(
            "ë²¡í„° ì°¨ì›",
            value=1024,
            help="ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› ìˆ˜"
        )
        
        distance_metric = st.selectbox(
            "ê±°ë¦¬ ì¸¡ì • ë°©ë²•",
            ["Cosine", "Euclidean", "Dot Product"],
            help="ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚° ë°©ë²•"
        )
        
        index_threshold = st.number_input(
            "ì¸ë±ìŠ¤ ì„ê³„ê°’",
            value=10000,
            help="ì¸ë±ìŠ¤ ìµœì í™” ì„ê³„ê°’"
        )
    
    st.divider()
    
    # OCR ì„¤ì •
    st.subheader("OCR ì„¤ì •")
    
    ocr_engine = st.selectbox(
        "OCR ì—”ì§„",
        ["Tesseract", "Azure Vision API"],
        help="ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‚¬ìš©í•  ì—”ì§„"
    )
    
    if ocr_engine == "Azure Vision API":
        azure_key = st.text_input(
            "Azure API Key",
            type="password",
            help="Azure Cognitive Services API í‚¤"
        )
        
        azure_endpoint = st.text_input(
            "Azure Endpoint",
            placeholder="https://your-resource.cognitiveservices.azure.com/",
            help="Azure ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸"
        )
    
    ocr_languages = st.multiselect(
        "OCR ì–¸ì–´",
        ["kor", "eng", "jpn", "chi_sim", "chi_tra"],
        default=["kor", "eng"],
        help="OCRì—ì„œ ì¸ì‹í•  ì–¸ì–´"
    )
    
    # ê³ ê¸‰ ì„¤ì • ì €ì¥
    if st.button("ğŸ’¾ ê³ ê¸‰ ì„¤ì • ì €ì¥", type="primary"):
        advanced_settings = {
            "vector_db": {
                "host": qdrant_host,
                "port": qdrant_port,
                "collection": collection_name,
                "vector_size": vector_size,
                "distance_metric": distance_metric,
                "index_threshold": index_threshold
            },
            "ocr": {
                "engine": ocr_engine,
                "languages": ocr_languages
            }
        }
        
        if ocr_engine == "Azure Vision API":
            advanced_settings["ocr"]["azure_key"] = azure_key
            advanced_settings["ocr"]["azure_endpoint"] = azure_endpoint
        
        st.session_state.advanced_settings = advanced_settings
        st.success("âœ… ê³ ê¸‰ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

with tab4:
    st.header("ğŸ’¾ ë°±ì—… ë° ë³µì›")
    
    # ë°±ì—…
    st.subheader("ğŸ“¤ ë°±ì—…")
    
    backup_options = st.multiselect(
        "ë°±ì—…í•  í•­ëª© ì„ íƒ",
        ["ì„¤ì •", "ëŒ€í™” ê¸°ë¡", "ê²€ìƒ‰ ê¸°ë¡", "ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡"],
        default=["ì„¤ì •", "ëŒ€í™” ê¸°ë¡"]
    )
    
    if st.button("ğŸ’¾ ë°±ì—… ìƒì„±", type="primary"):
        backup_data = {
            "created_at": datetime.now().isoformat(),
            "version": "1.0.0"
        }
        
        if "ì„¤ì •" in backup_options:
            backup_data["settings"] = {
                "ai": st.session_state.get("ai_settings", {}),
                "advanced": st.session_state.get("advanced_settings", {})
            }
        
        if "ëŒ€í™” ê¸°ë¡" in backup_options:
            backup_data["messages"] = st.session_state.get("messages", [])
        
        if "ê²€ìƒ‰ ê¸°ë¡" in backup_options:
            backup_data["search_history"] = st.session_state.get("search_history", [])
        
        if "ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡" in backup_options:
            backup_data["uploaded_files"] = st.session_state.get("uploaded_files", [])
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ“¥ ë°±ì—… ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(backup_data, ensure_ascii=False, indent=2),
            file_name=f"gtone_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    st.divider()
    
    # ë³µì›
    st.subheader("ğŸ“¥ ë³µì›")
    
    uploaded_backup = st.file_uploader(
        "ë°±ì—… íŒŒì¼ ì„ íƒ",
        type=["json"],
        help="ì´ì „ì— ìƒì„±í•œ ë°±ì—… íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_backup is not None:
        try:
            backup_data = json.loads(uploaded_backup.read())
            
            st.info(f"ë°±ì—… ìƒì„± ì‹œê°„: {backup_data.get('created_at', 'N/A')}")
            
            # ë³µì› ê°€ëŠ¥í•œ í•­ëª© í‘œì‹œ
            available_items = []
            if "settings" in backup_data:
                available_items.append("ì„¤ì •")
            if "messages" in backup_data:
                available_items.append(f"ëŒ€í™” ê¸°ë¡ ({len(backup_data['messages'])}ê°œ)")
            if "search_history" in backup_data:
                available_items.append(f"ê²€ìƒ‰ ê¸°ë¡ ({len(backup_data['search_history'])}ê°œ)")
            if "uploaded_files" in backup_data:
                available_items.append(f"ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡ ({len(backup_data['uploaded_files'])}ê°œ)")
            
            restore_items = st.multiselect(
                "ë³µì›í•  í•­ëª© ì„ íƒ",
                available_items,
                default=available_items
            )
            
            if st.button("â™»ï¸ ë³µì› ì‹¤í–‰", type="secondary"):
                # ë³µì› ì‹¤í–‰
                if "ì„¤ì •" in restore_items and "settings" in backup_data:
                    st.session_state.ai_settings = backup_data["settings"].get("ai", {})
                    st.session_state.advanced_settings = backup_data["settings"].get("advanced", {})
                
                if any("ëŒ€í™” ê¸°ë¡" in item for item in restore_items) and "messages" in backup_data:
                    st.session_state.messages = backup_data["messages"]
                
                if any("ê²€ìƒ‰ ê¸°ë¡" in item for item in restore_items) and "search_history" in backup_data:
                    st.session_state.search_history = backup_data["search_history"]
                
                if any("ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡" in item for item in restore_items) and "uploaded_files" in backup_data:
                    st.session_state.uploaded_files = backup_data["uploaded_files"]
                
                st.success("âœ… ë³µì›ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.experimental_rerun()
                
        except Exception as e:
            st.error(f"ë°±ì—… íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")

with tab5:
    st.header("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    st.subheader("ì‹œìŠ¤í…œ ì •ë³´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ë²„ì „**")
        st.code("GTOne RAG System v1.0.0")
        
        st.write("**Python ë²„ì „**")
        st.code("Python 3.11+")
        
        st.write("**í”„ë ˆì„ì›Œí¬**")
        st.code("FastAPI + Streamlit")
    
    with col2:
        st.write("**ë²¡í„° DB**")
        st.code("Qdrant v1.9.3")
        
        st.write("**ì„ë² ë”© ëª¨ë¸**")
        st.code("E5-large-instruct")
        
        st.write("**LLM ì„œë²„**")
        st.code("Ollama (External)")
    
    st.divider()
    
    # ë¼ì´ì„ ìŠ¤
    st.subheader("ë¼ì´ì„ ìŠ¤")
    st.text("""
    MIT License
    
    Copyright (c) 2024 GTOne
    
    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction...
    """)
    
    st.divider()
    
    # ë„ì›€ë§
    st.subheader("ë„ì›€ë§ ë° ì§€ì›")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("ğŸ“š [ì‚¬ìš©ì ê°€ì´ë“œ](https://github.com/selmo/gtrag/wiki)")
    
    with col2:
        st.markdown("ğŸ› [ë²„ê·¸ ë¦¬í¬íŠ¸](https://github.com/selmo/gtrag/issues)")
    
    with col3:
        st.markdown("ğŸ’¬ [ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/selmo)")
    
    # ì—°ë½ì²˜
    st.divider()
    st.caption("ë¬¸ì˜: support@gtone.com | ê¸°ìˆ  ì§€ì›: tech@gtone.com")

# í‘¸í„°
st.divider()
st.caption("ğŸ’¡ ì„¤ì • ë³€ê²½ í›„ì—ëŠ” ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìƒˆë¡œê³ ì¹¨ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
