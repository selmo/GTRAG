"""
ê°œì„ ëœ ë¬¸ì„œ íŒŒì„œ - í•œêµ­ì–´ PDF ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
"""
import os
import tempfile
from uuid import uuid4
from typing import List, Dict, Union
import logging
import re
from ftfy import fix_text


logger = logging.getLogger(__name__)

def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì¸ì½”ë”© ë¬¸ì œ í•´ê²°"""
    if not text:
        return ""

    # ë°”ì´íŠ¸ ë¬¸ìì—´ì´ë©´ UTF-8ë¡œ ë””ì½”ë“œ
    if isinstance(text, bytes):
        try:
            text = text.decode('utf-8')
        except UnicodeDecodeError:
            try:
                text = text.decode('cp949')  # í•œêµ­ì–´ ìœˆë„ìš° ì¸ì½”ë”©
            except UnicodeDecodeError:
                text = text.decode('utf-8', errors='replace')

    # â‘  ftfy ë¡œ í•œ ë²ˆ ë³µêµ¬
    text = fix_text(text)

    # â‘¡ ì œì–´ ë¬¸ì ì œê±° (ì¤„ë°”ê¿ˆ, íƒ­ ì œì™¸)
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)

    # ì´ìƒí•œ ë¬¸ìë“¤ ì •ë¦¬ (PDFì—ì„œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œë“¤)
    text = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£ä¸€-é¾¯\u3040-\u309F\u30A0-\u30FF.,!?;:()\[\]{}\'\"%-]', ' ', text)

    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)

    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()

    return text


GARBLED_THRESHOLD = 0.30          # ìœ íš¨ ë¬¸ì ë¹„ìœ¨ 30 %

def is_garbled(text: str) -> bool:
    """ê°€ë… ê°€ëŠ¥í•œ ë¬¸ì ë¹„ìœ¨ì´ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ True"""
    if not text:
        return True
    good = len(re.findall(r'[ê°€-í£a-zA-Z0-9]', text))
    return good / len(text) < GARBLED_THRESHOLD


def parse_pdf_with_pdfplumber(file_path: str, lang_hint="auto") -> List[Dict]:
    """pdfplumberë¥¼ ì‚¬ìš©í•œ PDF íŒŒì‹± (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)"""
    try:
        import pdfplumber

        # íŒŒì¼ ì ‘ê·¼ì„± ì‚¬ì „ í™•ì¸
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        if not os.access(file_path, os.R_OK):
            raise PermissionError(f"íŒŒì¼ ì½ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")

        logger.info(f"pdfplumberë¡œ PDF íŒŒì‹± ì‹œì‘: {os.path.basename(file_path)}")
        chunks = []

        # pdfplumber ì„¤ì • - CJK í°íŠ¸ë¥¼ ìœ„í•œ íŠ¹ë³„ ì²˜ë¦¬
        pdf_config = {
            # 'dedupe_chars': True,
        #     'ignore_blank_chars': True,
        #     'use_text_flow': True,
        }

        with pdfplumber.open(file_path, **pdf_config) as pdf:
            total_pages = len(pdf.pages)
            logger.info(f"PDF ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")

            for page_num, page in enumerate(pdf.pages):
                try:
                    text = None

                    # ë°©ë²• 1: ê¸°ë³¸ ì¶”ì¶œ
                    try:
                        text = page.extract_text()
                        if text and len(text.strip()) > 10:
                            logger.debug(f"í˜ì´ì§€ {page_num + 1}: ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                    except Exception as e:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1} ê¸°ë³¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                    # ë°©ë²• 2: ë” ê´€ëŒ€í•œ ì„¤ì •ìœ¼ë¡œ ì¶”ì¶œ
                    if not text or len(text.strip()) < 10:
                        try:
                            text = page.extract_text(
                                x_tolerance=3,
                                y_tolerance=3,
                                layout=True,
                                x_density=7.25,
                                y_density=7.25
                            )
                            if text and len(text.strip()) > 10:
                                logger.debug(f"í˜ì´ì§€ {page_num + 1}: ê´€ëŒ€í•œ ì„¤ì •ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                        except Exception as e:
                            logger.warning(f"í˜ì´ì§€ {page_num + 1} ê´€ëŒ€í•œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                    # ë°©ë²• 3: ë¬¸ì ê¸°ë°˜ ì¶”ì¶œ
                    if not text or len(text.strip()) < 10:
                        try:
                            chars = page.chars
                            if chars:
                                sorted_chars = sorted(chars, key=lambda x: (x['top'], x['x0']))
                                text = ''.join(char['text'] for char in sorted_chars)
                                if text and len(text.strip()) > 10:
                                    logger.debug(f"í˜ì´ì§€ {page_num + 1}: ë¬¸ì ê¸°ë°˜ ì¶”ì¶œ ì„±ê³µ")
                        except Exception as e:
                            logger.warning(f"í˜ì´ì§€ {page_num + 1} ë¬¸ì ê¸°ë°˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                    if not text or len(text.strip()) < 10:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1}: ëª¨ë“  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±")
                        continue

                    # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê²€ì¦
                    cleaned_text = clean_text(text)

                    if cleaned_text and len(cleaned_text.strip()) > 10:
                        if not is_garbled(cleaned_text):
                            chunks.extend(chunk_text(
                                cleaned_text,
                                source=os.path.basename(file_path),
                                page=page_num + 1,
                                doc_type="pdf",
                                lang=lang_hint
                            ))
                            logger.debug(f"í˜ì´ì§€ {page_num + 1}: ì²­í¬ ìƒì„± ì™„ë£Œ")
                        else:
                            logger.warning(f"í˜ì´ì§€ {page_num + 1}: ê¹¨ì§„ í…ìŠ¤íŠ¸ ê°ì§€ë¨")
                    else:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1}: ì •ë¦¬ëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ")

                except Exception as e:
                    logger.error(f"í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        logger.info(f"pdfplumber íŒŒì‹± ì™„ë£Œ: {len(chunks)} ì²­í¬ ìƒì„±")

        if not chunks:
            raise ValueError("ì¶”ì¶œëœ ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")

        return chunks

    except ImportError:
        logger.error("pdfplumber ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        raise ImportError("pdfplumber ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜: {e}")
        raise
    except PermissionError as e:
        logger.error(f"ê¶Œí•œ ì˜¤ë¥˜: {e}")
        raise
    except Exception as e:
        logger.error(f"pdfplumber PDF íŒŒì‹± ì‹¤íŒ¨: {type(e).__name__}: {e}")

        # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ìœ í˜•ë³„ ë©”ì‹œì§€
        if "corrupt" in str(e).lower() or "damaged" in str(e).lower():
            raise ValueError("ì†ìƒëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
        elif "password" in str(e).lower() or "encrypted" in str(e).lower():
            raise ValueError("ì•”í˜¸í™”ëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
        elif "memory" in str(e).lower():
            raise ValueError("PDF íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
        else:
            raise ValueError(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def parse_pdf_with_pymupdf(file_path: str, lang_hint="auto") -> List[Dict]:
    """PyMuPDFë¥¼ ì‚¬ìš©í•œ PDF íŒŒì‹± (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)"""
    try:
        import fitz  # PyMuPDF

        # íŒŒì¼ ì ‘ê·¼ì„± ì‚¬ì „ í™•ì¸
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        logger.info(f"PyMuPDFë¡œ PDF íŒŒì‹± ì‹œì‘: {os.path.basename(file_path)}")
        chunks = []

        try:
            doc = fitz.open(file_path)
        except Exception as e:
            if "password" in str(e).lower():
                raise ValueError("ì•”í˜¸í™”ëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
            elif "corrupt" in str(e).lower():
                raise ValueError("ì†ìƒëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
            else:
                raise ValueError(f"PDF íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

        total_pages = len(doc)
        logger.info(f"PDF ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")

        for page_num in range(total_pages):
            try:
                page = doc.load_page(page_num)
                text = None

                # ë°©ë²• 1: ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                try:
                    text = page.get_text(
                        "text",
                        flags=fitz.TEXT_PRESERVE_WHITESPACE | fitz.TEXT_PRESERVE_SPANS
                    )
                    if text and len(text.strip()) > 10:
                        logger.debug(f"í˜ì´ì§€ {page_num + 1}: ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                except Exception as e:
                    logger.warning(f"í˜ì´ì§€ {page_num + 1} ê¸°ë³¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                # ë°©ë²• 2: dict í˜•íƒœë¡œ ì¶”ì¶œ
                if not text or len(text.strip()) < 10:
                    try:
                        text_dict = page.get_text("dict")
                        extracted_text = []

                        for block in text_dict["blocks"]:
                            if "lines" in block:
                                for line in block["lines"]:
                                    for span in line["spans"]:
                                        if span["text"].strip():
                                            extracted_text.append(span["text"])

                        text = " ".join(extracted_text)
                        if text and len(text.strip()) > 10:
                            logger.debug(f"í˜ì´ì§€ {page_num + 1}: dict ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                    except Exception as e:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1} dict ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                if not text or len(text.strip()) < 10:
                    logger.warning(f"í˜ì´ì§€ {page_num + 1}: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
                    continue

                # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê²€ì¦
                cleaned_text = clean_text(text)

                if cleaned_text and len(cleaned_text.strip()) > 10:
                    if not is_garbled(cleaned_text):
                        chunks.extend(chunk_text(
                            cleaned_text,
                            source=os.path.basename(file_path),
                            page=page_num + 1,
                            doc_type="pdf",
                            lang=lang_hint
                        ))
                        logger.debug(f"í˜ì´ì§€ {page_num + 1}: ì²­í¬ ìƒì„± ì™„ë£Œ")
                    else:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1}: ê¹¨ì§„ í…ìŠ¤íŠ¸ ê°ì§€ë¨")

            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        doc.close()
        logger.info(f"PyMuPDF íŒŒì‹± ì™„ë£Œ: {len(chunks)} ì²­í¬ ìƒì„±")

        if not chunks:
            raise ValueError("ì¶”ì¶œëœ ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")

        return chunks

    except ImportError:
        logger.error("PyMuPDF(fitz) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        raise ImportError("PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜: {e}")
        raise
    except Exception as e:
        logger.error(f"PyMuPDF PDF íŒŒì‹± ì‹¤íŒ¨: {type(e).__name__}: {e}")
        raise ValueError(f"PyMuPDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


def parse_pdf_with_pypdf(file_path: str, lang_hint="auto") -> List[Dict]:
    """PyPDFë¥¼ ì‚¬ìš©í•œ PDF íŒŒì‹± (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)"""
    try:
        from pypdf import PdfReader

        # íŒŒì¼ ì ‘ê·¼ì„± ì‚¬ì „ í™•ì¸
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        logger.info(f"PyPDFë¡œ PDF íŒŒì‹± ì‹œì‘: {os.path.basename(file_path)}")
        chunks = []

        # ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì‹œë„
        reader = None
        for encoding in ['utf-8', 'latin-1', 'cp1252']:
            try:
                reader = PdfReader(file_path)
                logger.debug(f"PyPDF íŒŒì¼ ì½ê¸° ì„±ê³µ (ì¸ì½”ë”©: {encoding})")
                break
            except Exception as e:
                logger.warning(f"ì¸ì½”ë”© {encoding}ìœ¼ë¡œ ì½ê¸° ì‹¤íŒ¨: {e}")
                continue

        if reader is None:
            raise ValueError("ëª¨ë“  ì¸ì½”ë”©ìœ¼ë¡œ PDF ì½ê¸° ì‹¤íŒ¨")

        total_pages = len(reader.pages)
        logger.info(f"PDF ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")

        for page_num, page in enumerate(reader.pages):
            try:
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = page.extract_text()

                if not text or len(text.strip()) < 10:
                    logger.warning(f"í˜ì´ì§€ {page_num + 1}: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
                    continue

                # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê²€ì¦
                cleaned_text = clean_text(text)

                if cleaned_text and len(cleaned_text.strip()) > 10:
                    if not is_garbled(cleaned_text):
                        chunks.extend(chunk_text(
                            cleaned_text,
                            source=os.path.basename(file_path),
                            page=page_num + 1,
                            doc_type="pdf",
                            lang=lang_hint
                        ))
                        logger.debug(f"í˜ì´ì§€ {page_num + 1}: ì²­í¬ ìƒì„± ì™„ë£Œ")
                    else:
                        logger.warning(f"í˜ì´ì§€ {page_num + 1}: ê¹¨ì§„ í…ìŠ¤íŠ¸ ê°ì§€ë¨")

            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page_num + 1} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                continue

        logger.info(f"PyPDF íŒŒì‹± ì™„ë£Œ: {len(chunks)} ì²­í¬ ìƒì„±")

        if not chunks:
            raise ValueError("ì¶”ì¶œëœ ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")

        return chunks

    except ImportError:
        logger.error("PyPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        raise ImportError("PyPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜: {e}")
        raise
    except Exception as e:
        logger.error(f"PyPDF íŒŒì‹± ì‹¤íŒ¨: {type(e).__name__}: {e}")

        # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ìœ í˜•ë³„ ë©”ì‹œì§€
        if "password" in str(e).lower() or "encrypted" in str(e).lower():
            raise ValueError("ì•”í˜¸í™”ëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
        elif "corrupt" in str(e).lower() or "damaged" in str(e).lower():
            raise ValueError("ì†ìƒëœ PDF íŒŒì¼ì…ë‹ˆë‹¤")
        else:
            raise ValueError(f"PyPDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


def parse_text_file(file_path: str, lang_hint="auto") -> List[Dict]:
    """í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹± (ì¸ì½”ë”© ê°œì„ )"""
    try:
        # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin-1', 'utf-16', 'ascii']
        content = None
        used_encoding = None

        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                    used_encoding = encoding
                break
            except (UnicodeDecodeError, UnicodeError):
                continue

        if content is None:
            # ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ ê°•ì œ ë³€í™˜
            with open(file_path, 'rb') as f:
                raw_content = f.read()
                # chardetë¡œ ì¸ì½”ë”© ê°ì§€ ì‹œë„
                try:
                    import chardet
                    detected = chardet.detect(raw_content)
                    if detected and detected['encoding']:
                        content = raw_content.decode(detected['encoding'], errors='replace')
                        used_encoding = detected['encoding']
                    else:
                        content = raw_content.decode('utf-8', errors='replace')
                        used_encoding = 'utf-8 (forced)'
                except ImportError:
                    content = raw_content.decode('utf-8', errors='replace')
                    used_encoding = 'utf-8 (forced)'

        # í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_content = clean_text(content)

        logger.info(f"Text file parsed with encoding: {used_encoding}")

        return chunk_text(
            cleaned_content,
            source=os.path.basename(file_path),
            doc_type="text",
            lang=lang_hint
        )

    except Exception as e:
        logger.error(f"Text file parsing failed: {e}")
        return parse_as_fallback(file_path, f"í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


def parse_docx(file_path: str, lang_hint="auto") -> List[Dict]:
    """Word ë¬¸ì„œ íŒŒì‹± (ì¸ì½”ë”© ê°œì„ )"""
    try:
        from docx import Document

        doc = Document(file_path)
        paragraphs = []

        # ë¬¸ë‹¨ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for para in doc.paragraphs:
            if para.text.strip():
                cleaned_text = clean_text(para.text.strip())
                if cleaned_text:
                    paragraphs.append(cleaned_text)

        # í‘œ ë‚´ìš© ì¶”ì¶œ
        for table in doc.tables:
            for row in table.rows:
                row_texts = []
                for cell in row.cells:
                    cell_text = clean_text(cell.text.strip())
                    if cell_text:
                        row_texts.append(cell_text)

                if row_texts:
                    row_text = " | ".join(row_texts)
                    paragraphs.append(row_text)

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n\n".join(paragraphs)

        return chunk_text(
            full_text,
            source=os.path.basename(file_path),
            doc_type="docx",
            lang=lang_hint
        )

    except ImportError:
        logger.error("python-docx not available")
        return parse_as_fallback(file_path, "Word ë¬¸ì„œ (python-docx ë¯¸ì„¤ì¹˜)")
    except Exception as e:
        logger.error(f"DOCX parsing failed: {e}")
        return parse_as_fallback(file_path, f"Word ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")


def parse_as_fallback(file_path: str, description: str) -> List[Dict]:
    """ê°œì„ ëœ í´ë°± ì²˜ë¦¬ - ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ì™€ ë¬¸ì œ í•´ê²° íŒíŠ¸"""

    filename = os.path.basename(file_path)
    file_ext = os.path.splitext(file_path)[1].lower()

    # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
    file_info = {"size": 0, "readable": False, "exists": False}
    try:
        if os.path.exists(file_path):
            file_info["exists"] = True
            file_info["size"] = os.path.getsize(file_path)
            file_info["readable"] = os.access(file_path, os.R_OK)
    except:
        pass

    # ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
    if "ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ" in description:
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì œí•œì‚¬í•­**: PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- ê´€ë¦¬ìì—ê²Œ PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¥¼ ìš”ì²­í•˜ì„¸ìš”
- íŒŒì¼ì„ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ë³´ì„¸ìš”
- Word ë¬¸ì„œ(.docx) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì‹œë„í•´ ë³´ì„¸ìš”

ğŸ“‹ **íŒŒì¼ ì •ë³´**: {file_info['size'] / 1024:.1f}KB
        """.strip()

    elif "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in description:
        user_message = f"""
âŒ **íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜**: {filename}

íŒŒì¼ì´ ì œëŒ€ë¡œ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- íŒŒì¼ì„ ë‹¤ì‹œ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”
- íŒŒì¼ ì´ë¦„ì— íŠ¹ìˆ˜ë¬¸ìê°€ ìˆë‹¤ë©´ ì œê±°í•˜ì—¬ ì‹œë„í•˜ì„¸ìš”
- ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”
        """.strip()

    elif "íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤" in description:
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì œí•œì‚¬í•­**: íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì„œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- íŒŒì¼ì„ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”
- PDFì˜ ê²½ìš° í˜ì´ì§€ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ì‹œë„í•˜ì„¸ìš”
- ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ ë‚®ì¶°ì„œ ë‹¤ì‹œ ì €ì¥í•˜ì„¸ìš”

ğŸ“‹ **íŒŒì¼ ì •ë³´**: {file_info['size'] / 1024 / 1024:.1f}MB (ì œí•œ: 100MB)
        """.strip()

    elif "ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤" in description:
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì œí•œì‚¬í•­**: íŒŒì¼ì— ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ **í™•ì¸ ì‚¬í•­**:
- íŒŒì¼ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
- íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒŒì¼ì„ ì‹œë„í•´ ë³´ì„¸ìš”
        """.strip()

    elif "ê°€ë… ë¶ˆê°€ëŠ¥í•œ í…ìŠ¤íŠ¸" in description:
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì œí•œì‚¬í•­**: PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆì§€ë§Œ ì½ì„ ìˆ˜ ì—†ëŠ” í˜•íƒœì…ë‹ˆë‹¤.

ğŸ’¡ **ê°€ëŠ¥í•œ ì›ì¸**:
- ìŠ¤ìº”ëœ ì´ë¯¸ì§€ ê¸°ë°˜ PDF (OCR í•„ìš”)
- íŠ¹ìˆ˜ í°íŠ¸ë‚˜ ì¸ì½”ë”© ë¬¸ì œ
- ì†ìƒëœ PDF íŒŒì¼

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- PDFë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹¤ì‹œ ì €ì¥í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”
- Word ë¬¸ì„œë¡œ ë³€í™˜í•˜ì—¬ ì‹œë„í•˜ì„¸ìš”
- ë‹¤ë¥¸ PDF ë·°ì–´ì—ì„œ "ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥"ì„ ì‹œë„í•˜ì„¸ìš”

ğŸ“‹ **íŒŒì¼ ì •ë³´**: {file_info['size'] / 1024:.1f}KB
        """.strip()

    elif "ëª¨ë“  íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¤íŒ¨" in description:
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì œí•œì‚¬í•­**: ì—¬ëŸ¬ PDF ì²˜ë¦¬ ë°©ë²•ì„ ì‹œë„í–ˆì§€ë§Œ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ **ê°€ëŠ¥í•œ ì›ì¸**:
- ì•”í˜¸í™”ëœ PDF íŒŒì¼
- ì†ìƒë˜ê±°ë‚˜ íŠ¹ìˆ˜í•œ í˜•ì‹ì˜ PDF
- ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- PDF ì•”í˜¸ë¥¼ í•´ì œí•œ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì„¸ìš”
- ë‹¤ë¥¸ PDF ë·°ì–´ì—ì„œ "ì¸ì‡„ â†’ PDFë¡œ ì €ì¥"ì„ ì‹œë„í•˜ì„¸ìš”
- íŒŒì¼ì„ Wordë‚˜ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”
- ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”

ğŸ”§ **ê¸°ìˆ  ì •ë³´**: {description.split(':', 1)[-1] if ':' in description else description}

ğŸ“‹ **íŒŒì¼ ì •ë³´**: {file_info['size'] / 1024:.1f}KB
        """.strip()

    else:
        # ê¸°íƒ€ ì˜¤ë¥˜ì˜ ê²½ìš°
        user_message = f"""
ğŸ“„ **{filename}** íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.

âš ï¸ **ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ**: {description}

ğŸ’¡ **í•´ê²° ë°©ë²•**:
- íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ê³  ì§€ì›ë˜ëŠ” í˜•ì‹(.pdf, .docx, .txt)ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”
- íŒŒì¼ ì´ë¦„ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒŒì¼ë¡œ ì‹œë„í•´ ë³´ì„¸ìš”
- ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”

ğŸ“‹ **íŒŒì¼ ì •ë³´**: {file_ext.upper()[1:] if file_ext else 'ì•Œ ìˆ˜ ì—†ìŒ'} í˜•ì‹, {file_info['size'] / 1024:.1f}KB
        """.strip()

    return [{
        "chunk_id": str(uuid4()),
        "content": user_message,
        "meta": {
            "source": filename,
            "type": "fallback",
            "error_type": "parsing_failed",
            "original_error": description,
            "file_size": file_info["size"],
            "file_ext": file_ext,
            "suggestions": [
                "íŒŒì¼ í˜•ì‹ ë³€í™˜ ì‹œë„",
                "íŒŒì¼ í¬ê¸° ì¶•ì†Œ",
                "ê´€ë¦¬ì ë¬¸ì˜"
            ]
        }
    }]


def chunk_text(text: str, source: str, doc_type: str = "unknown",
               page: int = None, lang: str = "auto", chunk_size: int = 500,
               chunk_overlap: int = 50) -> List[Dict]:
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (í•œêµ­ì–´ ìµœì í™”)"""
    if not text or not text.strip():
        return []

    # í…ìŠ¤íŠ¸ ì •ë¦¬
    cleaned_text = clean_text(text)

    if not cleaned_text:
        return []

    chunks = []

    if len(cleaned_text) <= chunk_size:
        chunks.append({
            "chunk_id": str(uuid4()),
            "content": cleaned_text,
            "meta": {
                "source": source,
                "type": doc_type,
                "lang": lang,
                **({"page": page} if page else {}),
                "chunk_index": 0,
                "total_chunks": 1
            }
        })
    else:
        start = 0
        chunk_index = 0

        while start < len(cleaned_text):
            end = start + chunk_size

            # í•œêµ­ì–´ ë° ì˜ì–´ë¥¼ ê³ ë ¤í•œ ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end < len(cleaned_text):
                # í•œêµ­ì–´ ë¬¸ì¥ ë ë¬¸ìë“¤
                korean_endings = ['ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ì£ ', 'ë„¤', 'ë¼', 'ê¹Œ', 'ì•¼']

                # ì°¾ì„ ë²”ìœ„ ì„¤ì •
                search_start = max(start + chunk_size // 2, end - 100)

                # ìš°ì„ ìˆœìœ„ 1: ë¬¸ì¥ ë¶€í˜¸
                for i in range(end, search_start, -1):
                    if cleaned_text[i] in ['.', '!', '?', 'ã€‚', '!', '?', '\n']:
                        end = i + 1
                        break
                else:
                    # ìš°ì„ ìˆœìœ„ 2: í•œêµ­ì–´ ë¬¸ì¥ ë
                    for i in range(end, search_start, -1):
                        if i > 0 and cleaned_text[i-1:i+1] in ['ë‹¤.', 'ìš”.', 'ë‹¤!', 'ìš”!', 'ë‹¤?', 'ìš”?']:
                            end = i + 1
                            break
                        elif cleaned_text[i] in korean_endings and i < len(cleaned_text) - 1 and cleaned_text[i+1] in [' ', '\n', '\t']:
                            end = i + 1
                            break
                    else:
                        # ìš°ì„ ìˆœìœ„ 3: ê³µë°±
                        for i in range(end, search_start, -1):
                            if cleaned_text[i] in [' ', '\n', '\t']:
                                end = i + 1
                                break

            chunk_content = cleaned_text[start:end].strip()

            if chunk_content and len(chunk_content) > 10:
                chunks.append({
                    "chunk_id": str(uuid4()),
                    "content": chunk_content,
                    "meta": {
                        "source": source,
                        "type": doc_type,
                        "lang": lang,
                        **({"page": page} if page else {}),
                        "chunk_index": chunk_index,
                        "start_pos": start,
                        "end_pos": end
                    }
                })
                chunk_index += 1

            start = max(start + chunk_size - chunk_overlap, end)

    # ì´ ì²­í¬ ìˆ˜ ì—…ë°ì´íŠ¸
    for chunk in chunks:
        chunk["meta"]["total_chunks"] = len(chunks)

    return chunks


def parse_pdf(file_input: Union[str, bytes], lang_hint: str = "auto") -> List[Dict]:
    """ë©”ì¸ íŒŒì‹± í•¨ìˆ˜ - ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¨ê³„ì  ì‹œë„"""
    # ë°”ì´íŠ¸ ë°ì´í„°ì¸ ê²½ìš° ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    if isinstance(file_input, bytes):
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(file_input)
            temp_path = tmp_file.name

        try:
            return parse_file_by_extension(temp_path, lang_hint)
        finally:
            try:
                os.unlink(temp_path)
            except:
                pass

    elif isinstance(file_input, (str, os.PathLike)):
        return parse_file_by_extension(str(file_input), lang_hint)

    else:
        raise ValueError(f"Unsupported input type: {type(file_input)}")


def parse_file_by_extension(file_path: str, lang_hint: str = "auto") -> List[Dict]:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ íŒŒì‹± - ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬"""

    # 1ë‹¨ê³„: íŒŒì¼ ì¡´ì¬ ë° ì ‘ê·¼ ê¶Œí•œ ê²€ì¦
    if not os.path.exists(file_path):
        logger.error(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        return parse_as_fallback(file_path, "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    if not os.access(file_path, os.R_OK):
        logger.error(f"íŒŒì¼ ì½ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return parse_as_fallback(file_path, "íŒŒì¼ ì½ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")

    try:
        file_size = os.path.getsize(file_path)
        if file_size == 0:
            logger.warning(f"ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {file_path}")
            return parse_as_fallback(file_path, "ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")

        if file_size > 100 * 1024 * 1024:  # 100MB ì œí•œ
            logger.warning(f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ ({file_size / 1024 / 1024:.1f}MB): {file_path}")
            return parse_as_fallback(file_path, f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ ({file_size / 1024 / 1024:.1f}MB)")

    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
        return parse_as_fallback(file_path, f"íŒŒì¼ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

    file_ext = os.path.splitext(file_path)[1].lower()
    logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {os.path.basename(file_path)} ({file_ext}, {file_size / 1024:.1f}KB)")

    if file_ext == '.pdf':
        # PDF íŒŒì‹± - ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„ (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)
        successful_chunks = []
        library_errors = []

        # 1ë‹¨ê³„: pdfplumber ë¨¼ì € ì‹œë„
        try:
            logger.info("pdfplumberë¡œ PDF íŒŒì‹± ì‹œë„ ì¤‘...")
            result = parse_pdf_with_pdfplumber(file_path, lang_hint)
            if result and not all(chunk['meta'].get('type') == 'fallback' for chunk in result):
                content_check = " ".join(c['content'] for c in result if c['content'])
                if not is_garbled(content_check) and len(content_check.strip()) > 20:
                    logger.info(f"pdfplumber ì„±ê³µ: {len(result)} ì²­í¬ ìƒì„±")
                    return result
                else:
                    library_errors.append("pdfplumber: ê°€ë… ë¶ˆê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            else:
                library_errors.append("pdfplumber: ìœ íš¨í•œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨")
        except ImportError:
            library_errors.append("pdfplumber: ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            library_errors.append(f"pdfplumber: {str(e)}")
            logger.warning(f"pdfplumber ì‹¤íŒ¨: {e}")

        # 2ë‹¨ê³„: PyMuPDF ì‹œë„
        try:
            logger.info("PyMuPDFë¡œ PDF íŒŒì‹± ì‹œë„ ì¤‘...")
            result = parse_pdf_with_pymupdf(file_path, lang_hint)
            if result and not all(chunk['meta'].get('type') == 'fallback' for chunk in result):
                content_check = " ".join(c['content'] for c in result if c['content'])
                if not is_garbled(content_check) and len(content_check.strip()) > 20:
                    logger.info(f"PyMuPDF ì„±ê³µ: {len(result)} ì²­í¬ ìƒì„±")
                    return result
                else:
                    library_errors.append("PyMuPDF: ê°€ë… ë¶ˆê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            else:
                library_errors.append("PyMuPDF: ìœ íš¨í•œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨")
        except ImportError:
            library_errors.append("PyMuPDF: ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            library_errors.append(f"PyMuPDF: {str(e)}")
            logger.warning(f"PyMuPDF ì‹¤íŒ¨: {e}")

        # 3ë‹¨ê³„: PyPDF ì‹œë„
        try:
            logger.info("PyPDFë¡œ PDF íŒŒì‹± ì‹œë„ ì¤‘...")
            result = parse_pdf_with_pypdf(file_path, lang_hint)
            if result and not all(chunk['meta'].get('type') == 'fallback' for chunk in result):
                content_check = " ".join(c['content'] for c in result if c['content'])
                if not is_garbled(content_check) and len(content_check.strip()) > 20:
                    logger.info(f"PyPDF ì„±ê³µ: {len(result)} ì²­í¬ ìƒì„±")
                    return result
                else:
                    library_errors.append("PyPDF: ê°€ë… ë¶ˆê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            else:
                library_errors.append("PyPDF: ìœ íš¨í•œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨")
        except ImportError:
            library_errors.append("PyPDF: ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            library_errors.append(f"PyPDF: {str(e)}")
            logger.warning(f"PyPDF ì‹¤íŒ¨: {e}")

        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš° - ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
        error_summary = "; ".join(library_errors)
        logger.error(f"PDF íŒŒì‹± ì™„ì „ ì‹¤íŒ¨: {error_summary}")

        return parse_as_fallback(
            file_path,
            f"PDF íŒŒì‹± ì‹¤íŒ¨ - ì‹œë„í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {error_summary}"
        )

    elif file_ext in ['.docx', '.doc']:
        try:
            return parse_docx(file_path, lang_hint)
        except Exception as e:
            logger.error(f"Word ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return parse_as_fallback(file_path, f"Word ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")

    elif file_ext in ['.txt', '.md', '.rst']:
        try:
            return parse_text_file(file_path, lang_hint)
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return parse_as_fallback(file_path, f"í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
    else:
        # ê¸°ë³¸ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ ì‹œë„
        try:
            logger.info(f"ì•Œ ìˆ˜ ì—†ëŠ” í™•ì¥ì {file_ext}, í…ìŠ¤íŠ¸ë¡œ ì‹œë„")
            return parse_text_file(file_path, lang_hint)
        except Exception as e:
            return parse_as_fallback(file_path, f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹ ({file_ext}): {str(e)}")


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
if __name__ == "__main__":
    import sys

    print("ğŸ“„ Improved Korean PDF Parser Test")
    print("==================================")

    # ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
    test_korean = "ì•ˆë…•í•˜ì„¸ìš”. ì´ê²ƒì€ í•œê¸€ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. AI ê¸°ë°˜ ê²€ìƒ‰ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤."
    cleaned = clean_text(test_korean)
    print(f"âœ… Encoding test passed: {cleaned[:50]}...")

    if len(sys.argv) > 1:
        test_file = sys.argv[1]
        print(f"\nğŸ” Testing with: {test_file}")

        try:
            chunks = parse_pdf(test_file)
            print(f"âœ… Generated {len(chunks)} chunks")

            for i, chunk in enumerate(chunks[:3]):  # ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ í‘œì‹œ
                print(f"\n--- Chunk {i+1} ---")
                print(f"Content preview: {chunk['content'][:200]}...")
                print(f"Content length: {len(chunk['content'])}")
                print(f"Meta: {chunk['meta']}")

                # í•œêµ­ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
                korean_chars = len(re.findall(r'[ê°€-í£]', chunk['content']))
                print(f"Korean characters: {korean_chars}")

        except Exception as e:
            print(f"âŒ Failed: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("\nğŸ’¡ Usage: python parser.py <pdf_file_path>")