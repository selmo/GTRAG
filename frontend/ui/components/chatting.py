"""
ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì»´í¬ë„ŒíŠ¸ - ê°œì„ ëœ ë²„ì „
ì„¤ì • í˜ì´ì§€ì˜ ëª¨ë¸ ì„¤ì •ì´ ì™„ì „íˆ ë°˜ì˜ë˜ë„ë¡ ìˆ˜ì •
"""
import streamlit as st
from typing import Dict, List, Optional
from datetime import datetime
from frontend.ui.utils.streamlit_helpers import rerun


def get_model_settings():
    """ì„¤ì • í˜ì´ì§€ì—ì„œ ì €ì¥í•œ ëª¨ë¸ ì„¤ì •ì„ ê°€ì ¸ì˜¤ê¸°"""
    return {
        'model': st.session_state.get('selected_model'),
        'temperature': st.session_state.get('temperature', 0.3),
        'system_prompt': st.session_state.get('system_prompt',
                                              "ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."),
        'rag_top_k': st.session_state.get('rag_top_k', 3),
        'min_similarity': st.session_state.get('min_similarity', 0.5),
        'rag_timeout': st.session_state.get('rag_timeout', 300),
        'api_timeout': st.session_state.get('api_timeout', 300),
        'max_tokens': st.session_state.get('max_tokens', 1000),
        'top_p': st.session_state.get('top_p', 0.9),
        'frequency_penalty': st.session_state.get('frequency_penalty', 0.0),
        'context_window': st.session_state.get('context_window', 3000),
        'search_type': st.session_state.get('search_type', 'hybrid')
    }


def check_model_availability(api_client):
    """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        available_models = api_client.get_available_models()
        selected_model = st.session_state.get('selected_model')

        if not available_models:
            return False, "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. Ollama ì„œë²„ë¥¼ í™•ì¸í•˜ì„¸ìš”."

        if not selected_model:
            return False, "ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."

        if selected_model not in available_models:
            return False, f"ì„ íƒëœ ëª¨ë¸ '{selected_model}'ì´ ë” ì´ìƒ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."

        return True, None

    except Exception as e:
        return False, f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}"


def render_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë Œë”ë§"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ
            if message["role"] == "assistant" and "sources" in message:
                render_sources(message["sources"])

            # ë©”ì‹œì§€ì— ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ (ì˜µì…˜)
            if message["role"] == "assistant" and "model_used" in message:
                with st.expander("ğŸ¤– ìƒì„± ì •ë³´", expanded=False):
                    st.caption(f"ì‚¬ìš©ëœ ëª¨ë¸: {message['model_used']}")
                    if "search_info" in message:
                        search_info = message["search_info"]
                        st.caption(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {search_info.get('total_results', 0)}ê°œ")
                        st.caption(f"ê²€ìƒ‰ ìœ í˜•: {search_info.get('search_type', 'unknown')}")


def render_sources(sources: List[Dict]):
    """ì°¸ì¡° ë¬¸ì„œ ë Œë”ë§ - ê°œì„ ëœ ë²„ì „"""
    if not sources:
        return

    with st.expander(f"ğŸ“Œ ì°¸ì¡° ë¬¸ì„œ ({len(sources)}ê°œ)", expanded=False):
        for idx, source in enumerate(sources, 1):
            # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
            score = source.get('score', 0)
            source_name = source.get('source', 'Unknown')
            content = source.get('content', '')

            # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„
            if score >= 0.8:
                score_color = "ğŸŸ¢"
            elif score >= 0.6:
                score_color = "ğŸŸ¡"
            else:
                score_color = "ğŸ”´"

            st.write(f"{score_color} **[ë¬¸ì„œ {idx}] {source_name}** (ìœ ì‚¬ë„: {score:.3f})")

            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ê¸¸ë©´ ì¶•ì•½)
            if len(content) > 300:
                preview = content[:300] + "..."
                with st.expander(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.text(preview)
                    st.text("--- ì „ì²´ ë‚´ìš© ---")
                    st.text(content)
            else:
                st.text(content)

            if idx < len(sources):
                st.divider()


def display_current_settings_sidebar(api_client):
    """ì‚¬ì´ë“œë°”ì— í˜„ì¬ ì„¤ì • í‘œì‹œ"""
    with st.sidebar:
        st.header("ğŸ”§ í˜„ì¬ ì„¤ì •")

        settings = get_model_settings()

        # ëª¨ë¸ ì„¤ì • í‘œì‹œ
        if settings['model']:
            st.success(f"**ëª¨ë¸**: {settings['model']}")
            st.write(f"**Temperature**: {settings['temperature']}")
            st.write(f"**ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜**: {settings['rag_top_k']}")
            st.write(f"**ìµœì†Œ ìœ ì‚¬ë„**: {settings['min_similarity']}")
            st.write(f"**íƒ€ì„ì•„ì›ƒ**: {settings['rag_timeout']}ì´ˆ")
        else:
            st.error("âŒ ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
            st.markdown("ğŸ”— [ì„¤ì • í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”](../pages/settings.py)")

        st.divider()

        # ë¹ ë¥¸ ì„¤ì • ë³€ê²½
        st.subheader("ë¹ ë¥¸ ì„¤ì •")

        if st.button("ğŸ”„ ëª¨ë¸ ìƒíƒœ í™•ì¸"):
            with st.spinner("ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘..."):
                is_available, error_msg = check_model_availability(api_client)

                if is_available:
                    st.success("âœ… ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
                else:
                    st.error(f"âŒ {error_msg}")

        # ë¹ ë¥¸ ê²€ìƒ‰ ì„¤ì • ì¡°ì •
        st.subheader("ë¹ ë¥¸ ì¡°ì •")

        # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ë¹ ë¥¸ ì¡°ì •
        quick_top_k = st.slider(
            "ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜",
            min_value=1,
            max_value=10,
            value=settings['rag_top_k'],
            key="quick_top_k"
        )
        if quick_top_k != settings['rag_top_k']:
            st.session_state.rag_top_k = quick_top_k

        # ìµœì†Œ ìœ ì‚¬ë„ ë¹ ë¥¸ ì¡°ì •
        quick_min_score = st.slider(
            "ìµœì†Œ ìœ ì‚¬ë„",
            min_value=0.0,
            max_value=1.0,
            value=settings['min_similarity'],
            step=0.1,
            key="quick_min_score"
        )
        if quick_min_score != settings['min_similarity']:
            st.session_state.min_similarity = quick_min_score


def handle_chat_input(api_client):
    """ì±„íŒ… ì…ë ¥ ì²˜ë¦¬ - ì„¤ì • í˜ì´ì§€ ì„¤ì • ì™„ì „ ë°˜ì˜"""

    # ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì‚¬ì „ í™•ì¸
    is_model_available, model_error = check_model_availability(api_client)

    if not is_model_available:
        st.error(f"ğŸš« {model_error}")
        st.info("ğŸ’¡ ì„¤ì • í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•œ í›„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        return False  # ì±„íŒ… ì…ë ¥ ë¹„í™œì„±í™”

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        settings = get_model_settings()

        # ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë¸ ìƒíƒœ ì¬í™•ì¸
        is_available, error_msg = check_model_availability(api_client)
        if not is_available:
            st.error(f"ğŸš« {error_msg}")
            return False

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": prompt,
            "timestamp": datetime.now().isoformat()
        })

        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            response_placeholder = st.empty()

            with st.spinner(f"'{settings['model']}'ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    # API í´ë¼ì´ì–¸íŠ¸ íƒ€ì„ì•„ì›ƒ ì„¤ì •
                    api_client.set_timeout(settings['api_timeout'])

                    # ì„¤ì • í˜ì´ì§€ì˜ ëª¨ë“  ì„¤ì •ì„ ì ìš©í•˜ì—¬ RAG ë‹µë³€ ìš”ì²­
                    result = api_client.generate_answer(
                        query=prompt,
                        model=settings['model'],  # âœ… ì„¤ì •ëœ ëª¨ë¸ ì‚¬ìš©
                        temperature=settings['temperature'],  # âœ… ì„¤ì •ëœ ì˜¨ë„ ì‚¬ìš©
                        system_prompt=settings['system_prompt'],  # âœ… ì„¤ì •ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                        top_k=settings['rag_top_k'],  # âœ… ì„¤ì •ëœ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ì‚¬ìš©
                        min_score=settings['min_similarity'],  # âœ… ì„¤ì •ëœ ìµœì†Œ ìœ ì‚¬ë„ ì‚¬ìš©
                        search_type=settings['search_type'],  # âœ… ì„¤ì •ëœ ê²€ìƒ‰ íƒ€ì… ì‚¬ìš©
                        timeout=settings['rag_timeout']  # âœ… ì„¤ì •ëœ RAG íƒ€ì„ì•„ì›ƒ ì‚¬ìš©
                    )

                    if 'error' not in result:
                        # ë‹µë³€ í‘œì‹œ
                        answer = result.get('answer', 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                        response_placeholder.markdown(answer)

                        # ê²€ìƒ‰ ì •ë³´ í‘œì‹œ
                        search_info = result.get('search_info', {})
                        if search_info:
                            total_results = search_info.get('total_results', 0)
                            search_type_used = search_info.get('search_type', 'unknown')
                            contexts_used = search_info.get('contexts_used', 0)

                            # ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥¸ ë©”ì‹œì§€
                            if total_results > 0:
                                st.success(f"ğŸ” {total_results}ê°œ ë¬¸ì„œì—ì„œ {contexts_used}ê°œ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© (ê²€ìƒ‰: {search_type_used})")
                            else:
                                st.warning(f"âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ê²€ìƒ‰: {search_type_used})")

                            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
                            st.caption(f"ğŸ¤– ëª¨ë¸: {settings['model']} | ì˜¨ë„: {settings['temperature']}")

                        # ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ
                        sources = result.get('sources', [])
                        if sources:
                            render_sources(sources)

                        # ë©”ì‹œì§€ ì €ì¥ (ìƒì„¸ ì •ë³´ í¬í•¨)
                        message_data = {
                            "role": "assistant",
                            "content": answer,
                            "timestamp": datetime.now().isoformat(),
                            "model_used": settings['model'],
                            "settings_used": {
                                "temperature": settings['temperature'],
                                "top_k": settings['rag_top_k'],
                                "min_similarity": settings['min_similarity'],
                                "search_type": settings['search_type']
                            }
                        }

                        # ì†ŒìŠ¤ì™€ ê²€ìƒ‰ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                        if sources:
                            message_data['sources'] = sources
                        if search_info:
                            message_data['search_info'] = search_info

                        st.session_state.messages.append(message_data)

                    else:
                        # ì—ëŸ¬ ì²˜ë¦¬
                        error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                        handle_error(error_msg, settings['model'])

                except Exception as e:
                    handle_error(str(e), settings['model'])

    return True


def handle_error(error_msg: str, model_used: str = None):
    """ì—ëŸ¬ ì²˜ë¦¬ - ê°œì„ ëœ ë²„ì „"""

    # ì—ëŸ¬ ìœ í˜•ë³„ ë©”ì‹œì§€ ì»¤ìŠ¤í„°ë§ˆì´ì§•
    if "timeout" in error_msg.lower() or "ì‹œê°„ ì´ˆê³¼" in error_msg:
        error_text = f"â° ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.\nìƒì„¸: {error_msg}"
        if model_used:
            error_text += f"\nì‚¬ìš©ëœ ëª¨ë¸: {model_used}"
    elif "ì—°ê²°" in error_msg or "connection" in error_msg.lower():
        error_text = f"ğŸ”Œ ì„œë²„ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\nìƒì„¸: {error_msg}"
    elif "ëª¨ë¸" in error_msg or "model" in error_msg.lower():
        error_text = f"ğŸ¤– ëª¨ë¸ ê´€ë ¨ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\nìƒì„¸: {error_msg}"
    else:
        error_text = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"
        if model_used:
            error_text += f"\nì‚¬ìš©ëœ ëª¨ë¸: {model_used}"

    st.error(error_text)

    # ì—ëŸ¬ ë©”ì‹œì§€ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.session_state.messages.append({
        "role": "assistant",
        "content": error_text,
        "timestamp": datetime.now().isoformat(),
        "is_error": True,
        "model_used": model_used
    })


def clear_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
    if st.session_state.get('messages'):
        st.session_state.messages = []
        st.success("âœ… ëŒ€í™” ë‚´ì—­ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        rerun()
    else:
        st.info("ì´ˆê¸°í™”í•  ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")


def export_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸° - ê°œì„ ëœ ë²„ì „"""
    if st.session_state.get('messages'):
        import json

        # í˜„ì¬ ì„¤ì • ì •ë³´ë„ í•¨ê»˜ ë‚´ë³´ë‚´ê¸°
        settings = get_model_settings()

        chat_data = {
            "exported_at": datetime.now().isoformat(),
            "export_settings": settings,
            "total_messages": len(st.session_state.messages),
            "messages": st.session_state.messages
        }

        st.download_button(
            label="ğŸ’¾ ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(chat_data, ensure_ascii=False, indent=2),
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            help="ëŒ€í™” ë‚´ì—­ê³¼ ì‚¬ìš©ëœ ì„¤ì •ì„ JSON íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        )
    else:
        st.info("ë‚´ë³´ë‚¼ ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")


def display_chat_stats():
    """ì±„íŒ… í†µê³„ í‘œì‹œ"""
    if st.session_state.get('messages'):
        messages = st.session_state.messages
        total_messages = len(messages)
        user_messages = len([m for m in messages if m['role'] == 'user'])
        assistant_messages = len([m for m in messages if m['role'] == 'assistant'])
        error_messages = len([m for m in messages if m.get('is_error', False)])

        # ì‚¬ìš©ëœ ëª¨ë¸ë“¤ ì§‘ê³„
        models_used = set()
        for m in messages:
            if m['role'] == 'assistant' and 'model_used' in m:
                models_used.add(m['model_used'])

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ì´ ë©”ì‹œì§€", total_messages)

        with col2:
            st.metric("ì§ˆë¬¸", user_messages)

        with col3:
            st.metric("ë‹µë³€", assistant_messages)

        with col4:
            st.metric("ì˜¤ë¥˜", error_messages, delta="ë¬¸ì œ" if error_messages > 0 else None)

        if models_used:
            st.caption(f"ğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {', '.join(models_used)}")


def display_model_change_notification():
    """ëª¨ë¸ ë³€ê²½ ì•Œë¦¼ í‘œì‹œ"""
    current_model = st.session_state.get('selected_model')
    previous_model = st.session_state.get('previous_chat_model')

    if previous_model and current_model and previous_model != current_model:
        st.info(f"ğŸ”„ ëª¨ë¸ì´ '{previous_model}'ì—ì„œ '{current_model}'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # í˜„ì¬ ëª¨ë¸ì„ ì´ì „ ëª¨ë¸ë¡œ ì €ì¥
    st.session_state.previous_chat_model = current_model


def render_chat_interface(api_client):
    """ì „ì²´ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""

    # ì„¤ì • í‘œì‹œ ì‚¬ì´ë“œë°”
    display_current_settings_sidebar(api_client)

    # ëª¨ë¸ ë³€ê²½ ì•Œë¦¼
    display_model_change_notification()

    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    st.title("ğŸ’¬ GTOne RAG Chat")

    # ìƒë‹¨ ì»¨íŠ¸ë¡¤
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        st.write("### ëŒ€í™”")

    with col2:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            clear_chat_history()

    with col3:
        export_chat_history()

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if st.session_state.messages:
        render_chat_history()
    else:
        st.info("ğŸ’¡ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

    # ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    chat_active = handle_chat_input(api_client)

    # í•˜ë‹¨ í†µê³„
    if st.session_state.messages:
        st.divider()
        display_chat_stats()

    return chat_active