"""Chat history services."""
from __future__ import annotations

import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any

import streamlit as st

from frontend.ui.core.config import Constants
from frontend.ui.components.common import MetricCard  # stats

from .message_display import render_sources, calculate_overall_confidence, get_source_quality_grade

# ğŸš€ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì ìš©
try:
    from .reference_system import reference_system

    HAS_REFERENCE_SYSTEM = True
except ImportError:
    reference_system = None
    HAS_REFERENCE_SYSTEM = False

__all__ = ["ChatHistory"]


class ChatHistory:
    """Thin wrapper around *st.session_state.messages* list for type safety."""

    _SS_KEY = "messages"

    # ---------------------------------------------------------------------
    # Session helpers
    # ---------------------------------------------------------------------
    @staticmethod
    def _ensure_list() -> List[Dict]:
        if ChatHistory._SS_KEY not in st.session_state:
            st.session_state[ChatHistory._SS_KEY] = []
        return st.session_state[ChatHistory._SS_KEY]

    # ---------------------------------------------------------------------
    # Enhanced public helpers
    # ---------------------------------------------------------------------
    def add(self, role: str, content: str, **extra):
        """ë©”ì‹œì§€ ì¶”ê°€ (ê°•í™”ëœ ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "message_id": self._generate_message_id(),
            **extra,
        }

        # Assistant ë©”ì‹œì§€ì˜ ê²½ìš° ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬
        if role == "assistant":
            message = self._enhance_assistant_message(message)

        # User ë©”ì‹œì§€ì˜ ê²½ìš°ë„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        elif role == "user":
            message = self._enhance_user_message(message)

        self._ensure_list().append(message)

    def _generate_message_id(self) -> str:
        """ê³ ìœ í•œ ë©”ì‹œì§€ ID ìƒì„±"""
        import uuid
        return str(uuid.uuid4())[:8]

    def _enhance_assistant_message(self, message: Dict) -> Dict:
        """Assistant ë©”ì‹œì§€ ë©”íƒ€ë°ì´í„° ê°•í™”"""
        sources = message.get("sources", [])
        search_info = message.get("search_info", {})

        # ê·¼ê±° í’ˆì§ˆ ë¶„ì„
        if sources:
            overall_confidence = calculate_overall_confidence(sources)
            quality_grade = get_source_quality_grade(overall_confidence)

            # ê·¼ê±° í†µê³„
            source_stats = {
                "total_sources": len(sources),
                "avg_score": sum(s.get("score", 0) for s in sources) / len(sources),
                "max_score": max(s.get("score", 0) for s in sources),
                "min_score": min(s.get("score", 0) for s in sources),
                "overall_confidence": overall_confidence,
                "quality_grade": quality_grade,
                "high_confidence_count": len([s for s in sources if s.get("confidence", 0) >= 0.7]),
                "medium_confidence_count": len([s for s in sources if 0.4 <= s.get("confidence", 0) < 0.7]),
                "low_confidence_count": len([s for s in sources if s.get("confidence", 0) < 0.4])
            }

            # ì†ŒìŠ¤ ë‹¤ì–‘ì„± ë¶„ì„
            source_diversity = self._analyze_source_diversity(sources)

            message.update({
                "source_stats": source_stats,
                "source_diversity": source_diversity,
                "answer_quality": self._assess_answer_quality(message["content"], source_stats),
                "has_high_quality_sources": overall_confidence >= 0.7
            })

        # ê²€ìƒ‰ ì„±ëŠ¥ ë©”íƒ€ë°ì´í„°
        if search_info:
            message["search_performance"] = {
                "search_time": search_info.get("processing_time", 0),
                "search_efficiency": self._calculate_search_efficiency(search_info),
                "search_type_used": search_info.get("search_type", "unknown")
            }

        return message

    def _enhance_user_message(self, message: Dict) -> Dict:
        """User ë©”ì‹œì§€ ë©”íƒ€ë°ì´í„° ê°•í™”"""
        content = message["content"]

        # ì§ˆë¬¸ ë¶„ì„
        question_analysis = {
            "length": len(content),
            "word_count": len(content.split()),
            "has_question_mark": "?" in content,
            "question_type": self._classify_question_type(content),
            "complexity_level": self._assess_question_complexity(content),
            "language": self._detect_content_language(content)
        }

        message["question_analysis"] = question_analysis
        return message

    def _analyze_source_diversity(self, sources: List[Dict]) -> Dict:
        """ì†ŒìŠ¤ ë‹¤ì–‘ì„± ë¶„ì„"""
        if not sources:
            return {"diversity_score": 0, "unique_sources": 0, "source_types": []}

        # ê³ ìœ í•œ ì†ŒìŠ¤ íŒŒì¼ ìˆ˜
        unique_sources = len(set(s.get("source", "") for s in sources))

        # ì†ŒìŠ¤ íƒ€ì… ë¶„ì„
        source_types = []
        for source in sources:
            metadata = source.get("metadata", {})
            doc_type = metadata.get("document_type", "unknown")
            if doc_type not in source_types:
                source_types.append(doc_type)

        # ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚° (0~1)
        diversity_score = min(1.0, unique_sources / max(1, len(sources)))

        return {
            "diversity_score": diversity_score,
            "unique_sources": unique_sources,
            "total_sources": len(sources),
            "source_types": source_types,
            "type_diversity": len(source_types)
        }

    def _assess_answer_quality(self, answer: str, source_stats: Dict) -> Dict:
        """ë‹µë³€ í’ˆì§ˆ í‰ê°€"""
        if not answer:
            return {"quality_score": 0, "issues": ["ë¹ˆ ë‹µë³€"]}

        quality_factors = {
            "length_appropriate": 100 <= len(answer) <= 2000,
            "has_structure": any(marker in answer for marker in ["1.", "2.", "â€¢", "-", "\n\n"]),
            "cites_sources": source_stats.get("total_sources", 0) > 0,
            "high_confidence_sources": source_stats.get("overall_confidence", 0) >= 0.6,
            "diverse_sources": source_stats.get("total_sources", 0) >= 2
        }

        quality_score = sum(quality_factors.values()) / len(quality_factors)

        # í’ˆì§ˆ ì´ìŠˆ ì‹ë³„
        issues = []
        if not quality_factors["length_appropriate"]:
            if len(answer) < 100:
                issues.append("ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŒ")
            else:
                issues.append("ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ìŒ")

        if not quality_factors["has_structure"]:
            issues.append("êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë‹µë³€")

        if not quality_factors["high_confidence_sources"]:
            issues.append("ë‚®ì€ ì‹ ë¢°ë„ì˜ ê·¼ê±°")

        if not quality_factors["diverse_sources"]:
            issues.append("ì œí•œì ì¸ ê·¼ê±° ë‹¤ì–‘ì„±")

        return {
            "quality_score": quality_score,
            "quality_factors": quality_factors,
            "issues": issues,
            "overall_grade": self._get_quality_grade(quality_score)
        }

    def _get_quality_grade(self, score: float) -> str:
        """í’ˆì§ˆ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 0.9:
            return "A+ (ìš°ìˆ˜)"
        elif score >= 0.8:
            return "A (ì¢‹ìŒ)"
        elif score >= 0.7:
            return "B+ (ì–‘í˜¸)"
        elif score >= 0.6:
            return "B (ë³´í†µ)"
        elif score >= 0.5:
            return "C+ (ë¯¸í¡)"
        else:
            return "C (ê°œì„  í•„ìš”)"

    def _calculate_search_efficiency(self, search_info: Dict) -> float:
        """ê²€ìƒ‰ íš¨ìœ¨ì„± ê³„ì‚°"""
        search_time = search_info.get("processing_time", 0)
        total_candidates = search_info.get("total_candidates", 0)

        if search_time == 0 or total_candidates == 0:
            return 0.0

        # ë‹¨ìœ„ ì‹œê°„ë‹¹ ì²˜ë¦¬ëœ í›„ë³´ ìˆ˜ ê¸°ì¤€ íš¨ìœ¨ì„±
        efficiency = min(1.0, total_candidates / (search_time * 100))
        return efficiency

    def _classify_question_type(self, content: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
        content_lower = content.lower()

        if any(word in content_lower for word in ["ë¬´ì—‡", "what", "ì •ì˜", "ëœ»"]):
            return "ì •ì˜í˜•"
        elif any(word in content_lower for word in ["ì–´ë–»ê²Œ", "how", "ë°©ë²•"]):
            return "ë°©ë²•í˜•"
        elif any(word in content_lower for word in ["ì™œ", "why", "ì´ìœ ", "ì›ì¸"]):
            return "ì´ìœ í˜•"
        elif any(word in content_lower for word in ["ì–¸ì œ", "when", "ì‹œê¸°"]):
            return "ì‹œê°„í˜•"
        elif any(word in content_lower for word in ["ì–´ë””", "where", "ì¥ì†Œ"]):
            return "ì¥ì†Œí˜•"
        elif any(word in content_lower for word in ["ëˆ„êµ¬", "who"]):
            return "ì¸ë¬¼í˜•"
        elif content.endswith("?"):
            return "ì¼ë°˜ ì§ˆë¬¸"
        else:
            return "ìš”ì²­í˜•"

    def _assess_question_complexity(self, content: str) -> str:
        """ì§ˆë¬¸ ë³µì¡ë„ í‰ê°€"""
        complexity_indicators = {
            "ê¸¸ì´": len(content) > 100,
            "ë‹¤ì¤‘_ì£¼ì œ": len(content.split("ê·¸ë¦¬ê³ ")) > 1 or len(content.split("ë˜í•œ")) > 1,
            "ì¡°ê±´ë¶€": any(word in content for word in ["ë§Œì•½", "ê²½ìš°", "ìƒí™©", "ì¡°ê±´"]),
            "ë¹„êµ": any(word in content for word in ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸", "ê°™ì€"]),
            "ë¶„ì„": any(word in content for word in ["ë¶„ì„", "í‰ê°€", "ê²€í† ", "íŒë‹¨"])
        }

        complexity_score = sum(complexity_indicators.values())

        if complexity_score >= 3:
            return "ë³µì¡"
        elif complexity_score >= 1:
            return "ë³´í†µ"
        else:
            return "ë‹¨ìˆœ"

    def _detect_content_language(self, content: str) -> str:
        """ì½˜í…ì¸  ì–¸ì–´ ê°ì§€"""
        # ğŸ”§ ë¡œì»¬ import ì œê±° (ìƒë‹¨ì—ì„œ ì´ë¯¸ importë¨)
        korean_chars = len(re.findall(r'[ê°€-í£]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))

        total_chars = korean_chars + english_chars
        if total_chars == 0:
            return "ê¸°íƒ€"

        korean_ratio = korean_chars / total_chars

        if korean_ratio > 0.7:
            return "í•œêµ­ì–´"
        elif korean_ratio < 0.3:
            return "ì˜ì–´"
        else:
            return "í˜¼í•©"

    def clear(self):
        """ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”"""
        if self._ensure_list():
            # ì‚­ì œ ì „ í†µê³„ ì €ì¥
            stats = self._calculate_session_stats()

            st.session_state[self._SS_KEY] = []
            st.success(f"{Constants.Icons.STATUS_OK} ëŒ€í™” ë‚´ì—­ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì„¸ì…˜ í†µê³„ í‘œì‹œ
            if stats["total_messages"] > 0:
                st.info(f"ì‚­ì œëœ ì„¸ì…˜ í†µê³„: {stats['summary_text']}")
        else:
            st.info("ì´ˆê¸°í™”í•  ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")

    def export(self):
        """í–¥ìƒëœ ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥"""
        messages = self._ensure_list()
        if not messages:
            st.info("ë‚´ë³´ë‚¼ ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì„¸ì…˜ í†µê³„ ê³„ì‚°
        session_stats = self._calculate_session_stats()

        # ë‚´ë³´ë‚´ê¸° ë°ì´í„° êµ¬ì„±
        export_data = {
            "export_metadata": {
                "exported_at": datetime.now().isoformat(),
                "export_version": "2.0",
                "total_messages": len(messages),
                "session_stats": session_stats
            },
            "messages": messages,
            "session_summary": self._generate_session_summary()
        }

        # JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
        json_data = json.dumps(export_data, ensure_ascii=False, indent=2)

        st.download_button(
            label=f"{Constants.Icons.DOWNLOAD} ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ (ìƒì„¸ ë²„ì „)",
            data=json_data,
            file_name=f"gtone_chat_enhanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
        )

    def _calculate_session_stats(self) -> Dict:
        """ì„¸ì…˜ í†µê³„ ê³„ì‚°"""
        messages = self._ensure_list()

        if not messages:
            return {"total_messages": 0, "summary_text": "ë©”ì‹œì§€ ì—†ìŒ"}

        total = len(messages)
        user_msgs = [m for m in messages if m["role"] == "user"]
        assistant_msgs = [m for m in messages if m["role"] == "assistant"]

        # ê·¼ê±° í†µê³„
        total_sources = sum(len(m.get("sources", [])) for m in assistant_msgs)
        high_quality_responses = sum(1 for m in assistant_msgs
                                   if m.get("has_high_quality_sources", False))

        # í‰ê·  ì‘ë‹µ ì‹œê°„
        response_times = [m.get("search_performance", {}).get("search_time", 0)
                         for m in assistant_msgs]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0

        # ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„
        complex_questions = sum(1 for m in user_msgs
                              if m.get("question_analysis", {}).get("complexity_level") == "ë³µì¡")

        summary_text = (f"ì§ˆë¬¸ {len(user_msgs)}ê°œ, ë‹µë³€ {len(assistant_msgs)}ê°œ, "
                       f"ê³ í’ˆì§ˆ ë‹µë³€ {high_quality_responses}ê°œ, "
                       f"í‰ê·  ì‘ë‹µì‹œê°„ {avg_response_time:.1f}ì´ˆ")

        return {
            "total_messages": total,
            "user_messages": len(user_msgs),
            "assistant_messages": len(assistant_msgs),
            "total_sources_used": total_sources,
            "high_quality_responses": high_quality_responses,
            "avg_response_time": avg_response_time,
            "complex_questions": complex_questions,
            "summary_text": summary_text
        }

    def _generate_session_summary(self) -> Dict:
        """ì„¸ì…˜ ìš”ì•½ ìƒì„±"""
        messages = self._ensure_list()
        assistant_msgs = [m for m in messages if m["role"] == "assistant"]

        if not assistant_msgs:
            return {"summary": "ëŒ€í™” ì—†ìŒ"}

        # ì£¼ìš” ì£¼ì œ ì¶”ì¶œ
        all_keywords = []
        for msg in assistant_msgs:
            sources = msg.get("sources", [])
            for source in sources:
                keywords = source.get("keywords", [])
                all_keywords.extend(keywords)

        from collections import Counter
        top_keywords = Counter(all_keywords).most_common(10)

        # í’ˆì§ˆ ë¶„í¬
        quality_grades = [m.get("answer_quality", {}).get("overall_grade", "ì•Œ ìˆ˜ ì—†ìŒ")
                         for m in assistant_msgs]
        quality_distribution = Counter(quality_grades)

        return {
            "top_keywords": top_keywords,
            "quality_distribution": dict(quality_distribution),
            "conversation_flow": self._analyze_conversation_flow()
        }

    def _analyze_conversation_flow(self) -> Dict:
        """ëŒ€í™” íë¦„ ë¶„ì„"""
        messages = self._ensure_list()
        user_msgs = [m for m in messages if m["role"] == "user"]

        if not user_msgs:
            return {"flow_type": "ì—†ìŒ"}

        # ì§ˆë¬¸ ìœ í˜• ë¶„í¬
        question_types = [m.get("question_analysis", {}).get("question_type", "ì•Œ ìˆ˜ ì—†ìŒ")
                         for m in user_msgs]

        from collections import Counter
        type_distribution = Counter(question_types)

        # ë³µì¡ë„ ë³€í™”
        complexities = [m.get("question_analysis", {}).get("complexity_level", "ì•Œ ìˆ˜ ì—†ìŒ")
                       for m in user_msgs]

        return {
            "question_type_distribution": dict(type_distribution),
            "complexity_progression": complexities,
            "total_exchanges": len(user_msgs)
        }

    # ---------------------------------------------------------------------
    # Enhanced UI helpers
    # ---------------------------------------------------------------------
    def render(self):
        """ê°•í™”ëœ ë©”ì‹œì§€ ë Œë”ë§ - ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì§€ì›"""
        messages = self._ensure_list()

        for idx, msg in enumerate(messages):
            with st.chat_message(msg["role"]):
                if msg["role"] == "user":
                    # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ê¸°ë³¸ ë Œë”ë§
                    st.markdown(msg["content"])

                elif msg["role"] == "assistant":
                    # ğŸš€ Assistant ë©”ì‹œì§€ì— ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì ìš©
                    content = msg["content"]
                    sources = msg.get("sources", [])

                    if HAS_REFERENCE_SYSTEM and reference_system and sources:
                        # ë ˆí¼ëŸ°ìŠ¤ê°€ í¬í•¨ëœ ë‹µë³€ ë Œë”ë§
                        message_id = msg.get("message_id", f"history_msg_{idx}")

                        # ì´ë¯¸ ë ˆí¼ëŸ°ìŠ¤ê°€ ì‚½ì…ëœ ë‚´ìš©ì¸ì§€ í™•ì¸
                        if "[[" in content and "](#ref-" in content:
                            # ì´ë¯¸ ë ˆí¼ëŸ°ìŠ¤ê°€ ìˆëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ë Œë”ë§
                            st.markdown(content, unsafe_allow_html=True)
                        else:
                            # ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œìœ¼ë¡œ ì²˜ë¦¬
                            reference_system.render_interactive_answer(content, sources, message_id)
                    else:
                        # ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì—†ê±°ë‚˜ ì†ŒìŠ¤ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë Œë”ë§
                        st.markdown(content)

                    # Assistant ë©”ì‹œì§€ì˜ ì¶”ê°€ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                    self._render_assistant_metadata(msg)

                    # ê·¼ê±° í‘œì‹œ (ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì‚¬ìš©)
                    if "sources" in msg:
                        render_sources(
                            msg["sources"],
                            msg.get("search_info")
                        )

    def _render_assistant_metadata(self, msg: Dict):
        """Assistant ë©”ì‹œì§€ ë©”íƒ€ë°ì´í„° ë Œë”ë§"""
        # ê°„ë‹¨í•œ í’ˆì§ˆ ì§€í‘œ í‘œì‹œ
        if quality_info := msg.get("answer_quality"):
            quality_grade = quality_info.get("overall_grade", "ì•Œ ìˆ˜ ì—†ìŒ")
            quality_score = quality_info.get("quality_score", 0)

            if quality_score >= 0.7:
                st.success(f"âœ¨ ë‹µë³€ í’ˆì§ˆ: {quality_grade}")
            elif quality_score >= 0.5:
                st.info(f"ğŸ“Š ë‹µë³€ í’ˆì§ˆ: {quality_grade}")
            else:
                st.warning(f"âš ï¸ ë‹µë³€ í’ˆì§ˆ: {quality_grade}")

    def render_stats(self):
        """ê°•í™”ëœ í†µê³„ í‘œì‹œ"""
        msgs = self._ensure_list()
        if not msgs:
            return

        # ê¸°ë³¸ í†µê³„
        session_stats = self._calculate_session_stats()

        # ë©”íŠ¸ë¦­ ì¹´ë“œ í‘œì‹œ
        MetricCard.render_metric_grid([
            {"title": "ì´ ë©”ì‹œì§€", "value": session_stats["total_messages"]},
            {"title": "ì§ˆë¬¸", "value": session_stats["user_messages"]},
            {"title": "ë‹µë³€", "value": session_stats["assistant_messages"]},
            {"title": "ê³ í’ˆì§ˆ ë‹µë³€", "value": session_stats["high_quality_responses"],
             "delta": f"{session_stats['high_quality_responses']}/{session_stats['assistant_messages']}"
             if session_stats["assistant_messages"] > 0 else None},
        ])

        # ìƒì„¸ í†µê³„ (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ“ˆ ìƒì„¸ ì„¸ì…˜ í†µê³„", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                st.metric("ì „ì²´ í™œìš© ê·¼ê±°", session_stats["total_sources_used"])
                st.metric("ë³µì¡í•œ ì§ˆë¬¸", session_stats["complex_questions"])

            with col2:
                st.metric("í‰ê·  ì‘ë‹µì‹œê°„", f"{session_stats['avg_response_time']:.1f}ì´ˆ")

                # í’ˆì§ˆ ë¶„í¬ ì°¨íŠ¸
                if session_stats["assistant_messages"] > 0:
                    quality_rate = session_stats["high_quality_responses"] / session_stats["assistant_messages"]
                    st.metric("ê³ í’ˆì§ˆ ë‹µë³€ ë¹„ìœ¨", f"{quality_rate:.1%}")