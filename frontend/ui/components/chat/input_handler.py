"""Handles user input & triggers RAG calls."""
from __future__ import annotations

import re  # ğŸ”§ ëˆ„ë½ëœ import ì¶”ê°€
import time  # ğŸ”§ ì¶”ê°€
from datetime import datetime
import logging
from typing import Any, Dict, List

import streamlit as st

from frontend.ui.core.config import Constants
from frontend.ui.utils.error_handler import ErrorContext
from frontend.ui.components.common import ErrorDisplay
from frontend.ui.utils.streamlit_helpers import rerun

from .history import ChatHistory
from .utils import get_model_settings, check_model_availability, show_simple_loading, clear_loading

try:
    from frontend.ui.utils.model_manager import ModelManager  # type: ignore
    HAS_MODEL_MANAGER = True
except ImportError:
    ModelManager = None  # type: ignore
    HAS_MODEL_MANAGER = False

logger = logging.getLogger(__name__)


class ChatInputHandler:
    """Encapsulates *handle_chat_input* logic for composability."""

    def __init__(self, api_client):
        self.api_client = api_client
        self.history = ChatHistory()

    # --------------------------------------------------------------
    # Public entry point
    # --------------------------------------------------------------
    def render_input(self) -> bool:
        """Render Streamlit chatâ€‘input widget, returns *True* if interaction occurred."""
        # ğŸ”§ ëª¨ë¸ ê°€ìš©ì„± ì²´í¬ ìµœì í™” (ìºì‹œ í™œìš©)
        if 'model_check_cache' not in st.session_state:
            st.session_state.model_check_cache = {}

        cache_key = "model_availability_input"
        cache_data = st.session_state.model_check_cache.get(cache_key)

        current_time = time.time()
        if (cache_data and
            current_time - cache_data.get('timestamp', 0) < 10):
            ok, err_msg = cache_data['result']
        else:
            ok, err_msg = check_model_availability(self.api_client)
            st.session_state.model_check_cache[cache_key] = {
                'result': (ok, err_msg),
                'timestamp': current_time
            }

        if not ok:
            ErrorDisplay.render_error_with_suggestions(
                err_msg,
                [
                    "ì„¤ì • í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
                    "Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”",
                    "ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”",
                ],
            )
            return False

        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            # --- user message immediately added
            self.history.add("user", prompt)

            # --- obtain fresh settings
            with ErrorContext("ëª¨ë¸ ì„¤ì • ì¡°íšŒ") as ctx:
                try:
                    settings = get_model_settings()
                except Exception as exc:
                    ctx.add_error(exc)
                    return False

            # --- call backend (sync for now)
            with st.chat_message("assistant"):
                answer_placeholder = st.empty()
                status = st.empty()

                show_simple_loading(f"ğŸ¤– '{settings['model']}'ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...", status)

                with ErrorContext("RAG ë‹µë³€ ìƒì„±") as ctx:
                    try:
                        params = self._compose_enhanced_params(prompt, settings)
                        result = self.api_client.generate_answer(**params)  # type: ignore[arg-type]

                        clear_loading(status)

                        if "error" in result:
                            self._handle_error(result["error"], settings["model"], answer_placeholder)
                            return True

                        answer = result.get("answer", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        sources = result.get("sources", [])
                        search_info = result.get("search_info", {})

                        # ğŸ”§ ê·¼ê±° ë©”íƒ€ë°ì´í„° ê°•í™” (enhanced_sources ì •ì˜)
                        enhanced_sources = self._enhance_source_metadata(sources, prompt)

                        # ğŸš€ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì ìš©
                        try:
                            from .reference_system import reference_system
                            HAS_REFERENCE_SYSTEM = True
                        except ImportError:
                            reference_system = None
                            HAS_REFERENCE_SYSTEM = False

                        if answer and answer.strip():
                            if HAS_REFERENCE_SYSTEM and reference_system and enhanced_sources:
                                # ğŸš€ CSS ì „ìš© ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì‚¬ìš© (í˜¸ë²„ ë¯¸ë¦¬ë³´ê¸° í¬í•¨)
                                message_id = f"msg_{datetime.now().timestamp()}"
                                referenced_answer = reference_system.render_interactive_answer(
                                    answer, enhanced_sources, message_id, answer_placeholder
                                )
                            else:
                                # ê¸°ë³¸ ë Œë”ë§ (ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì—†ìŒ)
                                answer_placeholder.markdown(answer)
                        else:
                            answer_placeholder.warning("âš ï¸ ë¹ˆ ì‘ë‹µì´ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."

                        # ğŸ”§ íˆìŠ¤í† ë¦¬ ì¶”ê°€ ì „ ë””ë²„ê¹…
                        logger.info(f"ë‹µë³€ ê¸¸ì´: {len(answer)}, ê·¼ê±° ìˆ˜: {len(enhanced_sources)}")

                        self.history.add(
                            "assistant",
                            answer,
                            model_used=settings["model"],
                            sources=enhanced_sources,
                            search_info=search_info,
                            query_metadata={
                                "original_query": prompt,
                                "query_length": len(prompt),
                                "query_language": self._detect_language(prompt),
                                "query_keywords": self._extract_keywords(prompt),
                                "response_time": search_info.get("processing_time", 0),
                                "total_sources_found": len(sources),
                                "high_confidence_sources": len([s for s in enhanced_sources
                                                               if s.get("confidence", 0) >= 0.7])
                            },
                            settings_used={
                                "temperature": settings["temperature"],
                                "top_k": settings["rag_top_k"],
                                "min_similarity": settings["min_similarity"],
                                "search_type": settings["search_type"],
                                "enhanced_metadata": True
                            },
                        )
                    except Exception as exc:
                        clear_loading(status)
                        answer_placeholder.empty()
                        ctx.add_error(exc)
                        model = settings.get('model', 'unknown')
                        self._handle_error(str(exc), model, answer_placeholder)

            rerun()  # immediate UI refresh so that new messages appear
            return True
        return False

    # --------------------------------------------------------------
    # Enhanced parameter composition
    # --------------------------------------------------------------
    def _compose_enhanced_params(self, prompt: str, settings: Dict[str, Any]) -> Dict:
        """ìƒì„¸í•œ ê·¼ê±° ì •ë³´ë¥¼ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ êµ¬ì„±"""
        base_params = {
            "query": prompt,
            "model": settings["model"],
            "temperature": settings["temperature"],
            "system_prompt": settings["system_prompt"],
            "top_k": settings["rag_top_k"],
            "min_score": settings["min_similarity"],
            "search_type": settings["search_type"],
            "timeout": settings["rag_timeout"],

            # ê°•í™”ëœ ê·¼ê±° ìš”ì²­ ë§¤ê°œë³€ìˆ˜
            "include_metadata": True,
            "include_citations": True,
            "include_confidence_scores": True,
            "extract_keywords": True,
            "highlight_relevant_text": True,
            "return_search_details": True,

            # ê·¼ê±° í’ˆì§ˆ í–¥ìƒ ì˜µì…˜
            "deduplicate_sources": True,
            "rank_by_relevance": True,
            "min_content_length": 50,
            "max_content_length": 2000,

            # ë©”íƒ€ë°ì´í„° ìš”ì²­
            "metadata_fields": [
                "title", "section", "page", "author",
                "created_date", "document_type", "file_path"
            ]
        }

        # ëª¨ë¸ ë§¤ë‹ˆì € ì ìš©
        if HAS_MODEL_MANAGER:
            return ModelManager.apply_to_api_request(base_params)

        return base_params

    def _enhance_source_metadata(self, sources: List[Dict], query: str) -> List[Dict]:
        """ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„° ê°•í™”"""
        enhanced_sources = []

        query_keywords = self._extract_keywords(query)

        for source in sources:
            enhanced_source = source.copy()
            content = source.get("content", "")

            # í‚¤ì›Œë“œ ë§¤ì¹­ ì •ë³´ ì¶”ê°€
            enhanced_source["keywords"] = query_keywords
            enhanced_source["keyword_matches"] = self._count_keyword_matches(content, query_keywords)

            # ì½˜í…ì¸  ë©”íŠ¸ë¦­ ì¶”ê°€
            enhanced_source["content_metrics"] = {
                "length": len(content),
                "sentences": len(content.split('. ')) if content else 0,
                "has_numbers": bool(re.search(r'\d+', content)),
                "has_korean": bool(re.search(r'[ê°€-í£]', content)),
                "readability_score": self._calculate_readability(content)
            }

            # ì‹œê°„ ì •ë³´ ì¶”ê°€
            enhanced_source["processed_at"] = datetime.now().isoformat()

            # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
            enhanced_source["relevance_factors"] = {
                "base_score": source.get("score", 0),
                "keyword_bonus": min(0.1, enhanced_source["keyword_matches"] * 0.02),
                "length_factor": self._calculate_length_factor(len(content)),
                "metadata_bonus": 0.05 if source.get("metadata") else 0
            }

            enhanced_sources.append(enhanced_source)

        return enhanced_sources

    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í•œê¸€, ì˜ë¬¸ ë‹¨ì–´ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£]{2,}|[a-zA-Z]{3,}', text)

        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ê·¸ë˜ì„œ', 'ë˜í•œ', 'ë˜ëŠ”',
            'and', 'but', 'however', 'therefore', 'also', 'or', 'the', 'is', 'are'
        }

        keywords = [word for word in words if word.lower() not in stopwords]

        # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í‚¤ì›Œë“œë§Œ ë°˜í™˜
        from collections import Counter
        keyword_counts = Counter(keywords)

        return [word for word, count in keyword_counts.most_common(10)]

    def _count_keyword_matches(self, content: str, keywords: List[str]) -> int:
        """ì½˜í…ì¸ ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ íšŸìˆ˜ ê³„ì‚°"""
        if not keywords or not content:
            return 0

        content_lower = content.lower()
        matches = 0

        for keyword in keywords:
            matches += content_lower.count(keyword.lower())

        return matches

    def _calculate_readability(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
        if not text:
            return 0.0

        # ë‹¨ìˆœ ë©”íŠ¸ë¦­: í‰ê·  ë¬¸ì¥ ê¸¸ì´ì˜ ì—­ìˆ˜
        sentences = text.split('. ')
        if not sentences:
            return 0.0

        avg_sentence_length = len(text) / len(sentences)

        # ì ì ˆí•œ ë¬¸ì¥ ê¸¸ì´(50-150ì)ì¼ ë•Œ ë†’ì€ ì ìˆ˜
        if 50 <= avg_sentence_length <= 150:
            return 1.0
        elif avg_sentence_length < 50:
            return avg_sentence_length / 50
        else:
            return max(0.3, 150 / avg_sentence_length)

    def _calculate_length_factor(self, length: int) -> float:
        """ì½˜í…ì¸  ê¸¸ì´ì— ë”°ë¥¸ ë³´ì • íŒ©í„°"""
        if length < 50:
            return -0.1  # ë„ˆë¬´ ì§§ìŒ
        elif 100 <= length <= 500:
            return 0.1   # ì ì ˆí•œ ê¸¸ì´
        elif 500 < length <= 1000:
            return 0.05  # ê¸´ í¸
        else:
            return 0.0   # ë§¤ìš° ê¸º

    def _detect_language(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€"""
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))

        total_chars = korean_chars + english_chars
        if total_chars == 0:
            return "unknown"

        korean_ratio = korean_chars / total_chars

        if korean_ratio > 0.5:
            return "korean"
        elif korean_ratio < 0.1:
            return "english"
        else:
            return "mixed"

    # --------------------------------------------------------------
    # Existing methods (unchanged)
    # --------------------------------------------------------------
    def _compose_params(self, prompt: str, settings: Dict[str, Any]):
        """ê¸°ì¡´ ë§¤ê°œë³€ìˆ˜ êµ¬ì„± (í•˜ìœ„ í˜¸í™˜ì„±)"""
        return self._compose_enhanced_params(prompt, settings)

    def _handle_error(self, error_msg: str, model: str, placeholder):
        from frontend.ui.utils.error_handler import error_handler, GTRagError, ErrorType, ErrorSeverity

        placeholder.empty()

        # ì—ëŸ¬ ë©”ì‹œì§€ë¡œë¶€í„° Exception ê°ì²´ ìƒì„±
        try:
            # ëª¨ë¸ ê´€ë ¨ ì—ëŸ¬ì¸ì§€ í™•ì¸
            if "model" in error_msg.lower() or model:
                error_exception = GTRagError(
                    f"ëª¨ë¸ '{model}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {error_msg}",
                    error_type=ErrorType.MODEL_CONFIG,
                    severity=ErrorSeverity.MEDIUM,
                    suggestions=[
                        "ì„¤ì • í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ë‹¤ì‹œ ì„ íƒí•˜ì„¸ìš”",
                        "Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”",
                        "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”"
                    ]
                )
            else:
                # ì¼ë°˜ì ì¸ API ì˜¤ë¥˜
                error_exception = Exception(error_msg)

            # í†µí•© ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì‚¬ìš©
            error_handler.handle_error(error_exception, f"ëª¨ë¸ '{model}' API í˜¸ì¶œ")

        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ í‘œì‹œ
            st.error(f"âŒ ì˜¤ë¥˜: {error_msg}")
            if model:
                st.info(f"ì‚¬ìš©ëœ ëª¨ë¸: {model}")
            st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")