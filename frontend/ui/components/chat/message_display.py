"""Functions responsible solely for rendering messageâ€‘related UI bits."""
from __future__ import annotations

from typing import Dict, List, Any, Optional
import streamlit as st
import re
from datetime import datetime

from frontend.ui.core.config import Constants, config

try:
    from frontend.ui.utils.file_utils import FileNameCleaner  # type: ignore
    HAS_FILE_UTILS = True
except ImportError:
    HAS_FILE_UTILS = False

# ğŸš€ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì ìš©
try:
    from .reference_system import reference_system

    HAS_REFERENCE_SYSTEM = True
except ImportError:
    reference_system = None
    HAS_REFERENCE_SYSTEM = False


__all__ = ["render_sources"]


def _calculate_confidence_score(source: Dict) -> float:
    """ê·¼ê±° ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° - ìˆ˜ì •ëœ ë²„ì „"""
    base_score = source.get("score", 0.0)
    content = source.get("content", "")
    content_length = len(content)

    # ğŸ”§ ë¡œê¹… ì œê±° (ì˜¤ë¥˜ ë°©ì§€)
    # ë””ë²„ê¹…ì´ í•„ìš”í•œ ê²½ìš° print ì‚¬ìš© ë˜ëŠ” ë³„ë„ ë°©ë²• í™œìš©

    # ê¸°ë³¸ ì ìˆ˜ê°€ ì´ë¯¸ 1.0 ì´ìƒì´ë©´ ì •ê·œí™”
    if base_score >= 1.0:
        confidence = base_score / max(base_score, 1.2)  # ìµœëŒ€ ê¸°ì¤€ì ìœ¼ë¡œ ì •ê·œí™”
    else:
        confidence = base_score

    # ë³´ì • íŒ©í„°ë“¤ (ê³±ì…ˆ ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
    length_factor = 1.0
    if 100 <= content_length <= 1000:
        length_factor = 1.05  # 5% ì¦ê°€
    elif content_length > 1000:
        length_factor = 1.02  # 2% ì¦ê°€
    elif content_length < 50:
        length_factor = 0.9  # 10% ê°ì†Œ

    # ë©”íƒ€ë°ì´í„° í’ˆì§ˆ íŒ©í„°
    metadata_factor = 1.0
    metadata = source.get("metadata", {})
    if metadata.get("title"):
        metadata_factor *= 1.03  # 3% ì¦ê°€
    if metadata.get("section"):
        metadata_factor *= 1.02  # 2% ì¦ê°€

    # ìµœì¢… ê³„ì‚° (ê³±ì…ˆ ë°©ì‹)
    final_confidence = confidence * length_factor * metadata_factor

    # ìƒí•œì„  ì ìš© (0.95ë¡œ ì œí•œí•˜ì—¬ 100% ë°©ì§€)
    result = min(final_confidence, 0.95)

    return result


def _get_confidence_color(confidence: float) -> str:
    """ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
    if confidence >= 0.8:
        return "#22c55e"  # green
    elif confidence >= 0.6:
        return "#f59e0b"  # amber
    elif confidence >= 0.4:
        return "#ef4444"  # red
    else:
        return "#6b7280"  # gray


def _get_confidence_emoji(confidence: float) -> str:
    """ì‹ ë¢°ë„ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    if confidence >= 0.8:
        return "ğŸŸ¢"
    elif confidence >= 0.6:
        return "ğŸŸ¡"
    elif confidence >= 0.4:
        return "ğŸ”´"
    else:
        return "âšª"


def _extract_citation_snippet(content: str, max_length: int = 150) -> str:
    """ì¸ìš©í•  í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œ"""
    if not content:
        return ""

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'[.!?]\s+', content.strip())

    # ê°€ì¥ ì ì ˆí•œ ë¬¸ì¥ ì„ íƒ (ì¤‘ê°„ ê¸¸ì´ì˜ ì²« ë²ˆì§¸ ë¬¸ì¥)
    best_sentence = ""
    for sentence in sentences:
        if 20 <= len(sentence) <= max_length:
            best_sentence = sentence
            break

    # ì ì ˆí•œ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë¬¸ì¥ ì‚¬ìš©
    if not best_sentence and sentences:
        best_sentence = sentences[0]

    # ê¸¸ì´ ì œí•œ
    if len(best_sentence) > max_length:
        best_sentence = best_sentence[:max_length-3] + "..."

    return best_sentence.strip()


def _highlight_keywords(text: str, keywords: List[str]) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŒ…"""
    if not keywords:
        return text

    highlighted = text
    for keyword in keywords:
        if len(keyword) >= 2:
            # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  í•˜ì´ë¼ì´íŒ…
            pattern = re.compile(re.escape(keyword), re.IGNORECASE)
            highlighted = pattern.sub(
                lambda m: f"**{m.group()}**",
                highlighted
            )

    return highlighted


def _render_confidence_bar(confidence: float) -> None:
    """ì‹ ë¢°ë„ ì§„í–‰ë¥  ë°” ë Œë”ë§"""
    color = _get_confidence_color(confidence)
    percentage = int(confidence * 100)

    st.markdown(f"""
    <div style="background-color: #e5e5e5; border-radius: 10px; height: 8px; margin: 5px 0;">
        <div style="background-color: {color}; width: {percentage}%; height: 100%; 
                    border-radius: 10px; transition: width 0.3s ease;"></div>
    </div>
    <small style="color: {color}; font-weight: bold;">ì‹ ë¢°ë„: {percentage}%</small>
    """, unsafe_allow_html=True)


def _render_source_metadata(metadata: Dict, confidence: float) -> None:
    """ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„° í‘œì‹œ"""
    if not metadata:
        return

    cols = st.columns([1, 1, 1])

    with cols[0]:
        if title := metadata.get("title"):
            st.caption(f"ğŸ“„ **ì œëª©:** {title}")

    with cols[1]:
        if section := metadata.get("section"):
            st.caption(f"ğŸ“ **ì„¹ì…˜:** {section}")

    with cols[2]:
        if page := metadata.get("page"):
            st.caption(f"ğŸ“ƒ **í˜ì´ì§€:** {page}")

    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    if author := metadata.get("author"):
        st.caption(f"âœï¸ **ì‘ì„±ì:** {author}")

    if created_date := metadata.get("created_date"):
        st.caption(f"ğŸ“… **ì‘ì„±ì¼:** {created_date}")


def _render_source_actions(source: Dict, idx: int) -> None:
    """ì†ŒìŠ¤ë³„ ì•¡ì…˜ ë²„íŠ¼"""
    cols = st.columns([1, 1, 1, 2])

    with cols[0]:
        if st.button("ğŸ“‹ ë³µì‚¬", key=f"copy_{idx}", help="ë‚´ìš© ë³µì‚¬"):
            st.code(source.get("content", ""), language=None)

    with cols[1]:
        if st.button("ğŸ” ìƒì„¸", key=f"detail_{idx}", help="ìƒì„¸ ì •ë³´"):
            with st.expander("ìƒì„¸ ì •ë³´", expanded=True):
                st.json(source)

    with cols[2]:
        if st.button("ğŸ“¤ ì¸ìš©", key=f"cite_{idx}", help="ì¸ìš© í˜•ì‹"):
            citation = _generate_citation(source, idx)
            st.code(citation, language="text")


def _generate_citation(source: Dict, idx: int) -> str:
    """ì¸ìš© í˜•ì‹ ìƒì„±"""
    name = source.get("source", "Unknown")
    if HAS_FILE_UTILS:
        name = FileNameCleaner.clean_display_name(name)

    score = source.get("score", 0.0)
    content_snippet = _extract_citation_snippet(source.get("content", ""), 100)

    citation = f"[{idx}] {name} (ìœ ì‚¬ë„: {score:.3f})\n"
    citation += f"\"...{content_snippet}...\"\n"
    citation += f"ì°¸ì¡°ì¼: {datetime.now().strftime('%Y-%m-%d')}"

    return citation


def render_sources(sources: List[Dict], search_info: Optional[Dict] = None):
    """ìµœì í™”ëœ ê·¼ê±° í‘œì‹œ í•¨ìˆ˜ - ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì§€ì›"""
    if not sources:
        return

    # ğŸš€ ìƒˆë¡œìš´ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì‚¬ìš©
    if HAS_REFERENCE_SYSTEM and reference_system:
        # ê²€ìƒ‰ ì •ë³´ í‘œì‹œ
        if search_info:
            _render_search_summary(search_info)

        # ê·¼ê±° ì²˜ë¦¬ ë° í•„í„°ë§
        processed_sources = []
        for source in sources:
            confidence = _calculate_confidence_score(source)
            processed_sources.append({
                **source,
                "confidence": confidence,
                "citation_snippet": _extract_citation_snippet(source.get("content", ""))
            })

        # ğŸš€ í–¥ìƒëœ ê·¼ê±° í‘œì‹œ (ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ í¬í•¨)
        with st.expander(
                f"{Constants.Icons.DOCUMENT} **ì°¸ì¡° ê·¼ê±°** ({len(processed_sources)}ê°œ) - í´ë¦­í•˜ì—¬ ë³¸ë¬¸ ì°¸ì¡° í™•ì¸",
                expanded=False
        ):
            # ì‚¬ìš©ë²• ì•ˆë‚´
            st.info("ğŸ’¡ **ì‚¬ìš©ë²•**: ë³¸ë¬¸ì˜ [ìˆ«ì] í´ë¦­ â†’ í•´ë‹¹ ê·¼ê±°ë¡œ ì´ë™ | ê·¼ê±°ì˜ â†‘ ë²„íŠ¼ í´ë¦­ â†’ ë³¸ë¬¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° | Ctrl+ìˆ«ìí‚¤ë¡œ ë¹ ë¥¸ ì´ë™")

            # ê·¼ê±° ìš”ì•½ ì •ë³´
            avg_confidence = sum(s["confidence"] for s in processed_sources) / len(processed_sources)
            max_confidence = max(s["confidence"] for s in processed_sources)

            st.markdown(f"""
            **ğŸ“Š ê·¼ê±° í’ˆì§ˆ ìš”ì•½**
            - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%} | ìµœê³  ì‹ ë¢°ë„: {max_confidence:.1%}
            - í•„í„°ë§ëœ ê·¼ê±°: {len(processed_sources)}/{len(sources)}ê°œ
            """)

            st.divider()

            # ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œìœ¼ë¡œ ë Œë”ë§
            reference_system.render_enhanced_sources(processed_sources, search_info)

        return

    # ğŸ”§ í´ë°±: ê¸°ì¡´ ì‹œìŠ¤í…œ (ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì—†ì„ ë•Œ)
    _render_sources_fallback(sources, search_info)


def _render_sources_fallback(sources: List[Dict], search_info: Optional[Dict] = None):
    """ê¸°ì¡´ ê·¼ê±° í‘œì‹œ ì‹œìŠ¤í…œ (í´ë°±) - Settings ì—°ë™ ë²„ì „"""
    # ê²€ìƒ‰ ì •ë³´ í‘œì‹œ
    if search_info:
        _render_search_summary(search_info)

    # ğŸš€ Settingsì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì´ë“œë°” ìŠ¬ë¼ì´ë” ëŒ€ì‹ )
    try:
        from frontend.ui.core.config import Constants

        # Settings í˜ì´ì§€ ì„¤ì •ê°’ ì‚¬ìš©
        confidence_threshold = (
                st.session_state.get('temp_min_similarity') or  # ì„ì‹œ ì¡°ì •ê°’ ìš°ì„ 
                st.session_state.get('min_similarity') or  # ì„¸ì…˜ ì„¤ì •ê°’
                st.session_state.get('backend_min_similarity') or  # ë°±ì—”ë“œ ì„¤ì •ê°’
                Constants.Defaults.MIN_SIMILARITY  # ê¸°ë³¸ê°’
        )

        # ì •ë ¬ ì˜µì…˜ë„ Settingsì—ì„œ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: ì‹ ë¢°ë„ ìˆœ)
        sort_option = st.session_state.get('source_sort_option', "ì‹ ë¢°ë„ ìˆœ")

    except ImportError:
        # configë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        confidence_threshold = 0.3
        sort_option = "ì‹ ë¢°ë„ ìˆœ"

    # ğŸ¯ ì„¤ì • ì•ˆë‚´ ë° ì œì–´ íŒ¨ë„ (ê°„ë‹¨ ë²„ì „)
    with st.container():
        st.markdown("---")
        st.markdown("#### ğŸ”§ ê·¼ê±° í•„í„°ë§ ì„¤ì • 3")

        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            st.info("ğŸ’¡ **Settings í˜ì´ì§€**ì—ì„œ ê¸°ë³¸ í•„í„°ë§ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # í˜„ì¬ ì ìš© ì¤‘ì¸ ì„¤ì • í‘œì‹œ
            st.caption(f"í˜„ì¬ ìµœì†Œ ìœ ì‚¬ë„: **{confidence_threshold:.2f}** | ì •ë ¬: **{sort_option}**")

        with col2:
            # ì„ì‹œ ì¡°ì • ì˜µì…˜
            if st.button("ğŸ›ï¸ ì„ì‹œ ì¡°ì •", key="fallback_temp_adjust", help="í˜„ì¬ ì„¸ì…˜ì—ë§Œ ì ìš©ë˜ëŠ” ì„ì‹œ ì¡°ì •"):
                st.session_state.show_temp_controls = not st.session_state.get('show_temp_controls', False)

        with col3:
            # Settings í˜ì´ì§€ë¡œ ì´ë™
            if st.button("âš™ï¸ Settings", key="fallback_goto_settings", help="ì˜êµ¬ ì„¤ì • ë³€ê²½"):
                st.switch_page("pages/99_Settings.py")

        # ì„ì‹œ ì¡°ì • ì»¨íŠ¸ë¡¤ (ì„ íƒì  í‘œì‹œ)
        if st.session_state.get('show_temp_controls', False):
            st.markdown("**ì„ì‹œ ì¡°ì • (í˜„ì¬ ì„¸ì…˜ì—ë§Œ ì ìš©)**")

            temp_col1, temp_col2 = st.columns(2)

            with temp_col1:
                temp_threshold = st.slider(
                    "ìµœì†Œ ìœ ì‚¬ë„",
                    min_value=0.0,
                    max_value=1.0,
                    value=float(confidence_threshold),
                    step=0.05,
                    key="fallback_temp_threshold",
                    help="ì´ ê°’ì€ í˜„ì¬ ì„¸ì…˜ì—ë§Œ ì ìš©ë©ë‹ˆë‹¤"
                )

                # ì„¸ì…˜ì— ì„ì‹œê°’ ì €ì¥
                st.session_state.temp_min_similarity = temp_threshold
                confidence_threshold = temp_threshold

            with temp_col2:
                temp_sort = st.selectbox(
                    "ì •ë ¬ ë°©ì‹",
                    ["ì‹ ë¢°ë„ ìˆœ", "ìœ ì‚¬ë„ ìˆœ", "ê¸¸ì´ ìˆœ"],
                    index=["ì‹ ë¢°ë„ ìˆœ", "ìœ ì‚¬ë„ ìˆœ", "ê¸¸ì´ ìˆœ"].index(sort_option),
                    key="fallback_temp_sort"
                )

                # ì„¸ì…˜ì— ì„ì‹œê°’ ì €ì¥
                st.session_state.source_sort_option = temp_sort
                sort_option = temp_sort

            # ë¦¬ì…‹ ë²„íŠ¼
            if st.button("ğŸ”„ ê¸°ë³¸ê°’ ë³µì›", key="fallback_reset_temp"):
                for key in ['temp_min_similarity', 'source_sort_option', 'show_temp_controls']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()

    # ê·¼ê±° ì²˜ë¦¬ ë° í•„í„°ë§
    processed_sources = []
    for source in sources:
        confidence = _calculate_confidence_score(source)
        if confidence >= confidence_threshold:
            processed_sources.append({
                **source,
                "confidence": confidence,
                "citation_snippet": _extract_citation_snippet(source.get("content", ""))
            })

    # ì •ë ¬ ì ìš©
    if sort_option == "ì‹ ë¢°ë„ ìˆœ":
        processed_sources.sort(key=lambda x: x["confidence"], reverse=True)
    elif sort_option == "ìœ ì‚¬ë„ ìˆœ":
        processed_sources.sort(key=lambda x: x.get("score", 0), reverse=True)
    elif sort_option == "ê¸¸ì´ ìˆœ":
        processed_sources.sort(key=lambda x: len(x.get("content", "")), reverse=True)

    # í•„í„°ë§ ê²°ê³¼ í™•ì¸
    if not processed_sources:
        st.warning(f"âš ï¸ ì‹ ë¢°ë„ {confidence_threshold:.1f} ì´ìƒì˜ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ ì„ì‹œ ì¡°ì •ì—ì„œ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ê±°ë‚˜ Settingsì—ì„œ ê¸°ë³¸ê°’ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
        return

    # ë©”ì¸ ê·¼ê±° í‘œì‹œ
    with st.expander(
            f"{Constants.Icons.DOCUMENT} **ì°¸ì¡° ê·¼ê±°** ({len(processed_sources)}ê°œ/{len(sources)}ê°œ í‘œì‹œ)",
            expanded=True
    ):
        # ê·¼ê±° ìš”ì•½ ì •ë³´
        avg_confidence = sum(s["confidence"] for s in processed_sources) / len(processed_sources)
        max_confidence = max(s["confidence"] for s in processed_sources)

        # í•„í„°ë§ í†µê³„
        filtered_count = len(sources) - len(processed_sources)
        filter_rate = (len(processed_sources) / len(sources)) * 100 if sources else 0

        st.markdown(f"""
        **ğŸ“Š ê·¼ê±° í’ˆì§ˆ ìš”ì•½**
        - í‰ê·  ì‹ ë¢°ë„: **{avg_confidence:.1%}** | ìµœê³  ì‹ ë¢°ë„: **{max_confidence:.1%}**
        - í‘œì‹œ ë¹„ìœ¨: **{filter_rate:.1f}%** ({len(processed_sources)}/{len(sources)}ê°œ)
        - ì •ë ¬ ë°©ì‹: **{sort_option}** | ì„ê³„ê°’: **{confidence_threshold:.2f}**
        """)

        if filtered_count > 0:
            st.info(f"ğŸ“‹ {filtered_count}ê°œ ê·¼ê±°ê°€ ì„ê³„ê°’({confidence_threshold:.2f}) ë¯¸ë§Œìœ¼ë¡œ ìˆ¨ê²¨ì¡ŒìŠµë‹ˆë‹¤.")

        st.divider()

        # ê°œë³„ ê·¼ê±° í‘œì‹œ
        for idx, source in enumerate(processed_sources, 1):
            _render_individual_source_enhanced(source, idx)

            if idx < len(processed_sources):
                st.divider()


def _render_individual_source_enhanced(source: Dict, idx: int) -> None:
    """ê°œë³„ ê·¼ê±° í•­ëª© ë Œë”ë§ - í–¥ìƒëœ ë²„ì „"""
    score = source.get("score", 0)
    confidence = source.get("confidence", 0)
    raw_name = source.get("source", "Unknown")
    name = FileNameCleaner.clean_display_name(raw_name) if HAS_FILE_UTILS else raw_name
    content = source.get("content", "")
    citation_snippet = source.get("citation_snippet", "")

    # ğŸ¯ ê°œì„ ëœ í—¤ë” ì„¹ì…˜
    header_cols = st.columns([0.08, 0.02, 0.6, 0.3])

    with header_cols[0]:
        st.markdown(f"### {_get_confidence_emoji(confidence)}")

    with header_cols[1]:
        st.markdown(f"**[{idx}]**")

    with header_cols[2]:
        st.markdown(f"**{name}**")
        st.caption(f"ìœ ì‚¬ë„: {score:.3f} | ê¸¸ì´: {len(content):,}ì")

    with header_cols[3]:
        _render_confidence_bar(confidence)

    # ì¸ìš©ë¬¸ í•˜ì´ë¼ì´íŒ… (ê°œì„ ëœ ë²„ì „)
    if citation_snippet:
        highlighted_snippet = _highlight_keywords(
            citation_snippet,
            source.get("keywords", [])
        )
        st.markdown(f"ğŸ’¬ **í•µì‹¬ ì¸ìš©:** _{highlighted_snippet}_")

    # ë©”íƒ€ë°ì´í„° í‘œì‹œ
    _render_source_metadata(source.get("metadata", {}), confidence)

    # ğŸš€ í–¥ìƒëœ ë‚´ìš© í‘œì‹œ (ê³ ìœ  í‚¤ ë³´ì¥)
    import time
    unique_suffix = f"{idx}_{int(time.time() * 1000000) % 1000000}"

    # íƒ­ ê¸°ë°˜ ë‚´ìš© í‘œì‹œ
    if len(content) > 300:
        tab1, tab2, tab3 = st.tabs(["ğŸ“„ ìš”ì•½", "ğŸ“– ì „ì²´ ë‚´ìš©", "ğŸ”§ ì•¡ì…˜"])

        with tab1:
            # ìš”ì•½ëœ ë‚´ìš© (ì²˜ìŒ 300ì)
            preview_content = content[:300]
            if len(content) > 300:
                preview_content += "..."

            highlighted_preview = _highlight_keywords(
                preview_content,
                source.get("keywords", [])
            )
            st.markdown(highlighted_preview)

            # ì½ê¸° ê³„ì† ë²„íŠ¼
            if st.button("ğŸ“– ì „ì²´ ë‚´ìš© ë³´ê¸°", key=f"read_more_{unique_suffix}"):
                st.info("â†’ **ğŸ“– ì „ì²´ ë‚´ìš©** íƒ­ì„ í´ë¦­í•˜ì„¸ìš”")

        with tab2:
            # ë©”íƒ€ë°ì´í„° (ìƒë‹¨)
            meta_col1, meta_col2, meta_col3 = st.columns(3)

            with meta_col1:
                st.caption(f"**ìœ ì‚¬ë„:** {score:.3f}")
            with meta_col2:
                st.caption(f"**ì‹ ë¢°ë„:** {confidence:.1%}")
            with meta_col3:
                st.caption(f"**ê¸¸ì´:** {len(content):,}ì")

            st.divider()

            # ì „ì²´ ë‚´ìš© (ì½ê¸° ì „ìš©)
            st.markdown("**ğŸ“„ ì „ì²´ ë‚´ìš©**")
            st.text_area(
                "ì „ì²´ ë‚´ìš©",
                content,
                height=200,
                key=f"content_full_{unique_suffix}",
                help="ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                disabled=True,
                label_visibility="collapsed"
            )

        with tab3:
            # ì•¡ì…˜ ë²„íŠ¼ë“¤
            _render_source_actions(source, idx)

    else:
        # ì§§ì€ ë‚´ìš©ì˜ ê²½ìš° ë‹¨ìˆœ í‘œì‹œ
        tab1, tab2 = st.tabs(["ğŸ“„ ë‚´ìš©", "ğŸ”§ ì•¡ì…˜"])

        with tab1:
            highlighted_content = _highlight_keywords(
                content,
                source.get("keywords", [])
            )
            st.markdown(highlighted_content)
            st.success("âœ… ì „ì²´ ë‚´ìš©ì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.")

        with tab2:
            _render_source_actions(source, idx)


def _render_search_summary(search_info: Dict) -> None:
    """ê²€ìƒ‰ ìš”ì•½ ì •ë³´ í‘œì‹œ - expander ì¤‘ì²© ë¬¸ì œ í•´ê²°"""
    if not search_info:
        return

    # ğŸ”§ expander ëŒ€ì‹  ì¼ë°˜ ì»¨í…Œì´ë„ˆ ì‚¬ìš© (ì¤‘ì²© ë¬¸ì œ í•´ê²°)
    st.markdown("#### ğŸ” ê²€ìƒ‰ ì •ë³´")

    cols = st.columns([1, 1, 1, 1])

    with cols[0]:
        st.metric("ê²€ìƒ‰ ì‹œê°„", f"{search_info.get('search_time', 0):.2f}ì´ˆ")

    with cols[1]:
        st.metric("ê²€ìƒ‰ ë°©ì‹", search_info.get('search_type', 'hybrid'))

    with cols[2]:
        st.metric("ì´ í›„ë³´", f"{search_info.get('total_candidates', 0)}ê°œ")

    with cols[3]:
        st.metric("í•„í„°ë§ë¨", f"{search_info.get('filtered_count', 0)}ê°œ")

    st.divider()


def _render_individual_source(source: Dict, idx: int) -> None:
    """ê°œë³„ ê·¼ê±° í•­ëª© ë Œë”ë§"""
    score = source.get("score", 0)
    confidence = source.get("confidence", 0)
    raw_name = source.get("source", "Unknown")
    name = FileNameCleaner.clean_display_name(raw_name) if HAS_FILE_UTILS else raw_name
    content = source.get("content", "")
    citation_snippet = source.get("citation_snippet", "")

    # í—¤ë” ì„¹ì…˜
    header_cols = st.columns([0.1, 0.6, 0.3])

    with header_cols[0]:
        st.markdown(f"### {_get_confidence_emoji(confidence)}")

    with header_cols[1]:
        st.markdown(f"**[ê·¼ê±° {idx}] {name}**")
        st.caption(f"ìœ ì‚¬ë„: {score:.3f} | ê¸¸ì´: {len(content):,}ì")

    with header_cols[2]:
        _render_confidence_bar(confidence)

    # ì¸ìš©ë¬¸ í•˜ì´ë¼ì´íŒ…
    if citation_snippet:
        highlighted_snippet = _highlight_keywords(
            citation_snippet,
            source.get("keywords", [])
        )
        st.markdown(f"ğŸ’¬ **í•µì‹¬ ì¸ìš©:** _{highlighted_snippet}_")

    # ë©”íƒ€ë°ì´í„° í‘œì‹œ
    _render_source_metadata(source.get("metadata", {}), confidence)

    # ë‚´ìš© í‘œì‹œ
    content_tabs = st.tabs(["ğŸ“„ ìš”ì•½", "ğŸ“– ì „ì²´ ë‚´ìš©", "ğŸ”§ ì•¡ì…˜"])

    with content_tabs[0]:
        # ìš”ì•½ëœ ë‚´ìš© (ì²˜ìŒ 300ì)
        preview_len = min(300, len(content))
        preview_content = content[:preview_len]
        if len(content) > preview_len:
            preview_content += "..."

        highlighted_preview = _highlight_keywords(
            preview_content,
            source.get("keywords", [])
        )
        st.markdown(highlighted_preview)

    with content_tabs[1]:
        # ì „ì²´ ë‚´ìš©
        if len(content) > 500:
            st.text_area(
                "ì „ì²´ ë‚´ìš©",
                content,
                height=200,
                key=f"content_full_{idx}",
                help="ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
        else:
            highlighted_full = _highlight_keywords(
                content,
                source.get("keywords", [])
            )
            st.markdown(highlighted_full)

    with content_tabs[2]:
        # ì•¡ì…˜ ë²„íŠ¼ë“¤
        _render_source_actions(source, idx)


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def calculate_overall_confidence(sources: List[Dict]) -> float:
    """ì „ì²´ ê·¼ê±°ì˜ ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°"""
    if not sources:
        return 0.0

    # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ìƒìœ„ ê·¼ê±°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
    total_weight = 0
    weighted_sum = 0

    for i, source in enumerate(sources[:5]):  # ìƒìœ„ 5ê°œë§Œ ê³ ë ¤
        confidence = _calculate_confidence_score(source)
        weight = 1.0 / (i + 1)  # ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜

        weighted_sum += confidence * weight
        total_weight += weight

    return weighted_sum / total_weight if total_weight > 0 else 0.0


def get_source_quality_grade(confidence: float) -> str:
    """ê·¼ê±° í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
    if confidence >= 0.9:
        return "A+ (ë§¤ìš° ë†’ìŒ)"
    elif confidence >= 0.8:
        return "A (ë†’ìŒ)"
    elif confidence >= 0.7:
        return "B+ (ì–‘í˜¸)"
    elif confidence >= 0.6:
        return "B (ë³´í†µ)"
    elif confidence >= 0.5:
        return "C+ (ë‚®ìŒ)"
    elif confidence >= 0.4:
        return "C (ë§¤ìš° ë‚®ìŒ)"
    else:
        return "D (ë¶€ì ì ˆ)"


def filter_sources_by_quality(sources: List[Dict], min_confidence: float = 0.5) -> List[Dict]:
    """í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ê·¼ê±° í•„í„°ë§"""
    filtered = []
    for source in sources:
        confidence = _calculate_confidence_score(source)
        if confidence >= min_confidence:
            filtered.append({**source, "confidence": confidence})

    return sorted(filtered, key=lambda x: x["confidence"], reverse=True)