"""Functions responsible solely for rendering messageâ€‘related UI bits."""
from __future__ import annotations

from typing import Dict, List, Any, Optional
import streamlit as st
import re
from datetime import datetime

from frontend.ui.core.config import Constants, config

try:
    from frontend.ui.utils.file_utils import FileNameCleaner  # type: ignore
    HAS_FILE_UTILS = True
except ImportError:
    HAS_FILE_UTILS = False

# ğŸš€ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì ìš©
try:
    from .reference_system import reference_system

    HAS_REFERENCE_SYSTEM = True
except ImportError:
    reference_system = None
    HAS_REFERENCE_SYSTEM = False


__all__ = ["render_sources"]


def _calculate_confidence_score(source: Dict) -> float:
    """ê·¼ê±° ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° - ìˆ˜ì •ëœ ë²„ì „"""
    base_score = source.get("score", 0.0)
    content = source.get("content", "")
    content_length = len(content)

    # ğŸ”§ ë¡œê¹… ì œê±° (ì˜¤ë¥˜ ë°©ì§€)
    # ë””ë²„ê¹…ì´ í•„ìš”í•œ ê²½ìš° print ì‚¬ìš© ë˜ëŠ” ë³„ë„ ë°©ë²• í™œìš©

    # ê¸°ë³¸ ì ìˆ˜ê°€ ì´ë¯¸ 1.0 ì´ìƒì´ë©´ ì •ê·œí™”
    if base_score >= 1.0:
        confidence = base_score / max(base_score, 1.2)  # ìµœëŒ€ ê¸°ì¤€ì ìœ¼ë¡œ ì •ê·œí™”
    else:
        confidence = base_score

    # ë³´ì • íŒ©í„°ë“¤ (ê³±ì…ˆ ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
    length_factor = 1.0
    if 100 <= content_length <= 1000:
        length_factor = 1.05  # 5% ì¦ê°€
    elif content_length > 1000:
        length_factor = 1.02  # 2% ì¦ê°€
    elif content_length < 50:
        length_factor = 0.9  # 10% ê°ì†Œ

    # ë©”íƒ€ë°ì´í„° í’ˆì§ˆ íŒ©í„°
    metadata_factor = 1.0
    metadata = source.get("metadata", {})
    if metadata.get("title"):
        metadata_factor *= 1.03  # 3% ì¦ê°€
    if metadata.get("section"):
        metadata_factor *= 1.02  # 2% ì¦ê°€

    # ìµœì¢… ê³„ì‚° (ê³±ì…ˆ ë°©ì‹)
    final_confidence = confidence * length_factor * metadata_factor

    # ìƒí•œì„  ì ìš© (0.95ë¡œ ì œí•œí•˜ì—¬ 100% ë°©ì§€)
    result = min(final_confidence, 0.95)

    return result


def _get_confidence_color(confidence: float) -> str:
    """ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
    if confidence >= 0.8:
        return "#22c55e"  # green
    elif confidence >= 0.6:
        return "#f59e0b"  # amber
    elif confidence >= 0.4:
        return "#ef4444"  # red
    else:
        return "#6b7280"  # gray


def _get_confidence_emoji(confidence: float) -> str:
    """ì‹ ë¢°ë„ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    if confidence >= 0.8:
        return "ğŸŸ¢"
    elif confidence >= 0.6:
        return "ğŸŸ¡"
    elif confidence >= 0.4:
        return "ğŸ”´"
    else:
        return "âšª"


def _extract_citation_snippet(content: str, max_length: int = 150) -> str:
    """ì¸ìš©í•  í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œ"""
    if not content:
        return ""

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'[.!?]\s+', content.strip())

    # ê°€ì¥ ì ì ˆí•œ ë¬¸ì¥ ì„ íƒ (ì¤‘ê°„ ê¸¸ì´ì˜ ì²« ë²ˆì§¸ ë¬¸ì¥)
    best_sentence = ""
    for sentence in sentences:
        if 20 <= len(sentence) <= max_length:
            best_sentence = sentence
            break

    # ì ì ˆí•œ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë¬¸ì¥ ì‚¬ìš©
    if not best_sentence and sentences:
        best_sentence = sentences[0]

    # ê¸¸ì´ ì œí•œ
    if len(best_sentence) > max_length:
        best_sentence = best_sentence[:max_length-3] + "..."

    return best_sentence.strip()


def _highlight_keywords(text: str, keywords: List[str]) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŒ…"""
    if not keywords:
        return text

    highlighted = text
    for keyword in keywords:
        if len(keyword) >= 2:
            # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  í•˜ì´ë¼ì´íŒ…
            pattern = re.compile(re.escape(keyword), re.IGNORECASE)
            highlighted = pattern.sub(
                lambda m: f"**{m.group()}**",
                highlighted
            )

    return highlighted


def _render_confidence_bar(confidence: float) -> None:
    """ì‹ ë¢°ë„ ì§„í–‰ë¥  ë°” ë Œë”ë§"""
    color = _get_confidence_color(confidence)
    percentage = int(confidence * 100)

    st.markdown(f"""
    <div style="background-color: #e5e5e5; border-radius: 10px; height: 8px; margin: 5px 0;">
        <div style="background-color: {color}; width: {percentage}%; height: 100%; 
                    border-radius: 10px; transition: width 0.3s ease;"></div>
    </div>
    <small style="color: {color}; font-weight: bold;">ì‹ ë¢°ë„: {percentage}%</small>
    """, unsafe_allow_html=True)


def _render_source_metadata(metadata: Dict, confidence: float) -> None:
    """ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„° í‘œì‹œ"""
    if not metadata:
        return

    cols = st.columns([1, 1, 1])

    with cols[0]:
        if title := metadata.get("title"):
            st.caption(f"ğŸ“„ **ì œëª©:** {title}")

    with cols[1]:
        if section := metadata.get("section"):
            st.caption(f"ğŸ“ **ì„¹ì…˜:** {section}")

    with cols[2]:
        if page := metadata.get("page"):
            st.caption(f"ğŸ“ƒ **í˜ì´ì§€:** {page}")

    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    if author := metadata.get("author"):
        st.caption(f"âœï¸ **ì‘ì„±ì:** {author}")

    if created_date := metadata.get("created_date"):
        st.caption(f"ğŸ“… **ì‘ì„±ì¼:** {created_date}")


def _render_source_actions(source: Dict, idx: int) -> None:
    """ì†ŒìŠ¤ë³„ ì•¡ì…˜ ë²„íŠ¼"""
    cols = st.columns([1, 1, 1, 2])

    with cols[0]:
        if st.button("ğŸ“‹ ë³µì‚¬", key=f"copy_{idx}", help="ë‚´ìš© ë³µì‚¬"):
            st.code(source.get("content", ""), language=None)

    with cols[1]:
        if st.button("ğŸ” ìƒì„¸", key=f"detail_{idx}", help="ìƒì„¸ ì •ë³´"):
            with st.expander("ìƒì„¸ ì •ë³´", expanded=True):
                st.json(source)

    with cols[2]:
        if st.button("ğŸ“¤ ì¸ìš©", key=f"cite_{idx}", help="ì¸ìš© í˜•ì‹"):
            citation = _generate_citation(source, idx)
            st.code(citation, language="text")


def _generate_citation(source: Dict, idx: int) -> str:
    """ì¸ìš© í˜•ì‹ ìƒì„±"""
    name = source.get("source", "Unknown")
    if HAS_FILE_UTILS:
        name = FileNameCleaner.clean_display_name(name)

    score = source.get("score", 0.0)
    content_snippet = _extract_citation_snippet(source.get("content", ""), 100)

    citation = f"[{idx}] {name} (ìœ ì‚¬ë„: {score:.3f})\n"
    citation += f"\"...{content_snippet}...\"\n"
    citation += f"ì°¸ì¡°ì¼: {datetime.now().strftime('%Y-%m-%d')}"

    return citation


def render_sources(sources: List[Dict], search_info: Optional[Dict] = None):
    """ìµœì í™”ëœ ê·¼ê±° í‘œì‹œ í•¨ìˆ˜ - ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì§€ì›"""
    if not sources:
        return

    # ğŸš€ ìƒˆë¡œìš´ ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì‚¬ìš©
    if HAS_REFERENCE_SYSTEM and reference_system:
        # ê²€ìƒ‰ ì •ë³´ í‘œì‹œ
        if search_info:
            _render_search_summary(search_info)

        # ê·¼ê±° í’ˆì§ˆ í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        confidence_threshold = st.sidebar.slider(
            "ğŸ¯ ê·¼ê±° ì‹ ë¢°ë„ ìµœì†Œê°’",
            0.0, 1.0, 0.3, 0.1,
            help="ì´ ê°’ ì´ìƒì˜ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê·¼ê±°ë§Œ í‘œì‹œ"
        )

        # ì •ë ¬ ì˜µì…˜
        sort_option = st.sidebar.selectbox(
            "ğŸ“Š ì •ë ¬ ë°©ì‹",
            ["ì‹ ë¢°ë„ ìˆœ", "ìœ ì‚¬ë„ ìˆœ", "ê¸¸ì´ ìˆœ"],
            help="ê·¼ê±° í‘œì‹œ ìˆœì„œ"
        )

        # ê·¼ê±° ì²˜ë¦¬ ë° í•„í„°ë§
        processed_sources = []
        for source in sources:
            confidence = _calculate_confidence_score(source)
            if confidence >= confidence_threshold:
                processed_sources.append({
                    **source,
                    "confidence": confidence,
                    "citation_snippet": _extract_citation_snippet(source.get("content", ""))
                })

        # ì •ë ¬
        if sort_option == "ì‹ ë¢°ë„ ìˆœ":
            processed_sources.sort(key=lambda x: x["confidence"], reverse=True)
        elif sort_option == "ìœ ì‚¬ë„ ìˆœ":
            processed_sources.sort(key=lambda x: x.get("score", 0), reverse=True)
        elif sort_option == "ê¸¸ì´ ìˆœ":
            processed_sources.sort(key=lambda x: len(x.get("content", "")), reverse=True)

        if not processed_sources:
            st.warning(f"âš ï¸ ì‹ ë¢°ë„ {confidence_threshold:.1f} ì´ìƒì˜ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ğŸš€ í–¥ìƒëœ ê·¼ê±° í‘œì‹œ (ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ í¬í•¨)
        with st.expander(
                f"{Constants.Icons.DOCUMENT} **ì°¸ì¡° ê·¼ê±°** ({len(processed_sources)}ê°œ) - í´ë¦­í•˜ì—¬ ë³¸ë¬¸ ì°¸ì¡° í™•ì¸",
                expanded=False
        ):
            # ì‚¬ìš©ë²• ì•ˆë‚´
            st.info("ğŸ’¡ **ì‚¬ìš©ë²•**: ë³¸ë¬¸ì˜ [ìˆ«ì] í´ë¦­ â†’ í•´ë‹¹ ê·¼ê±°ë¡œ ì´ë™ | ê·¼ê±°ì˜ â†‘ ë²„íŠ¼ í´ë¦­ â†’ ë³¸ë¬¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° | Ctrl+ìˆ«ìí‚¤ë¡œ ë¹ ë¥¸ ì´ë™")

            # ê·¼ê±° ìš”ì•½ ì •ë³´
            avg_confidence = sum(s["confidence"] for s in processed_sources) / len(processed_sources)
            max_confidence = max(s["confidence"] for s in processed_sources)

            st.markdown(f"""
            **ğŸ“Š ê·¼ê±° í’ˆì§ˆ ìš”ì•½**
            - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%} | ìµœê³  ì‹ ë¢°ë„: {max_confidence:.1%}
            - í•„í„°ë§ëœ ê·¼ê±°: {len(processed_sources)}/{len(sources)}ê°œ
            """)

            st.divider()

            # ì¸í„°ë™í‹°ë¸Œ ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œìœ¼ë¡œ ë Œë”ë§
            reference_system.render_enhanced_sources(processed_sources, search_info)

        return

    # ğŸ”§ í´ë°±: ê¸°ì¡´ ì‹œìŠ¤í…œ (ë ˆí¼ëŸ°ìŠ¤ ì‹œìŠ¤í…œ ì—†ì„ ë•Œ)
    _render_sources_fallback(sources, search_info)


def _render_sources_fallback(sources: List[Dict], search_info: Optional[Dict] = None):
    """ê¸°ì¡´ ê·¼ê±° í‘œì‹œ ì‹œìŠ¤í…œ (í´ë°±)"""
    # ê²€ìƒ‰ ì •ë³´ í‘œì‹œ
    if search_info:
        _render_search_summary(search_info)

    # ê·¼ê±° í’ˆì§ˆ í•„í„°ë§
    confidence_threshold = st.sidebar.slider(
        "ğŸ¯ ê·¼ê±° ì‹ ë¢°ë„ ìµœì†Œê°’",
        0.0, 1.0, 0.3, 0.1,
        help="ì´ ê°’ ì´ìƒì˜ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê·¼ê±°ë§Œ í‘œì‹œ"
    )

    # ì •ë ¬ ì˜µì…˜
    sort_option = st.sidebar.selectbox(
        "ğŸ“Š ì •ë ¬ ë°©ì‹",
        ["ì‹ ë¢°ë„ ìˆœ", "ìœ ì‚¬ë„ ìˆœ", "ê¸¸ì´ ìˆœ"],
        help="ê·¼ê±° í‘œì‹œ ìˆœì„œ"
    )

    # ê·¼ê±° ì²˜ë¦¬ ë° í•„í„°ë§
    processed_sources = []
    for source in sources:
        confidence = _calculate_confidence_score(source)
        if confidence >= confidence_threshold:
            processed_sources.append({
                **source,
                "confidence": confidence,
                "citation_snippet": _extract_citation_snippet(source.get("content", ""))
            })

    # ì •ë ¬
    if sort_option == "ì‹ ë¢°ë„ ìˆœ":
        processed_sources.sort(key=lambda x: x["confidence"], reverse=True)
    elif sort_option == "ìœ ì‚¬ë„ ìˆœ":
        processed_sources.sort(key=lambda x: x.get("score", 0), reverse=True)
    elif sort_option == "ê¸¸ì´ ìˆœ":
        processed_sources.sort(key=lambda x: len(x.get("content", "")), reverse=True)

    if not processed_sources:
        st.warning(f"âš ï¸ ì‹ ë¢°ë„ {confidence_threshold:.1f} ì´ìƒì˜ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë©”ì¸ ê·¼ê±° í‘œì‹œ (ê¸°ì¡´ ë°©ì‹)
    with st.expander(
            f"{Constants.Icons.DOCUMENT} **ì°¸ì¡° ê·¼ê±°** ({len(processed_sources)}ê°œ)",
            expanded=True
    ):
        # ê·¼ê±° ìš”ì•½ ì •ë³´
        avg_confidence = sum(s["confidence"] for s in processed_sources) / len(processed_sources)
        max_confidence = max(s["confidence"] for s in processed_sources)

        st.markdown(f"""
        **ğŸ“Š ê·¼ê±° í’ˆì§ˆ ìš”ì•½**
        - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%} | ìµœê³  ì‹ ë¢°ë„: {max_confidence:.1%}
        - í•„í„°ë§ëœ ê·¼ê±°: {len(processed_sources)}/{len(sources)}ê°œ
        """)

        st.divider()

        # ê°œë³„ ê·¼ê±° í‘œì‹œ
        for idx, source in enumerate(processed_sources, 1):
            _render_individual_source(source, idx)

            if idx < len(processed_sources):
                st.divider()


def _render_search_summary(search_info: Dict) -> None:
    """ê²€ìƒ‰ ìš”ì•½ ì •ë³´ í‘œì‹œ - expander ì¤‘ì²© ë¬¸ì œ í•´ê²°"""
    if not search_info:
        return

    # ğŸ”§ expander ëŒ€ì‹  ì¼ë°˜ ì»¨í…Œì´ë„ˆ ì‚¬ìš© (ì¤‘ì²© ë¬¸ì œ í•´ê²°)
    st.markdown("#### ğŸ” ê²€ìƒ‰ ì •ë³´")

    cols = st.columns([1, 1, 1, 1])

    with cols[0]:
        st.metric("ê²€ìƒ‰ ì‹œê°„", f"{search_info.get('search_time', 0):.2f}ì´ˆ")

    with cols[1]:
        st.metric("ê²€ìƒ‰ ë°©ì‹", search_info.get('search_type', 'hybrid'))

    with cols[2]:
        st.metric("ì´ í›„ë³´", f"{search_info.get('total_candidates', 0)}ê°œ")

    with cols[3]:
        st.metric("í•„í„°ë§ë¨", f"{search_info.get('filtered_count', 0)}ê°œ")

    st.divider()


def _render_individual_source(source: Dict, idx: int) -> None:
    """ê°œë³„ ê·¼ê±° í•­ëª© ë Œë”ë§"""
    score = source.get("score", 0)
    confidence = source.get("confidence", 0)
    raw_name = source.get("source", "Unknown")
    name = FileNameCleaner.clean_display_name(raw_name) if HAS_FILE_UTILS else raw_name
    content = source.get("content", "")
    citation_snippet = source.get("citation_snippet", "")

    # í—¤ë” ì„¹ì…˜
    header_cols = st.columns([0.1, 0.6, 0.3])

    with header_cols[0]:
        st.markdown(f"### {_get_confidence_emoji(confidence)}")

    with header_cols[1]:
        st.markdown(f"**[ê·¼ê±° {idx}] {name}**")
        st.caption(f"ìœ ì‚¬ë„: {score:.3f} | ê¸¸ì´: {len(content):,}ì")

    with header_cols[2]:
        _render_confidence_bar(confidence)

    # ì¸ìš©ë¬¸ í•˜ì´ë¼ì´íŒ…
    if citation_snippet:
        highlighted_snippet = _highlight_keywords(
            citation_snippet,
            source.get("keywords", [])
        )
        st.markdown(f"ğŸ’¬ **í•µì‹¬ ì¸ìš©:** _{highlighted_snippet}_")

    # ë©”íƒ€ë°ì´í„° í‘œì‹œ
    _render_source_metadata(source.get("metadata", {}), confidence)

    # ë‚´ìš© í‘œì‹œ
    content_tabs = st.tabs(["ğŸ“„ ìš”ì•½", "ğŸ“– ì „ì²´ ë‚´ìš©", "ğŸ”§ ì•¡ì…˜"])

    with content_tabs[0]:
        # ìš”ì•½ëœ ë‚´ìš© (ì²˜ìŒ 300ì)
        preview_len = min(300, len(content))
        preview_content = content[:preview_len]
        if len(content) > preview_len:
            preview_content += "..."

        highlighted_preview = _highlight_keywords(
            preview_content,
            source.get("keywords", [])
        )
        st.markdown(highlighted_preview)

    with content_tabs[1]:
        # ì „ì²´ ë‚´ìš©
        if len(content) > 500:
            st.text_area(
                "ì „ì²´ ë‚´ìš©",
                content,
                height=200,
                key=f"content_full_{idx}",
                help="ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
        else:
            highlighted_full = _highlight_keywords(
                content,
                source.get("keywords", [])
            )
            st.markdown(highlighted_full)

    with content_tabs[2]:
        # ì•¡ì…˜ ë²„íŠ¼ë“¤
        _render_source_actions(source, idx)


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def calculate_overall_confidence(sources: List[Dict]) -> float:
    """ì „ì²´ ê·¼ê±°ì˜ ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°"""
    if not sources:
        return 0.0

    # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ìƒìœ„ ê·¼ê±°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
    total_weight = 0
    weighted_sum = 0

    for i, source in enumerate(sources[:5]):  # ìƒìœ„ 5ê°œë§Œ ê³ ë ¤
        confidence = _calculate_confidence_score(source)
        weight = 1.0 / (i + 1)  # ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜

        weighted_sum += confidence * weight
        total_weight += weight

    return weighted_sum / total_weight if total_weight > 0 else 0.0


def get_source_quality_grade(confidence: float) -> str:
    """ê·¼ê±° í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
    if confidence >= 0.9:
        return "A+ (ë§¤ìš° ë†’ìŒ)"
    elif confidence >= 0.8:
        return "A (ë†’ìŒ)"
    elif confidence >= 0.7:
        return "B+ (ì–‘í˜¸)"
    elif confidence >= 0.6:
        return "B (ë³´í†µ)"
    elif confidence >= 0.5:
        return "C+ (ë‚®ìŒ)"
    elif confidence >= 0.4:
        return "C (ë§¤ìš° ë‚®ìŒ)"
    else:
        return "D (ë¶€ì ì ˆ)"


def filter_sources_by_quality(sources: List[Dict], min_confidence: float = 0.5) -> List[Dict]:
    """í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ê·¼ê±° í•„í„°ë§"""
    filtered = []
    for source in sources:
        confidence = _calculate_confidence_score(source)
        if confidence >= min_confidence:
            filtered.append({**source, "confidence": confidence})

    return sorted(filtered, key=lambda x: x["confidence"], reverse=True)