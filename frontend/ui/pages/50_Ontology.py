"""
ì˜¨í†¨ë¡œì§€ ê´€ë¦¬ í˜ì´ì§€ - í‚¤ì›Œë“œ, ë©”íƒ€ë°ì´í„°, ì»¨í…ìŠ¤íŠ¸ íƒìƒ‰
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime
from typing import Dict, List, Any, Optional

# ê¸°ì¡´ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from frontend.ui.utils.client_manager import ClientManager
from frontend.ui.utils.streamlit_helpers import rerun
from frontend.ui.components.common import StatusIndicator
from frontend.ui.utils.api_utils import OntologyAPIManager, safe_api_call, display_api_response

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì˜¨í†¨ë¡œì§€ ê´€ë¦¬ - GTOne RAG",
    page_icon="ğŸ§ ",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.metric-card {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #007acc;
    margin: 0.5rem 0;
}

.keyword-tag {
    background-color: #e3f2fd;
    color: #1976d2;
    padding: 0.2rem 0.5rem;
    border-radius: 12px;
    font-size: 0.8rem;
    margin: 0.1rem;
    display: inline-block;
}

.entity-tag {
    background-color: #f3e5f5;
    color: #7b1fa2;
    padding: 0.2rem 0.5rem;
    border-radius: 12px;
    font-size: 0.8rem;
    margin: 0.1rem;
    display: inline-block;
}

.domain-badge {
    background-color: #e8f5e8;
    color: #2e7d32;
    padding: 0.3rem 0.6rem;
    border-radius: 16px;
    font-weight: bold;
    font-size: 0.9rem;
}

.search-results {
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 1rem;
    margin: 0.5rem 0;
    background-color: #fafafa;
}

.similarity-score {
    background: linear-gradient(90deg, #4caf50, #ffeb3b, #f44336);
    padding: 0.2rem 0.5rem;
    border-radius: 12px;
    color: white;
    font-weight: bold;
    font-size: 0.8rem;
}
</style>
""", unsafe_allow_html=True)


def get_ontology_statistics(client) -> Optional[Dict]:
    """ì˜¨í†¨ë¡œì§€ í†µê³„ ì¡°íšŒ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.get_ontology_statistics()

        if response.success:
            return response.data
        else:
            st.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {response.error_message}")
            return None

    except Exception as e:
        st.error(f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return None


def search_by_keyword(client, keyword: str, limit: int = 10) -> List[Dict]:
    """í‚¤ì›Œë“œ ê²€ìƒ‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.search_by_keyword(keyword, limit, min_score=0.7)

        if response.success:
            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            data = response.data
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
                return data.get("results", data.get("keywords", data.get("data", [])))
            else:
                st.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(data)}")
                return []
        else:
            st.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {response.error_message}")
            return []

    except Exception as e:
        st.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return []


def search_by_domain(client, domain: str, limit: int = 20) -> List[Dict]:
    """ë„ë©”ì¸ë³„ ê²€ìƒ‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.search_by_domain(domain, limit)

        if response.success:
            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            data = response.data
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
                return data.get("results", data.get("documents", data.get("data", [])))
            else:
                st.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(data)}")
                return []
        else:
            st.error(f"ë„ë©”ì¸ ê²€ìƒ‰ ì‹¤íŒ¨: {response.error_message}")
            return []

    except Exception as e:
        st.error(f"ë„ë©”ì¸ ê²€ìƒ‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return []


def get_top_keywords(client, limit: int = 50, category: str = None, domain: str = None) -> List[Dict]:
    """ìƒìœ„ í‚¤ì›Œë“œ ì¡°íšŒ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.get_top_keywords(limit, category, domain)

        if response.success:
            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            data = response.data
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ ì‹œë„)
                for key in ["keywords", "data", "results", "items"]:
                    if key in data and isinstance(data[key], list):
                        return data[key]
                # í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
                st.warning(f"í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(data.keys())}")
                return []
            else:
                st.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(data)}")
                return []
        else:
            st.error(f"í‚¤ì›Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {response.error_message}")
            return []

    except Exception as e:
        st.error(f"í‚¤ì›Œë“œ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return []


def get_document_ontology(client, doc_id: str) -> Optional[Dict]:
    """ë¬¸ì„œë³„ ì˜¨í†¨ë¡œì§€ ì¡°íšŒ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.get_document_ontology(doc_id)

        if response.success:
            return response.data
        else:
            # 404 ì˜¤ë¥˜ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ë¬¸ì„œê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
            if "404" not in response.error_message and "not found" not in response.error_message.lower():
                st.error(f"ë¬¸ì„œ ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ì‹¤íŒ¨: {response.error_message}")
            return None

    except Exception as e:
        st.error(f"ë¬¸ì„œ ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return None


def get_similar_documents(client, doc_id: str, limit: int = 5) -> List[Dict]:
    """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        response = ontology_api.get_similar_documents(doc_id, limit, min_similarity=0.6)

        if response.success:
            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            data = response.data
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
                return data.get("results", data.get("documents", data.get("data", [])))
            else:
                st.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹: {type(data)}")
                return []
        else:
            # ìœ ì‚¬ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš°ëŠ” ì •ìƒì ì¸ ìƒí™©
            if "not found" not in response.error_message.lower():
                st.error(f"ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {response.error_message}")
            return []

    except Exception as e:
        st.error(f"ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return []


def render_statistics_dashboard(client):
    """í†µê³„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§ - ê°œì„ ëœ ë²„ì „"""
    st.subheader("ğŸ“Š ì˜¨í†¨ë¡œì§€ í†µê³„ ëŒ€ì‹œë³´ë“œ")

    # ë¡œë”© ìƒíƒœì™€ í•¨ê»˜ í†µê³„ ì¡°íšŒ
    with st.spinner("í†µê³„ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        stats = get_ontology_statistics(client)

    if not stats:
        st.warning("ì˜¨í†¨ë¡œì§€ í†µê³„ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì¬ì‹œë„ ë²„íŠ¼ ì œê³µ
        if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„"):
            st.rerun()
        return

    # ì „ì²´ í†µê³„ ì¹´ë“œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats.get("total_documents", 0))

    with col2:
        st.metric("ì´ í‚¤ì›Œë“œ ìˆ˜", stats.get("total_keywords", 0))

    with col3:
        avg_keywords = stats.get("avg_keywords_per_doc", 0)
        st.metric("ë¬¸ì„œë‹¹ í‰ê·  í‚¤ì›Œë“œ", f"{avg_keywords:.1f}")

    with col4:
        total_docs = stats.get("total_documents", 0)
        coverage = (total_docs / max(total_docs, 1)) * 100 if total_docs > 0 else 0
        st.metric("ì˜¨í†¨ë¡œì§€ ì»¤ë²„ë¦¬ì§€", f"{coverage:.1f}%")

    # ì°¨íŠ¸ ì˜ì—­ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€í•˜ë˜ ë°ì´í„° ì•ˆì „ì„± ê²€ì‚¬ ì¶”ê°€)
    col1, col2 = st.columns(2)

    with col1:
        domain_dist = stats.get("domain_distribution", {})
        if domain_dist and isinstance(domain_dist, dict) and len(domain_dist) > 0:
            try:
                fig_domain = px.pie(
                    values=list(domain_dist.values()),
                    names=list(domain_dist.keys()),
                    title="ë„ë©”ì¸ë³„ ë¬¸ì„œ ë¶„í¬"
                )
                fig_domain.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig_domain, use_container_width=True)
            except Exception as e:
                st.error(f"ë„ë©”ì¸ ë¶„í¬ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.info("ë„ë©”ì¸ ë¶„í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        doc_type_dist = stats.get("document_type_distribution", {})
        if doc_type_dist and isinstance(doc_type_dist, dict) and len(doc_type_dist) > 0:
            try:
                fig_doctype = px.bar(
                    x=list(doc_type_dist.keys()),
                    y=list(doc_type_dist.values()),
                    title="ë¬¸ì„œ ìœ í˜•ë³„ ë¶„í¬"
                )
                fig_doctype.update_layout(xaxis_title="ë¬¸ì„œ ìœ í˜•", yaxis_title="ë¬¸ì„œ ìˆ˜")
                st.plotly_chart(fig_doctype, use_container_width=True)
            except Exception as e:
                st.error(f"ë¬¸ì„œ ìœ í˜• ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.info("ë¬¸ì„œ ìœ í˜• ë¶„í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„í¬
    keyword_cat_dist = stats.get("keyword_category_distribution", {})
    if keyword_cat_dist and isinstance(keyword_cat_dist, dict) and len(keyword_cat_dist) > 0:
        st.subheader("í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
        try:
            fig_keyword_cat = px.bar(
                x=list(keyword_cat_dist.values()),
                y=list(keyword_cat_dist.keys()),
                orientation='h',
                title="í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬"
            )
            fig_keyword_cat.update_layout(xaxis_title="í‚¤ì›Œë“œ ìˆ˜", yaxis_title="ì¹´í…Œê³ ë¦¬")
            st.plotly_chart(fig_keyword_cat, use_container_width=True)
        except Exception as e:
            st.error(f"í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


def render_keyword_explorer(client):
    """í‚¤ì›Œë“œ íƒìƒ‰ê¸° ë Œë”ë§ - DuplicateWidgetID ì˜¤ë¥˜ ìˆ˜ì •"""
    st.subheader("ğŸ” í‚¤ì›Œë“œ íƒìƒ‰ê¸°")

    # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        search_term = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

    with col2:
        category_filter = st.selectbox(
            "ì¹´í…Œê³ ë¦¬ í•„í„°",
            ["ì „ì²´", "technical", "person", "organization", "location", "general"]
        )

    with col3:
        limit = st.number_input("ê²°ê³¼ ìˆ˜", min_value=5, max_value=50, value=10)

    # ê²€ìƒ‰ ì‹¤í–‰
    if search_term and search_term.strip():
        st.write(f"**'{search_term}' ê²€ìƒ‰ ê²°ê³¼:**")

        results = search_by_keyword(client, search_term.strip(), limit)

        if results and len(results) > 0:
            for idx, result in enumerate(results):
                if not isinstance(result, dict):
                    st.warning(f"ê²°ê³¼ {idx + 1}: ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
                    continue

                with st.container():
                    st.markdown(f"""
                    <div class="search-results">
                        <h4>ğŸ“„ {result.get('source', 'Unknown')}</h4>
                        <p><strong>í‚¤ì›Œë“œ:</strong> <span class="keyword-tag">{result.get('keyword', '')}</span></p>
                        <p><strong>ìœ ì‚¬ë„:</strong> {result.get('score', 0):.3f}</p>
                        <p><strong>ì¹´í…Œê³ ë¦¬:</strong> {result.get('category', 'unknown')}</p>
                        <p><strong>ë„ë©”ì¸:</strong> <span class="domain-badge">{result.get('estimated_domain', 'unknown')}</span></p>
                        <p><strong>ë¬¸ì„œ ìœ í˜•:</strong> {result.get('document_type', 'unknown')}</p>
                    </div>
                    """, unsafe_allow_html=True)

                    # ğŸ”§ ìˆ˜ì •: ê³ ìœ í•œ í‚¤ ìƒì„±
                    doc_id = result.get('doc_id', f'unknown_{idx}')
                    unique_key = f"keyword_detail_{search_term}_{idx}_{doc_id}"

                    if st.button("ìƒì„¸ ë³´ê¸°", key=unique_key):
                        if doc_id and doc_id != f'unknown_{idx}':
                            st.session_state.selected_doc_id = doc_id
                            st.session_state.page_mode = 'document_detail'
                            rerun()
                        else:
                            st.warning("ë¬¸ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ê²€ìƒ‰ ì œì•ˆ ì œê³µ
            if len(search_term.strip()) < 2:
                st.caption("ğŸ’¡ 2ê¸€ì ì´ìƒ ì…ë ¥í•´ë³´ì„¸ìš”.")
            elif search_term.strip().isdigit():
                st.caption("ğŸ’¡ ìˆ«ìë§Œìœ¼ë¡œëŠ” ê²€ìƒ‰í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”.")

    # ìƒìœ„ í‚¤ì›Œë“œ ë­í‚¹
    st.subheader("ğŸ† ì¸ê¸° í‚¤ì›Œë“œ ë­í‚¹")

    col1, col2 = st.columns(2)
    with col1:
        domain_filter = st.selectbox(
            "ë„ë©”ì¸ í•„í„° (ë­í‚¹)",
            ["ì „ì²´", "technology", "finance", "legal", "medical", "business", "academic"]
        )

    with col2:
        ranking_limit = st.number_input("ë­í‚¹ ìˆ˜", min_value=10, max_value=100, value=20)

    if st.button("í‚¤ì›Œë“œ ë­í‚¹ ì¡°íšŒ"):
        domain_param = None if domain_filter == "ì „ì²´" else domain_filter
        top_keywords = get_top_keywords(client, ranking_limit, domain=domain_param)

        if top_keywords and len(top_keywords) > 0:
            processed_keywords = []
            for idx, kw in enumerate(top_keywords):
                if isinstance(kw, dict):
                    processed_keywords.append({
                        "ìˆœìœ„": idx + 1,
                        "í‚¤ì›Œë“œ": kw.get("keyword", "Unknown"),
                        "ë¬¸ì„œ ìˆ˜": kw.get("document_count", 0),
                        "ì´ ë¹ˆë„": kw.get("total_frequency", 0),
                        "í‰ê·  ì ìˆ˜": f"{kw.get('avg_score', 0):.3f}",
                        "ì¹´í…Œê³ ë¦¬": ", ".join(kw.get("categories", [])) if kw.get("categories") else "ì—†ìŒ",
                        "ë„ë©”ì¸": ", ".join(kw.get("domains", [])) if kw.get("domains") else "ì—†ìŒ"
                    })
                else:
                    st.warning(f"í‚¤ì›Œë“œ {idx + 1}: ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")

            if processed_keywords:
                df_keywords = pd.DataFrame(processed_keywords)
                st.dataframe(df_keywords, use_container_width=True)

                if len(processed_keywords) >= 10:
                    try:
                        top_10_data = processed_keywords[:10]
                        fig_top = px.bar(
                            x=[item["ë¬¸ì„œ ìˆ˜"] for item in top_10_data],
                            y=[item["í‚¤ì›Œë“œ"] for item in top_10_data],
                            orientation='h',
                            title="ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ (ë¬¸ì„œ ìˆ˜ ê¸°ì¤€)"
                        )
                        fig_top.update_layout(yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig_top, use_container_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            else:
                st.warning("ì²˜ë¦¬ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info(f"{domain_filter} ë„ë©”ì¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def render_domain_explorer(client):
    """ë„ë©”ì¸ íƒìƒ‰ê¸° ë Œë”ë§ - DuplicateWidgetID ì˜¤ë¥˜ ìˆ˜ì •"""
    st.subheader("ğŸ¢ ë„ë©”ì¸ë³„ ë¬¸ì„œ íƒìƒ‰")

    col1, col2 = st.columns(2)

    with col1:
        selected_domain = st.selectbox(
            "ë„ë©”ì¸ ì„ íƒ",
            ["technology", "finance", "legal", "medical", "business", "academic", "general"]
        )

    with col2:
        domain_limit = st.number_input("ì¡°íšŒí•  ë¬¸ì„œ ìˆ˜", min_value=5, max_value=50, value=15)

    if st.button("ë„ë©”ì¸ë³„ ë¬¸ì„œ ì¡°íšŒ"):
        results = search_by_domain(client, selected_domain, domain_limit)

        if results and len(results) > 0:
            st.write(f"**{selected_domain} ë„ë©”ì¸ ë¬¸ì„œ ({len(results)}ê°œ):**")

            for idx, doc in enumerate(results, 1):
                if not isinstance(doc, dict):
                    st.warning(f"ë¬¸ì„œ {idx}: ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
                    continue

                with st.expander(f"{idx}. {doc.get('source', 'Unknown')}"):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**ë¬¸ì„œ ìœ í˜•:** {doc.get('document_type', 'unknown')}")
                        st.write(f"**í‚¤ì›Œë“œ ìˆ˜:** {doc.get('keyword_count', 0)}")
                        st.write(f"**ì¶”ì¶œ ì‹œê°„:** {doc.get('extracted_at', 'Unknown')}")

                    with col2:
                        keywords = doc.get('top_keywords', [])
                        if keywords and isinstance(keywords, list):
                            st.write("**ì£¼ìš” í‚¤ì›Œë“œ:**")
                            keyword_html = " ".join([
                                f'<span class="keyword-tag">{kw}</span>'
                                for kw in keywords[:8] if isinstance(kw, str)
                            ])
                            if keyword_html:
                                st.markdown(keyword_html, unsafe_allow_html=True)

                        topics = doc.get('main_topics', [])
                        if topics and isinstance(topics, list):
                            st.write("**ì£¼ìš” ì£¼ì œ:**")
                            for topic in topics[:3]:
                                if isinstance(topic, str):
                                    st.write(f"â€¢ {topic}")

                    # ğŸ”§ ìˆ˜ì •: ê³ ìœ í•œ í‚¤ ìƒì„±
                    doc_id = doc.get('doc_id', f'unknown_{idx}')
                    unique_key = f"domain_detail_{selected_domain}_{idx}_{doc_id}"

                    if st.button("ìƒì„¸ ë¶„ì„", key=unique_key):
                        if doc_id and doc_id != f'unknown_{idx}':
                            st.session_state.selected_doc_id = doc_id
                            st.session_state.page_mode = 'document_detail'
                            rerun()
                        else:
                            st.warning("ë¬¸ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info(f"{selected_domain} ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ë‹¤ë¥¸ ë„ë©”ì¸ ì œì•ˆ
            st.caption("ğŸ’¡ ë‹¤ë¥¸ ë„ë©”ì¸ì„ ì„ íƒí•´ë³´ì„¸ìš”:")
            alternative_domains = ["general", "technology", "business"]
            for i, alt_domain in enumerate(alternative_domains):
                if alt_domain != selected_domain:
                    # ğŸ”§ ìˆ˜ì •: ê³ ìœ í•œ í‚¤ ìƒì„±
                    unique_key = f"alt_domain_{alt_domain}_{i}"
                    if st.button(f"ğŸ” {alt_domain} ë„ë©”ì¸ íƒìƒ‰", key=unique_key):
                        st.session_state.temp_domain = alt_domain
                        st.rerun()


def render_document_detail(client, doc_id: str):
    """ë¬¸ì„œ ìƒì„¸ ì˜¨í†¨ë¡œì§€ ë³´ê¸° - DuplicateWidgetID ì˜¤ë¥˜ ìˆ˜ì •"""
    st.subheader(f"ğŸ“„ ë¬¸ì„œ ìƒì„¸ ì˜¨í†¨ë¡œì§€ ë¶„ì„")

    if st.button("â† ë’¤ë¡œ ê°€ê¸°"):
        st.session_state.page_mode = 'main'
        rerun()

    with st.spinner("ë¬¸ì„œ ì˜¨í†¨ë¡œì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        ontology = get_document_ontology(client, doc_id)

    if not ontology:
        st.error("ë¬¸ì„œì˜ ì˜¨í†¨ë¡œì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„"):
                st.rerun()
        with col2:
            if st.button("ğŸ“‹ ë¬¸ì„œ ëª©ë¡ìœ¼ë¡œ"):
                st.session_state.page_mode = 'main'
                st.rerun()
        return

    # ë¬¸ì„œ ê¸°ë³¸ ì •ë³´
    st.write(f"**ë¬¸ì„œëª…:** {ontology.get('source', 'Unknown')}")
    st.write(f"**ë¬¸ì„œ ID:** {doc_id}")

    col1, col2, col3 = st.columns(3)

    with col1:
        metadata = ontology.get('metadata', {})
        st.write(f"**ì–¸ì–´:** {metadata.get('language', 'unknown')}")
        st.write(f"**ë¬¸ì„œ ìœ í˜•:** {metadata.get('document_type', 'unknown')}")
        st.write(f"**ì¶”ì • ë„ë©”ì¸:** {metadata.get('estimated_domain', 'unknown')}")

    with col2:
        text_stats = metadata.get('text_statistics', {})
        st.write(f"**ì´ ë¬¸ì ìˆ˜:** {text_stats.get('total_length', 0):,}")
        st.write(f"**ë‹¨ì–´ ìˆ˜:** {text_stats.get('words', 0):,}")
        st.write(f"**ë¬¸ì¥ ìˆ˜:** {text_stats.get('sentences', 0):,}")

    with col3:
        processing_stats = ontology.get('processing_stats', {})
        st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {processing_stats.get('total_time', 0):.2f}ì´ˆ")
        st.write(f"**í‚¤ì›Œë“œ ìˆ˜:** {processing_stats.get('keywords_count', 0)}")
        st.write(f"**ê°œì²´ëª… ìˆ˜:** {processing_stats.get('entities_count', 0)}")

    # íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ìƒì„¸ ì •ë³´
    tab1, tab2, tab3, tab4 = st.tabs(["í‚¤ì›Œë“œ", "ê°œì²´ëª…", "ì»¨í…ìŠ¤íŠ¸", "ìœ ì‚¬ ë¬¸ì„œ"])

    with tab1:
        keywords = ontology.get('keywords', [])
        if keywords and isinstance(keywords, list):
            st.write(f"**ì¶”ì¶œëœ í‚¤ì›Œë“œ ({len(keywords)}ê°œ):**")

            keyword_by_category = {}
            for kw in keywords:
                if isinstance(kw, dict):
                    category = kw.get('category', 'unknown')
                    if category not in keyword_by_category:
                        keyword_by_category[category] = []
                    keyword_by_category[category].append(kw)

            for category, kw_list in keyword_by_category.items():
                if kw_list:
                    st.write(f"**{category.title()} ({len(kw_list)}ê°œ):**")

                    try:
                        keyword_data = []
                        for kw in sorted(kw_list, key=lambda x: x.get('score', 0), reverse=True):
                            if isinstance(kw, dict):
                                keyword_data.append({
                                    "í‚¤ì›Œë“œ": kw.get("term", "Unknown"),
                                    "ì ìˆ˜": kw.get("score", 0),
                                    "ë¹ˆë„": kw.get("frequency", 0)
                                })

                        if keyword_data:
                            keyword_df = pd.DataFrame(keyword_data)
                            st.dataframe(keyword_df, use_container_width=True)
                    except Exception as e:
                        st.error(f"í‚¤ì›Œë“œ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.info("ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        entities = metadata.get('key_entities', [])
        if entities and isinstance(entities, list):
            st.write(f"**ì¸ì‹ëœ ê°œì²´ëª… ({len(entities)}ê°œ):**")

            try:
                entity_data = []
                for ent in entities:
                    if isinstance(ent, dict):
                        entity_data.append({
                            "ê°œì²´ëª…": ent.get("text", "Unknown"),
                            "íƒ€ì…": ent.get("label", "Unknown"),
                            "ì‹ ë¢°ë„": f"{ent.get('confidence', 0):.3f}"
                        })

                if entity_data:
                    entity_df = pd.DataFrame(entity_data)
                    st.dataframe(entity_df, use_container_width=True)

                    entity_types = [ent.get("label", "unknown") for ent in entities if isinstance(ent, dict)]
                    if entity_types:
                        entity_counts = pd.Series(entity_types).value_counts()
                        fig_entities = px.pie(
                            values=entity_counts.values,
                            names=entity_counts.index,
                            title="ê°œì²´ëª… íƒ€ì…ë³„ ë¶„í¬"
                        )
                        st.plotly_chart(fig_entities, use_container_width=True)
            except Exception as e:
                st.error(f"ê°œì²´ëª… ì‹œê°í™” ì‹¤íŒ¨: {e}")
        else:
            st.info("ì¸ì‹ëœ ê°œì²´ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab3:
        context = ontology.get('context', {})

        main_topics = context.get('main_topics', [])
        if main_topics and isinstance(main_topics, list):
            st.write("**ì£¼ìš” ì£¼ì œ:**")
            for topic in main_topics:
                if isinstance(topic, str):
                    st.write(f"â€¢ {topic}")

        related_concepts = context.get('related_concepts', [])
        if related_concepts and isinstance(related_concepts, list):
            st.write("**ê´€ë ¨ ê°œë…:**")
            concept_html = " ".join([
                f'<span class="keyword-tag">{concept}</span>'
                for concept in related_concepts if isinstance(concept, str)
            ])
            if concept_html:
                st.markdown(concept_html, unsafe_allow_html=True)

        domain_indicators = context.get('domain_indicators', [])
        if domain_indicators and isinstance(domain_indicators, list):
            st.write("**ë„ë©”ì¸ ì§€ì‹œì–´:**")
            for indicator in domain_indicators:
                if isinstance(indicator, str):
                    st.write(f"â€¢ {indicator}")

        clusters = context.get('semantic_clusters', [])
        if clusters and isinstance(clusters, list):
            st.write(f"**ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„° ({len(clusters)}ê°œ):**")
            for cluster in clusters:
                if isinstance(cluster, dict):
                    with st.expander(f"í´ëŸ¬ìŠ¤í„° {cluster.get('cluster_id', 0)} (í¬ê¸°: {cluster.get('size', 0)})"):
                        st.write(f"**ëŒ€í‘œ ì²­í¬:** {cluster.get('representative_chunk', '')}")
                        st.write(f"**í‰ê·  ìœ ì‚¬ë„:** {cluster.get('avg_similarity', 0):.3f}")

    with tab4:
        st.write("**ìœ ì‚¬í•œ ë¬¸ì„œë“¤:**")

        with st.spinner("ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¾ëŠ” ì¤‘..."):
            similar_docs = get_similar_documents(client, doc_id)

        if similar_docs and len(similar_docs) > 0:
            for idx, sim_doc in enumerate(similar_docs):
                if not isinstance(sim_doc, dict):
                    continue

                similarity = sim_doc.get('similarity_score', 0)

                if similarity >= 0.8:
                    color = "#4caf50"
                elif similarity >= 0.7:
                    color = "#ff9800"
                else:
                    color = "#f44336"

                st.markdown(f"""
                <div class="search-results">
                    <h4>ğŸ“„ {sim_doc.get('source', 'Unknown')}</h4>
                    <p><strong>ìœ ì‚¬ë„:</strong> 
                        <span style="background-color: {color}; color: white; padding: 0.2rem 0.5rem; border-radius: 12px; font-weight: bold;">
                            {similarity:.3f}
                        </span>
                    </p>
                    <p><strong>ë¬¸ì„œ ìœ í˜•:</strong> {sim_doc.get('document_type', 'unknown')}</p>
                    <p><strong>ë„ë©”ì¸:</strong> <span class="domain-badge">{sim_doc.get('estimated_domain', 'unknown')}</span></p>
                </div>
                """, unsafe_allow_html=True)

                keywords = sim_doc.get('top_keywords', [])
                if keywords and isinstance(keywords, list):
                    keyword_html = " ".join([
                        f'<span class="keyword-tag">{kw}</span>'
                        for kw in keywords[:5] if isinstance(kw, str)
                    ])
                    if keyword_html:
                        st.markdown(f"**í‚¤ì›Œë“œ:** {keyword_html}", unsafe_allow_html=True)

                # ğŸ”§ ìˆ˜ì •: ê³ ìœ í•œ í‚¤ ìƒì„±
                similar_doc_id = sim_doc.get('doc_id', f'unknown_{idx}')
                unique_key = f"similar_doc_{doc_id}_{idx}_{similar_doc_id}"

                if st.button("ì´ ë¬¸ì„œ ë³´ê¸°", key=unique_key):
                    if similar_doc_id and similar_doc_id != f'unknown_{idx}':
                        st.session_state.selected_doc_id = similar_doc_id
                        rerun()
                    else:
                        st.warning("ë¬¸ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.caption("ğŸ’¡ ë‹¤ë¥¸ ë¬¸ì„œë“¤ì„ íƒìƒ‰í•´ë³´ì„¸ìš”:")
            if st.button("ğŸ” ì „ì²´ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                st.session_state.page_mode = 'main'
                st.rerun()


# 2. ì „ì—­ API ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (main() í•¨ìˆ˜ ì•ì— ì¶”ê°€)
ontology_api = OntologyAPIManager()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    st.title("ğŸ§  ì˜¨í†¨ë¡œì§€ ê´€ë¦¬")
    st.write("ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œ, ë©”íƒ€ë°ì´í„°, ì»¨í…ìŠ¤íŠ¸ë¥¼ íƒìƒ‰í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.")

    # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = ClientManager.get_client()

    # ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    try:
        health_response = client.request("GET", "/v1/ontology/health")

        # ì‘ë‹µ í˜•ì‹ í™•ì¸ ë° ì²˜ë¦¬
        if isinstance(health_response, dict):
            if health_response.get("error"):
                st.error("ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.write("ê°€ëŠ¥í•œ ì›ì¸:")
                st.write("â€¢ ì˜¨í†¨ë¡œì§€ ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                st.write("â€¢ API ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
                st.write("â€¢ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
                return

            # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
            if not health_response.get("ontology_collections_status", {}).get("ontology", False):
                st.warning("ì˜¨í†¨ë¡œì§€ ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
        else:
            st.error(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ í—¬ìŠ¤ì²´í¬ ì‘ë‹µ í˜•ì‹: {type(health_response)}")
            return

    except Exception as e:
        st.error(f"ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'page_mode' not in st.session_state:
        st.session_state.page_mode = 'main'

    if 'selected_doc_id' not in st.session_state:
        st.session_state.selected_doc_id = None

    # í˜ì´ì§€ ëª¨ë“œì— ë”°ë¥¸ ë Œë”ë§
    if st.session_state.page_mode == 'document_detail' and st.session_state.selected_doc_id:
        render_document_detail(client, st.session_state.selected_doc_id)
    else:
        # ë©”ì¸ í˜ì´ì§€
        st.session_state.page_mode = 'main'

        # íƒ­ìœ¼ë¡œ ê¸°ëŠ¥ êµ¬ë¶„
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ” í‚¤ì›Œë“œ íƒìƒ‰", "ğŸ¢ ë„ë©”ì¸ íƒìƒ‰"])

        with tab1:
            render_statistics_dashboard(client)

        with tab2:
            render_keyword_explorer(client)

        with tab3:
            render_domain_explorer(client)


if __name__ == "__main__":
    main()