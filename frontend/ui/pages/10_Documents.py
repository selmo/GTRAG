"""
ë¬¸ì„œ ê´€ë¦¬ í˜ì´ì§€ (ê°œì„  v5 - ì˜¤ë¥˜ ìˆ˜ì •)
============================================================
- **ê°•í™”ëœ API ì‘ë‹µ ê²€ì¦**: ë‹¤ì–‘í•œ ì‘ë‹µ í˜•íƒœì— ëŒ€í•œ ê²¬ê³ í•œ ì²˜ë¦¬
- **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„
- **ìƒì„¸í•œ ë¡œê¹…**: ë¬¸ì œ ì§„ë‹¨ì„ ìœ„í•œ ìƒì„¸ ë¡œê·¸
- **ì‚¬ìš©ì ì¹œí™”ì  ì˜¤ë¥˜ ë©”ì‹œì§€**: ëª…í™•í•œ ì˜¤ë¥˜ ì›ì¸ê³¼ í•´ê²° ë°©ë²• ì œì‹œ
- **ë¡œë”© ìƒíƒœ í‘œì‹œ**: ì‹¤ì‹œê°„ ë¡œë”© ì§„í–‰ ìƒí™© í‘œì‹œ
- **ì™„ì „í•œ í†µê³„ ëŒ€ì‹œë³´ë“œ**: ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ ë° ë¶„ì„ ê¸°ëŠ¥
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Any, Dict, List, Tuple, Optional
import logging
import time
import requests
import json

import pandas as pd
import streamlit as st

# Plotly imports (ìµœì  í†µê³„ ê¸°ëŠ¥ìš©)
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    st.warning("âš ï¸ Plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê³ ê¸‰ ì°¨íŠ¸ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤. `pip install plotly` ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(PROJECT_ROOT))

from frontend.ui.utils.streamlit_helpers import rerun, set_page_config_safe
from frontend.ui.utils.client_manager import ClientManager
from frontend.ui.utils.file_utils import FileNameCleaner, FileUtils
from frontend.ui.components.uploader import (
    render_file_uploader,
    filter_and_sort_files,
    render_file_list_view,
    render_file_card_view,
    _reset_file_selection_state,
)
from frontend.ui.components.common import StatusIndicator, Constants

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
set_page_config_safe(
    page_title="ë¬¸ì„œ ê´€ë¦¬ Â· GTOne RAG",
    page_icon="ğŸ“„",
    layout="wide",
)

api_client = ClientManager.get_client()

st.title("ğŸ“„ ë¬¸ì„œ ê´€ë¦¬")
st.caption("ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ê´€ë¦¬í•˜ê³  ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")

# â”€â”€ íƒ­ ì¬ë°°ì¹˜ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_ALL_TABS = ["ğŸ“¤ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ", "ğŸ“ ë¬¸ì„œ ëª©ë¡", "ğŸ“Š í†µê³„"]
active_tab = st.session_state.get("active_docs_tab", _ALL_TABS[0])
if active_tab not in _ALL_TABS:
    active_tab = _ALL_TABS[0]
ordered = [active_tab] + [t for t in _ALL_TABS if t != active_tab]
_tabs = st.tabs(ordered)
TAB_MAP = {lbl: _tabs[i] for i, lbl in enumerate(ordered)}
TAB_UPLOAD = TAB_MAP["ğŸ“¤ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ"]
TAB_LIST   = TAB_MAP["ğŸ“ ë¬¸ì„œ ëª©ë¡"]
TAB_STATS  = TAB_MAP["ğŸ“Š í†µê³„"]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

NULL_EQUIV = {None, "", "none", "null", "None", "NULL"}

def _null_if_empty(val: Any):
    return None if val in NULL_EQUIV else val


def _parse_timestamp(ts_raw: Any) -> str:
    """ë‹¤ì–‘í•œ í˜•íƒœ(ISO/epoch/None) â†’ 'YYYYâ€‘MMâ€‘DD HH:MM' ë˜ëŠ” '-'"""
    ts_raw = _null_if_empty(ts_raw)
    if ts_raw is None:
        return "-"
    try:
        # epoch in seconds
        if isinstance(ts_raw, (int, float)) and ts_raw > 1e10:
            ts_raw = ts_raw / 1000  # milliseconds â†’ seconds
        ts = datetime.fromtimestamp(ts_raw) if isinstance(ts_raw, (int, float)) else pd.to_datetime(ts_raw)
        return ts.strftime("%Y-%m-%d %H:%M")
    except Exception:
        return str(ts_raw)


def _format_size(size_raw: Any) -> str:
    """bytes/int/str â†’ '?.? MB' or '-'."""
    size_raw = _null_if_empty(size_raw)
    if size_raw is None:
        return "-"
    try:
        if isinstance(size_raw, str) and size_raw.isdigit():
            size_raw = int(size_raw)
        if isinstance(size_raw, (int, float)):
            return FileUtils.format_file_size(size_raw)
        # ì´ë¯¸ '?.? MB' í˜•íƒœë©´ ê·¸ëŒ€ë¡œ
        if any(unit in str(size_raw) for unit in ("KB", "MB", "GB")):
            return str(size_raw)
    except Exception:
        pass
    return str(size_raw)


def _normalize_server_files(files: Any) -> List[Dict[str, Any]]:
    """API ì‘ë‹µì„ UIâ€‘friendly êµ¬ì¡°ë¡œ ë³€í™˜ (ìµœì í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""

    # ìƒì„¸ ë¡œê¹…
    logger.info(f"ğŸ”„ íŒŒì¼ ì •ê·œí™” ì‹œì‘: ì…ë ¥ íƒ€ì… {type(files)}")

    # ì…ë ¥ íƒ€ì… ê²€ì¦ ë° ì •ê·œí™”
    if files is None:
        logger.warning("âš ï¸ API ì‘ë‹µì´ Noneì…ë‹ˆë‹¤")
        return []

    if isinstance(files, str):
        logger.error(f"âŒ API ì‘ë‹µì´ ë¬¸ìì—´ì…ë‹ˆë‹¤ (ê¸¸ì´: {len(files)})")
        logger.debug(f"ğŸ“ ì‘ë‹µ ë‚´ìš©: {files[:200]}...")

        # JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸ ì‹œë„
        try:
            parsed = json.loads(files)
            logger.info("âœ… JSON ë¬¸ìì—´ì„ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤")
            return _normalize_server_files(parsed)
        except json.JSONDecodeError:
            logger.error("âŒ JSON íŒŒì‹± ì‹¤íŒ¨ - ìˆœìˆ˜ ë¬¸ìì—´ì…ë‹ˆë‹¤")
            return []

    if isinstance(files, dict):
        logger.info(f"ğŸ“Š dict ì‘ë‹µ - í‚¤ë“¤: {list(files.keys())}")

        # ë¬¸ì„œ ëª©ë¡ì„ ì°¾ê¸° ìœ„í•œ í‚¤ ìš°ì„ ìˆœìœ„
        document_keys = ["documents", "items", "data", "files", "results"]

        for key in document_keys:
            if key in files and isinstance(files[key], list):
                logger.info(f"âœ… '{key}' í‚¤ì—ì„œ ë¬¸ì„œ ëª©ë¡ ë°œê²¬: {len(files[key])}ê°œ")
                return _normalize_server_files(files[key])

        # ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        if "error" in files:
            logger.error(f"âŒ API ì˜¤ë¥˜ ì‘ë‹µ: {files['error']}")
            return []

        # dict ìì²´ê°€ ë¬¸ì„œì¸ì§€ í™•ì¸ (ë‹¨ì¼ ë¬¸ì„œ ì‘ë‹µ)
        if "name" in files or "id" in files:
            logger.info("ğŸ“„ ë‹¨ì¼ ë¬¸ì„œ ì‘ë‹µìœ¼ë¡œ íŒë‹¨")
            return _normalize_server_files([files])

        logger.warning(f"âš ï¸ dictì—ì„œ ë¬¸ì„œ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        logger.debug(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(files.keys())}")
        return []

    if not isinstance(files, (list, tuple)):
        logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ë‹µ íƒ€ì…: {type(files)}")
        logger.debug(f"ğŸ“ ì‘ë‹µ ë‚´ìš©: {str(files)[:200]}...")
        return []

    if not files:
        logger.info("ğŸ“‹ ë¹ˆ ë¬¸ì„œ ëª©ë¡")
        return []

    logger.info(f"ğŸ“Š {len(files)}ê°œ í•­ëª© ì •ê·œí™” ì‹œì‘")

    normalized: List[Dict[str, Any]] = []
    error_count = 0

    for idx, f in enumerate(files):
        try:
            # ê°œë³„ íŒŒì¼ í•­ëª© ê²€ì¦
            if f is None:
                logger.warning(f"âš ï¸ íŒŒì¼ {idx}: None ê°’, ê±´ë„ˆëœ€")
                error_count += 1
                continue

            if not isinstance(f, dict):
                logger.warning(f"âš ï¸ íŒŒì¼ {idx}: dictê°€ ì•„ë‹˜ ({type(f)}), ê±´ë„ˆëœ€")
                logger.debug(f"ğŸ“ ë‚´ìš©: {str(f)[:100]}...")
                error_count += 1
                continue

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if not any(key in f for key in ["name", "id", "filename", "title"]):
                logger.warning(f"âš ï¸ íŒŒì¼ {idx}: ì‹ë³„ ê°€ëŠ¥í•œ ì´ë¦„ í•„ë“œ ì—†ìŒ, ê±´ë„ˆëœ€")
                logger.debug(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(f.keys())}")
                error_count += 1
                continue

            # íŒŒì¼ëª… ì²˜ë¦¬
            original_name = (
                f.get("name") or
                f.get("filename") or
                f.get("title") or
                f.get("id") or
                f"Unknown_File_{idx}"
            )

            display_name = (
                FileNameCleaner.clean_display_name(original_name)
                if hasattr(FileNameCleaner, "clean_display_name")
                else original_name
            )

            # í¬ê¸° ì •ë³´ ì²˜ë¦¬
            size_raw = _null_if_empty(
                f.get("size") or
                f.get("file_size") or
                f.get("filesize") or
                f.get("bytes")
            )
            size_display = _format_size(size_raw)

            # ì‹œê°„ ì •ë³´ ì²˜ë¦¬
            uploaded_display = _parse_timestamp(
                f.get("uploaded_at") or
                f.get("time") or
                f.get("upload_time") or
                f.get("created_at")
            )

            created_display = _parse_timestamp(
                f.get("created_at") or
                f.get("created") or
                f.get("creation_time")
            )

            modified_display = _parse_timestamp(
                f.get("modified_at") or
                f.get("updated_at") or
                f.get("last_modified")
            )

            # ì‹œê°„ ì •ë³´ ë©€í‹°ë¼ì¸ êµ¬ì„±
            time_multiline = uploaded_display
            extra_parts = []

            if created_display != "-" and created_display != uploaded_display:
                extra_parts.append(f"ìƒì„± {created_display}")

            if modified_display != "-" and modified_display not in {uploaded_display, created_display}:
                extra_parts.append(f"ìˆ˜ì • {modified_display}")

            if extra_parts:
                time_multiline += "\n" + "\n".join(extra_parts)

            # ì²­í¬ ì •ë³´ ì²˜ë¦¬
            chunks = max(0, int(f.get("chunks", 0) or 0))

            normalized_item = {
                **f,  # ì›ë³¸ ë°ì´í„° ë³´ì¡´
                "original_name": original_name,
                "name": display_name,
                "size": size_display,
                "size_bytes": size_raw or 0,
                "chunks": chunks,
                "time": time_multiline,
                "uploaded": uploaded_display,
                "created": created_display,
                "modified": modified_display,
                "processing_status": "success"
            }

            normalized.append(normalized_item)

            if idx % 10 == 0:  # ì§„í–‰ ìƒí™© ë¡œê¹…
                logger.debug(f"ğŸ“Š ì§„í–‰ ìƒí™©: {idx + 1}/{len(files)} ì²˜ë¦¬ë¨")

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ {idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logger.debug(f"ğŸ·ï¸ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            if hasattr(f, 'keys'):
                logger.debug(f"ğŸ“‹ ë¬¸ì œ í•­ëª© í‚¤: {list(f.keys()) if isinstance(f, dict) else 'N/A'}")
            error_count += 1
            continue

    # ìµœì¢… ê²°ê³¼ ë¡œê¹…
    success_count = len(normalized)
    logger.info(f"âœ… ì •ê·œí™” ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì˜¤ë¥˜ {error_count}ê°œ")

    if error_count > 0:
        logger.warning(f"âš ï¸ {error_count}ê°œ í•­ëª© ì²˜ë¦¬ ì‹¤íŒ¨ (ì „ì²´ {len(files)}ê°œ ì¤‘)")

    return normalized


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (1) ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with TAB_UPLOAD:
    render_file_uploader(api_client)
    with st.expander("ğŸ’¡ ì—…ë¡œë“œ íŒ"):
        st.markdown(
            """
- **PDF**ëŠ” *í…ìŠ¤íŠ¸ ê¸°ë°˜* PDFê°€ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤.
- **ì´ë¯¸ì§€**ëŠ” OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë¶„ì„í•©ë‹ˆë‹¤.
- **50 MB ì´ˆê³¼** íŒŒì¼ì€ ë¶„í•  ì—…ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.
            """
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (2) ëª©ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with TAB_LIST:
    st.header("ğŸ“ ì—…ë¡œë“œëœ ë¬¸ì„œ")

    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    col_refresh, _ = st.columns([1, 9])
    with col_refresh:
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", key="refresh_doc_list", use_container_width=True):
            _reset_file_selection_state()
            st.session_state.force_refresh = True
            st.session_state.active_docs_tab = "ğŸ“ ë¬¸ì„œ ëª©ë¡"
            # ì„¸ì…˜ ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”
            if 'uploaded_files' in st.session_state:
                del st.session_state.uploaded_files
            if 'last_documents_error' in st.session_state:
                del st.session_state.last_documents_error
            rerun()

    # ë¬¸ì„œ ë¡œë“œ
    if (
            "uploaded_files" not in st.session_state
            or st.session_state.get("force_refresh", False)
    ):
        try:
            with st.spinner("ğŸ“‹ ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                # ìƒˆë¡œìš´ API í´ë¼ì´ì–¸íŠ¸ ë°©ì‹ ì‚¬ìš©
                if hasattr(api_client, 'list_documents'):
                    # íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
                    response = api_client.list_documents(
                        stats_only=False,
                        include_details=True
                    )

                    # ì‘ë‹µì´ dict í˜•íƒœì¸ ê²½ìš°
                    if isinstance(response, dict):
                        server_files = response.get("documents", [])
                        if response.get("error"):
                            st.error(f"API ì˜¤ë¥˜: {response['error']}")
                            st.session_state.uploaded_files = []
                            st.session_state.force_refresh = False
                            st.stop()
                    else:
                        # ì‘ë‹µì´ ì§ì ‘ listì¸ ê²½ìš°
                        server_files = response
                else:
                    # ê¸°ì¡´ ë°©ì‹ fallback
                    server_files = api_client.list_documents()

                # ì•ˆì „í•œ ì •ê·œí™”
                if isinstance(server_files, list):
                    st.session_state.uploaded_files = _normalize_server_files(server_files)
                elif isinstance(server_files, dict):
                    # dictì—ì„œ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ
                    documents = server_files.get("documents", server_files.get("items", []))
                    st.session_state.uploaded_files = _normalize_server_files(documents)
                else:
                    st.error(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•íƒœ: {type(server_files)}")
                    st.session_state.uploaded_files = []

                st.session_state.force_refresh = False

                # ì„±ê³µ ë©”ì‹œì§€
                doc_count = len(st.session_state.uploaded_files)
                if doc_count > 0:
                    st.success(f"âœ… {doc_count}ê°œ ë¬¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                else:
                    st.info("ğŸ“‹ ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"âŒ ë¬¸ì„œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            st.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")

            # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
            with st.expander("ğŸ”§ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                import traceback

                st.code(traceback.format_exc())

                # API ì‘ë‹µ í…ŒìŠ¤íŠ¸
                try:
                    st.write("### API ì§ì ‘ í…ŒìŠ¤íŠ¸")
                    raw_response = api_client.list_documents() if hasattr(api_client, 'list_documents') else "ë©”ì„œë“œ ì—†ìŒ"
                    st.write(f"ì›ë³¸ ì‘ë‹µ íƒ€ì…: {type(raw_response)}")
                    st.write(f"ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 200ì): {str(raw_response)[:200]}...")
                except Exception as e2:
                    st.write(f"API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e2)}")

            st.session_state.uploaded_files = []
            st.session_state.force_refresh = False

    # ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
    files = st.session_state.get("uploaded_files", [])

    if not files:
        st.info("í‘œì‹œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("### ğŸ“¤ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")
        if st.button("ğŸ“¤ ì—…ë¡œë“œ í˜ì´ì§€ë¡œ ì´ë™", use_container_width=True):
            st.session_state.active_docs_tab = "ğŸ“¤ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ"
            rerun()
    else:
        # í•„í„° ë° ì •ë ¬ UI
        col_search, col_sort, col_view = st.columns([3, 2, 2])

        with col_search:
            search_filter = st.text_input("ğŸ” ë¬¸ì„œëª… ê²€ìƒ‰", placeholder="íŒŒì¼ëª… ì…ë ¥")

        with col_sort:
            sort_option = st.selectbox(
                "ì •ë ¬ ê¸°ì¤€",
                [
                    "ìµœì‹  ì—…ë¡œë“œìˆœ",
                    "ìµœì‹  ìƒì„±ìˆœ",
                    "ìµœì‹  ìˆ˜ì •ìˆœ",
                    "ì´ë¦„ìˆœ",
                    "í¬ê¸°ìˆœ",
                    "ì²­í¬ìˆœ",
                    "íƒ€ì…ìˆœ",
                ],
            )

        with col_view:
            view_mode = st.radio("í‘œì‹œ ë°©ì‹", ["ëª©ë¡", "ì¹´ë“œ"], horizontal=True)

        # í•„í„°ë§ ë° ì •ë ¬
        filtered_files = files.copy()

        if search_filter:
            filtered_files = [f for f in filtered_files if search_filter.lower() in f.get("name", "").lower()]

        # ì •ë ¬ ì ìš©
        if sort_option == "ìµœì‹  ì—…ë¡œë“œìˆœ":
            filtered_files = sorted(filtered_files, key=lambda x: x.get("uploaded", ""), reverse=True)
        elif sort_option == "ìµœì‹  ìƒì„±ìˆœ":
            filtered_files = sorted(filtered_files, key=lambda x: x.get("created", ""), reverse=True)
        elif sort_option == "ìµœì‹  ìˆ˜ì •ìˆœ":
            filtered_files = sorted(filtered_files, key=lambda x: x.get("modified", ""), reverse=True)
        else:
            filtered_files = filter_and_sort_files(filtered_files, "", sort_option)

        # ê²°ê³¼ í‘œì‹œ
        if filtered_files:
            st.caption(f"ì´ {len(filtered_files)}ê°œ ë¬¸ì„œ (ì „ì²´ {len(files)}ê°œ ì¤‘)")

            if view_mode == "ëª©ë¡":
                render_file_list_view(filtered_files, api_client)
            else:
                render_file_card_view(filtered_files, api_client)
        else:
            if search_filter:
                st.info(f"'{search_filter}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("í‘œì‹œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (3) í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with TAB_STATS:
    st.header("ğŸ“Š ë¬¸ì„œ í†µê³„ ëŒ€ì‹œë³´ë“œ")

    # ë°ì´í„° ë¡œë“œ í™•ì¸
    files = st.session_state.get("uploaded_files", [])

    # ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not files:
        st.info("ğŸ“‹ í†µê³„ë¥¼ í‘œì‹œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("### ğŸ“¤ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¤ ì—…ë¡œë“œ í˜ì´ì§€ë¡œ ì´ë™", use_container_width=True, key="stats_to_upload"):
                st.session_state.active_docs_tab = "ğŸ“¤ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ"
                rerun()
        with col2:
            if st.button("ğŸ“ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°", use_container_width=True, key="stats_to_list"):
                st.session_state.active_docs_tab = "ğŸ“ ë¬¸ì„œ ëª©ë¡"
                rerun()

        # ìƒ˜í”Œ í†µê³„ ë³´ê¸° ì˜µì…˜
        with st.expander("ğŸ‘€ ìƒ˜í”Œ í†µê³„ ë¯¸ë¦¬ë³´ê¸°"):
            st.markdown("""
            **í†µê³„ ëŒ€ì‹œë³´ë“œì—ì„œ ì œê³µí•˜ëŠ” ê¸°ëŠ¥:**
            - ğŸ“ˆ ì‹¤ì‹œê°„ ë¬¸ì„œ í˜„í™© ëª¨ë‹ˆí„°ë§
            - ğŸ“Š ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ ë° ê·¸ë˜í”„
            - ğŸ“… ì‹œê°„ë³„ ì—…ë¡œë“œ íŠ¸ë Œë“œ ë¶„ì„
            - ğŸ“ íŒŒì¼ íƒ€ì…ë³„ ìƒì„¸ ë¶„í¬
            - ğŸ“ í¬ê¸° ë° ì²­í¬ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            - ğŸ† ìƒìœ„ ë¬¸ì„œ ìˆœìœ„ ë° í†µê³„
            - ğŸ” í•„í„°ë§ ë° ë“œë¦´ë‹¤ìš´ ë¶„ì„
            - ğŸ“¥ ìƒì„¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ
            """)
    else:
        # ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° í†µê³„ ëŒ€ì‹œë³´ë“œ í‘œì‹œ

        # í•„í„° ì˜µì…˜
        with st.expander("ğŸ”§ í•„í„° ë° ì„¤ì •", expanded=False):
            col1, col2, col3 = st.columns(3)

            with col1:
                # ë‚ ì§œ ë²”ìœ„ í•„í„°
                date_filter = st.selectbox(
                    "ğŸ“… ê¸°ê°„ í•„í„°",
                    ["ì „ì²´", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ìµœê·¼ 90ì¼", "ì‚¬ìš©ì ì •ì˜"],
                    help="ë¶„ì„í•  ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”"
                )

            with col2:
                # íŒŒì¼ íƒ€ì… í•„í„°
                all_types = set()
                for f in files:
                    name = f.get("name", "")
                    if "." in name:
                        all_types.add(name.split(".")[-1].lower())
                    else:
                        all_types.add("í™•ì¥ì ì—†ìŒ")

                selected_types = st.multiselect(
                    "ğŸ“ íŒŒì¼ íƒ€ì…",
                    sorted(all_types),
                    default=sorted(all_types),
                    help="ë¶„ì„í•  íŒŒì¼ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”"
                )

            with col3:
                # í¬ê¸° ë²”ìœ„ í•„í„°
                size_filter = st.selectbox(
                    "ğŸ“ í¬ê¸° ë²”ìœ„",
                    ["ì „ì²´", "1MB ë¯¸ë§Œ", "1-10MB", "10MB ì´ìƒ"],
                    help="ë¶„ì„í•  íŒŒì¼ í¬ê¸° ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                )

        # í•„í„° ì ìš©
        filtered_files = files.copy()

        # ë‚ ì§œ í•„í„° ì ìš©
        if date_filter != "ì „ì²´":
            now = datetime.now()
            if date_filter == "ìµœê·¼ 7ì¼":
                cutoff = now - timedelta(days=7)
            elif date_filter == "ìµœê·¼ 30ì¼":
                cutoff = now - timedelta(days=30)
            elif date_filter == "ìµœê·¼ 90ì¼":
                cutoff = now - timedelta(days=90)

            if date_filter != "ì‚¬ìš©ì ì •ì˜":
                filtered_files = [
                    f for f in filtered_files
                    if _parse_timestamp(f.get("uploaded_at")) != "-" and
                       pd.to_datetime(_parse_timestamp(f.get("uploaded_at"))).replace(tzinfo=None) >= cutoff
                ]

        # íƒ€ì… í•„í„° ì ìš©
        if selected_types:
            filtered_files = [
                f for f in filtered_files
                if (f.get("name", "").split(".")[-1].lower() in selected_types if "." in f.get("name", "")
                    else "í™•ì¥ì ì—†ìŒ" in selected_types)
            ]

        # í¬ê¸° í•„í„° ì ìš©
        if size_filter != "ì „ì²´":
            if size_filter == "1MB ë¯¸ë§Œ":
                filtered_files = [f for f in filtered_files if f.get("size_bytes", 0) < 1024 * 1024]
            elif size_filter == "1-10MB":
                filtered_files = [f for f in filtered_files if 1024 * 1024 <= f.get("size_bytes", 0) <= 10 * 1024 * 1024]
            elif size_filter == "10MB ì´ìƒ":
                filtered_files = [f for f in filtered_files if f.get("size_bytes", 0) > 10 * 1024 * 1024]

        # í•„í„° ê²°ê³¼ í‘œì‹œ
        if len(filtered_files) != len(files):
            st.info(f"ğŸ” í•„í„° ì ìš©: {len(files)}ê°œ ë¬¸ì„œ ì¤‘ {len(filtered_files)}ê°œ í‘œì‹œ")

        if not filtered_files:
            st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ê¸°ë³¸ í†µê³„ ê³„ì‚°
            total_docs = len(filtered_files)
            total_chunks = sum(f.get("chunks", 0) for f in filtered_files)
            total_size_bytes = sum(f.get("size_bytes", 0) for f in filtered_files)
            total_size_mb = total_size_bytes / (1024 * 1024) if total_size_bytes > 0 else 0

            avg_chunks = total_chunks / total_docs if total_docs > 0 else 0
            avg_size_mb = total_size_mb / total_docs if total_docs > 0 else 0

            # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ
            st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ í˜„í™©")

            col1, col2, col3, col4, col5 = st.columns(5)

            with col1:
                st.metric(
                    "ğŸ“„ ì´ ë¬¸ì„œ",
                    f"{total_docs:,}",
                    delta=f"ì „ì²´ {len(files):,}ê°œ ì¤‘" if total_docs != len(files) else None,
                    help="í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜"
                )

            with col2:
                st.metric(
                    "ğŸ§© ì´ ì²­í¬",
                    f"{total_chunks:,}",
                    delta=f"í‰ê·  {avg_chunks:.1f}/ë¬¸ì„œ",
                    help="ì¸ë±ì‹±ëœ ì´ ì²­í¬ ìˆ˜"
                )

            with col3:
                st.metric(
                    "ğŸ’¾ ì´ ìš©ëŸ‰",
                    f"{total_size_mb:.1f} MB",
                    delta=f"í‰ê·  {avg_size_mb:.1f} MB/ë¬¸ì„œ",
                    help="ì „ì²´ ë¬¸ì„œì˜ ì´ í¬ê¸°"
                )

            with col4:
                # ìµœëŒ€ í¬ê¸° ë¬¸ì„œ
                max_size_doc = max(filtered_files, key=lambda x: x.get("size_bytes", 0))
                max_size_mb = max_size_doc.get("size_bytes", 0) / (1024 * 1024)
                st.metric(
                    "ğŸ“Š ìµœëŒ€ í¬ê¸°",
                    f"{max_size_mb:.1f} MB",
                    delta=max_size_doc.get("name", "Unknown")[:15] + "...",
                    help="ê°€ì¥ í° ë¬¸ì„œ"
                )

            with col5:
                # ìµœëŒ€ ì²­í¬ ë¬¸ì„œ
                max_chunk_doc = max(filtered_files, key=lambda x: x.get("chunks", 0))
                max_chunks = max_chunk_doc.get("chunks", 0)
                st.metric(
                    "ğŸ”¥ ìµœëŒ€ ì²­í¬",
                    f"{max_chunks:,}",
                    delta=max_chunk_doc.get("name", "Unknown")[:15] + "...",
                    help="ì²­í¬ê°€ ê°€ì¥ ë§ì€ ë¬¸ì„œ"
                )

            # ê³ ê¸‰ ì°¨íŠ¸ ê¸°ëŠ¥ (Plotly ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if PLOTLY_AVAILABLE:
                # íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ìƒì„¸ ë¶„ì„
                tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë¶„í¬ ë¶„ì„", "ğŸ“… ì‹œê°„ ë¶„ì„", "ğŸ† ìˆœìœ„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])

                with tab1:
                    st.subheader("ğŸ“Š ë¶„í¬ ë¶„ì„")

                    col1, col2 = st.columns(2)

                    with col1:
                        # íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)
                        type_stats = {}
                        for f in filtered_files:
                            name = f.get("name", "")
                            ext = name.split(".")[-1].lower() if "." in name else "í™•ì¥ì ì—†ìŒ"
                            type_stats[ext] = type_stats.get(ext, 0) + 1

                        if type_stats:
                            fig_pie = px.pie(
                                values=list(type_stats.values()),
                                names=list(type_stats.keys()),
                                title="ğŸ“ íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬",
                                hole=0.4
                            )
                            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_pie, use_container_width=True)

                    with col2:
                        # í¬ê¸° ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
                        sizes_mb = [f.get("size_bytes", 0) / (1024 * 1024) for f in filtered_files]

                        fig_hist = px.histogram(
                            x=sizes_mb,
                            title="ğŸ“ íŒŒì¼ í¬ê¸° ë¶„í¬",
                            labels={"x": "í¬ê¸° (MB)", "y": "ë¬¸ì„œ ìˆ˜"},
                            nbins=20
                        )
                        fig_hist.update_layout(showlegend=False)
                        st.plotly_chart(fig_hist, use_container_width=True)

                    # ì²­í¬ vs í¬ê¸° ì‚°ì ë„
                    st.subheader("ğŸ”— ì²­í¬-í¬ê¸° ìƒê´€ê´€ê³„")

                    scatter_data = pd.DataFrame({
                        "í¬ê¸° (MB)": [f.get("size_bytes", 0) / (1024 * 1024) for f in filtered_files],
                        "ì²­í¬ ìˆ˜": [f.get("chunks", 0) for f in filtered_files],
                        "íŒŒì¼ëª…": [f.get("name", "Unknown") for f in filtered_files]
                    })

                    fig_scatter = px.scatter(
                        scatter_data,
                        x="í¬ê¸° (MB)",
                        y="ì²­í¬ ìˆ˜",
                        hover_data=["íŒŒì¼ëª…"],
                        title="íŒŒì¼ í¬ê¸°ì™€ ì²­í¬ ìˆ˜ì˜ ê´€ê³„",
                        trendline="ols"  # ì¶”ì„¸ì„  ì¶”ê°€
                    )
                    st.plotly_chart(fig_scatter, use_container_width=True)

                with tab2:
                    st.subheader("ğŸ“… ì‹œê°„ë³„ ì—…ë¡œë“œ ë¶„ì„")

                    # ì—…ë¡œë“œ ë‚ ì§œë³„ ë¶„ì„
                    upload_dates = []
                    for f in filtered_files:
                        uploaded = f.get("uploaded", "-")
                        if uploaded != "-":
                            try:
                                date_obj = pd.to_datetime(uploaded).date()
                                upload_dates.append(date_obj)
                            except:
                                continue

                    if upload_dates:
                        # ë‚ ì§œë³„ ì—…ë¡œë“œ ìˆ˜ ê³„ì‚°
                        date_counts = pd.Series(upload_dates).value_counts().sort_index()

                        # ì‹œê³„ì—´ ì°¨íŠ¸
                        fig_timeline = px.line(
                            x=date_counts.index,
                            y=date_counts.values,
                            title="ğŸ“ˆ ì¼ë³„ ì—…ë¡œë“œ ì¶”ì´",
                            labels={"x": "ë‚ ì§œ", "y": "ì—…ë¡œë“œ ìˆ˜"}
                        )
                        fig_timeline.update_traces(mode='lines+markers')
                        st.plotly_chart(fig_timeline, use_container_width=True)

                        # ìš”ì¼ë³„ íŒ¨í„´
                        weekday_counts = pd.Series(upload_dates).apply(lambda x: x.strftime('%A')).value_counts()
                        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                        weekday_counts = weekday_counts.reindex(weekday_order, fill_value=0)

                        col1, col2 = st.columns(2)

                        with col1:
                            fig_weekday = px.bar(
                                x=weekday_counts.index,
                                y=weekday_counts.values,
                                title="ğŸ“… ìš”ì¼ë³„ ì—…ë¡œë“œ íŒ¨í„´",
                                labels={"x": "ìš”ì¼", "y": "ì—…ë¡œë“œ ìˆ˜"}
                            )
                            st.plotly_chart(fig_weekday, use_container_width=True)

                        with col2:
                            # ì‹œê°„ëŒ€ë³„ ë¶„ì„ (ì‹œê°„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°)
                            hours = []
                            for f in filtered_files:
                                uploaded = f.get("uploaded", "-")
                                if uploaded != "-":
                                    try:
                                        hour = pd.to_datetime(uploaded).hour
                                        hours.append(hour)
                                    except:
                                        continue

                            if hours:
                                hour_counts = pd.Series(hours).value_counts().sort_index()
                                fig_hour = px.bar(
                                    x=hour_counts.index,
                                    y=hour_counts.values,
                                    title="ğŸ• ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ íŒ¨í„´",
                                    labels={"x": "ì‹œê°„", "y": "ì—…ë¡œë“œ ìˆ˜"}
                                )
                                st.plotly_chart(fig_hour, use_container_width=True)
                    else:
                        st.info("ğŸ“… ì‹œê°„ ë¶„ì„ì„ ìœ„í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                with tab3:
                    st.subheader("ğŸ† ë¬¸ì„œ ìˆœìœ„")

                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**ğŸ“ í¬ê¸°ë³„ Top 10**")
                        top_size = sorted(filtered_files, key=lambda x: x.get("size_bytes", 0), reverse=True)[:10]

                        size_rank_data = []
                        for i, f in enumerate(top_size, 1):
                            size_mb = f.get("size_bytes", 0) / (1024 * 1024)
                            size_rank_data.append({
                                "ìˆœìœ„": i,
                                "íŒŒì¼ëª…": f.get("name", "Unknown"),
                                "í¬ê¸°": f"{size_mb:.1f} MB",
                                "ì²­í¬": f.get("chunks", 0)
                            })

                        st.dataframe(pd.DataFrame(size_rank_data), hide_index=True)

                    with col2:
                        st.write("**ğŸ§© ì²­í¬ë³„ Top 10**")
                        top_chunks = sorted(filtered_files, key=lambda x: x.get("chunks", 0), reverse=True)[:10]

                        chunk_rank_data = []
                        for i, f in enumerate(top_chunks, 1):
                            size_mb = f.get("size_bytes", 0) / (1024 * 1024)
                            chunk_rank_data.append({
                                "ìˆœìœ„": i,
                                "íŒŒì¼ëª…": f.get("name", "Unknown"),
                                "ì²­í¬": f.get("chunks", 0),
                                "í¬ê¸°": f"{size_mb:.1f} MB"
                            })

                        st.dataframe(pd.DataFrame(chunk_rank_data), hide_index=True)

                    # íš¨ìœ¨ì„± ë¶„ì„ (ì²­í¬/MB ë¹„ìœ¨)
                    st.write("**âš¡ íš¨ìœ¨ì„± ìˆœìœ„ (ì²­í¬/MB)**")
                    efficiency_data = []
                    for f in filtered_files:
                        size_mb = f.get("size_bytes", 0) / (1024 * 1024)
                        chunks = f.get("chunks", 0)
                        if size_mb > 0:
                            efficiency = chunks / size_mb
                            efficiency_data.append({
                                "íŒŒì¼ëª…": f.get("name", "Unknown"),
                                "ì²­í¬/MB": f"{efficiency:.1f}",
                                "ì²­í¬": chunks,
                                "í¬ê¸°": f"{size_mb:.1f} MB"
                            })

                    if efficiency_data:
                        efficiency_df = pd.DataFrame(efficiency_data)
                        efficiency_df["ì²­í¬/MB"] = pd.to_numeric(efficiency_df["ì²­í¬/MB"])
                        efficiency_df = efficiency_df.sort_values("ì²­í¬/MB", ascending=False).head(10)
                        st.dataframe(efficiency_df, hide_index=True)

                with tab4:
                    st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„° í…Œì´ë¸”")

                    # ê²€ìƒ‰ ê¸°ëŠ¥
                    search_term = st.text_input("ğŸ” íŒŒì¼ëª… ê²€ìƒ‰", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

                    # ë°ì´í„° ì¤€ë¹„
                    detailed_data = []
                    for f in filtered_files:
                        if not search_term or search_term.lower() in f.get("name", "").lower():
                            size_mb = f.get("size_bytes", 0) / (1024 * 1024)
                            detailed_data.append({
                                "íŒŒì¼ëª…": f.get("name", "Unknown"),
                                "íƒ€ì…": f.get("name", "").split(".")[-1] if "." in f.get("name", "") else "ì—†ìŒ",
                                "í¬ê¸° (MB)": f"{size_mb:.2f}",
                                "ì²­í¬ ìˆ˜": f.get("chunks", 0),
                                "ì²­í¬/MB": f"{f.get('chunks', 0) / size_mb:.1f}" if size_mb > 0 else "N/A",
                                "ì—…ë¡œë“œì¼": f.get("uploaded", "-"),
                                "ìƒì„±ì¼": f.get("created", "-"),
                                "ìˆ˜ì •ì¼": f.get("modified", "-")
                            })

                    if detailed_data:
                        detailed_df = pd.DataFrame(detailed_data)

                        # ì»¬ëŸ¼ ì„ íƒ
                        selected_columns = st.multiselect(
                            "í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ",
                            detailed_df.columns.tolist(),
                            default=["íŒŒì¼ëª…", "íƒ€ì…", "í¬ê¸° (MB)", "ì²­í¬ ìˆ˜", "ì—…ë¡œë“œì¼"]
                        )

                        if selected_columns:
                            st.dataframe(
                                detailed_df[selected_columns],
                                use_container_width=True,
                                hide_index=True
                            )

                        # CSV ë‹¤ìš´ë¡œë“œ
                        csv_data = detailed_df.to_csv(index=False)
                        st.download_button(
                            label="ğŸ“¥ ìƒì„¸ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
                            data=csv_data,
                            file_name=f"detailed_document_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.info("ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

            else:
                # Plotly ì—†ì´ ê¸°ë³¸ í†µê³„ë§Œ í‘œì‹œ
                st.subheader("ğŸ“Š ê¸°ë³¸ í†µê³„")

                # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
                type_stats = {}
                for f in filtered_files:
                    name = f.get("name", "")
                    if "." in name:
                        ext = name.split(".")[-1].lower()
                    else:
                        ext = "í™•ì¥ì ì—†ìŒ"

                    if ext not in type_stats:
                        type_stats[ext] = {"count": 0, "size": 0, "chunks": 0}

                    type_stats[ext]["count"] += 1
                    type_stats[ext]["size"] += f.get("size_bytes", 0)
                    type_stats[ext]["chunks"] += f.get("chunks", 0)

                # íƒ€ì…ë³„ í†µê³„ í…Œì´ë¸”
                type_data = []
                for ext, stats in type_stats.items():
                    type_data.append({
                        "íŒŒì¼ íƒ€ì…": f".{ext}" if ext != "í™•ì¥ì ì—†ìŒ" else ext,
                        "ë¬¸ì„œ ìˆ˜": stats["count"],
                        "ì´ ìš©ëŸ‰ (MB)": f"{stats['size'] / (1024*1024):.1f}",
                        "ì´ ì²­í¬": stats["chunks"],
                        "í‰ê·  ì²­í¬/ë¬¸ì„œ": f"{stats['chunks'] / stats['count']:.1f}"
                    })

                type_df = pd.DataFrame(type_data)
                type_df = type_df.sort_values("ë¬¸ì„œ ìˆ˜", ascending=False)
                st.dataframe(type_df, use_container_width=True, hide_index=True)

            # í•˜ë‹¨ ì•¡ì…˜ ë²„íŠ¼ë“¤
            st.divider()

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                if st.button("ğŸ”„ í†µê³„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                    st.session_state.force_refresh = True
                    st.session_state.active_docs_tab = "ğŸ“Š í†µê³„"
                    rerun()

            with col2:
                if st.button("ğŸ“¤ ì—…ë¡œë“œí•˜ê¸°", use_container_width=True):
                    st.session_state.active_docs_tab = "ğŸ“¤ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ"
                    rerun()

            with col3:
                if st.button("ğŸ“ ë¬¸ì„œ ëª©ë¡", use_container_width=True):
                    st.session_state.active_docs_tab = "ğŸ“ ë¬¸ì„œ ëª©ë¡"
                    rerun()

            with col4:
                # ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ
                report_data = {
                    "í†µê³„_ìš”ì•½": {
                        "ì´_ë¬¸ì„œ_ìˆ˜": total_docs,
                        "ì´_ì²­í¬_ìˆ˜": total_chunks,
                        "ì´_ìš©ëŸ‰_MB": round(total_size_mb, 2),
                        "í‰ê· _ì²­í¬_ë¬¸ì„œ": round(avg_chunks, 1),
                        "í‰ê· _í¬ê¸°_MB": round(avg_size_mb, 2)
                    },
                    "íŒŒì¼_ëª©ë¡": detailed_data if 'detailed_data' in locals() else []
                }

                report_json = json.dumps(report_data, ensure_ascii=False, indent=2)

                st.download_button(
                    label="ğŸ“Š ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (JSON)",
                    data=report_json,
                    file_name=f"document_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )