"""
ì„¤ì • í˜ì´ì§€ - ê°œì„ ëœ ë²„ì „
- Import ê²½ë¡œ í†µì¼
- ê³µí†µ ì»´í¬ë„ŒíŠ¸ ì ìš©
- ì„¤ì • ì¤‘ì•™í™”
- ì—ëŸ¬ ì²˜ë¦¬ í‘œì¤€í™”
"""
import streamlit as st
import sys
from pathlib import Path
import json
from datetime import datetime

from frontend.ui.utils.session import SessionManager

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))

# í†µì¼ëœ import ê²½ë¡œ
from frontend.ui.utils.streamlit_helpers import rerun
from frontend.ui.core.config import config, Constants
from frontend.ui.components.common import (
    StatusIndicator, MetricCard, ErrorDisplay, ActionButton, LoadingSpinner
)
from frontend.ui.utils.error_handler import (
    ErrorContext, GTRagError, ErrorType, ErrorSeverity
)

# ì¡°ê±´ë¶€ import (í‘œì¤€ íŒ¨í„´)
try:
    from frontend.ui.utils.client_manager import ClientManager
    HAS_API_CLIENT = True
except ImportError:
    APIClient = None
    HAS_API_CLIENT = False

try:
    from frontend.ui.utils.system_health import SystemHealthManager, SystemStatus, ServiceStatus
    HAS_SYSTEM_HEALTH = True
except ImportError:
    SystemHealthManager = None
    SystemStatus = None
    ServiceStatus = None
    HAS_SYSTEM_HEALTH = False

try:
    from frontend.ui.utils.model_manager import ModelManager
    HAS_MODEL_MANAGER = True
except ImportError:
    ModelManager = None
    HAS_MODEL_MANAGER = False


# ===============================
# ì„¤ì • ê´€ë¦¬ í•¨ìˆ˜ë“¤ (import ì´í›„, í˜ì´ì§€ ì„¤ì • ì „ì— ì¶”ê°€)
# ===============================

# 1. ìˆ˜ì •ëœ ì„¤ì • ë™ê¸°í™” í•¨ìˆ˜ (ëª¨ë¸ëª… ë™ê¸°í™” ì¶”ê°€)
def sync_backend_settings_to_session():
    """ë°±ì—”ë“œ ì„¤ì •ì„ ì„¸ì…˜ ìƒíƒœì— ë™ê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ë°±ì—”ë“œì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        current_settings = api_client.get_settings()

        if current_settings:
            # Ollama í˜¸ìŠ¤íŠ¸ ì„¤ì •
            if 'ollama_host' in current_settings:
                st.session_state.backend_ollama_host = current_settings['ollama_host']

            # â˜… ëª¨ë¸ëª… ë™ê¸°í™” ì¶”ê°€ â˜…
            if 'ollama_model' in current_settings:
                st.session_state.backend_selected_model = current_settings['ollama_model']

            # LLM íŒŒë¼ë¯¸í„° ë™ê¸°í™”
            if 'llm' in current_settings:
                llm_settings = current_settings['llm']
                llm_params = ['model', 'temperature', 'max_tokens', 'top_p', 'frequency_penalty', 'system_prompt']
                for param in llm_params:
                    if param in llm_settings:
                        st.session_state[f'backend_{param}'] = llm_settings[param]

                # LLM ì„¤ì •ì˜ modelë„ selected_modelë¡œ ë™ê¸°í™”
                if 'model' in llm_settings:
                    st.session_state.backend_selected_model = llm_settings['model']

            # RAG íŒŒë¼ë¯¸í„° ë™ê¸°í™”
            if 'rag' in current_settings:
                rag_settings = current_settings['rag']
                rag_param_mapping = {
                    'top_k': 'rag_top_k',
                    'min_score': 'min_similarity',
                    'context_window': 'context_window',
                    'chunk_size': 'chunk_size',
                    'chunk_overlap': 'chunk_overlap',
                    'embed_model': 'embedding_model'
                }
                for backend_key, session_key in rag_param_mapping.items():
                    if backend_key in rag_settings:
                        st.session_state[f'backend_{session_key}'] = rag_settings[backend_key]

            # ONTOLOGY íŒŒë¼ë¯¸í„° ë™ê¸°í™”
            if 'ontology' in current_settings:
                ontology_settings = current_settings['ontology']
                if 'keyword_method' in ontology_settings:
                    st.session_state.backend_keyword_method = ontology_settings['keyword_method']

            return current_settings, None
        else:
            return None, "ì €ì¥ëœ ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"

    except Exception as e:
        return None, f"ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"


# 2. ìˆ˜ì •ëœ ëª¨ë¸ ì„ íƒ ì„¹ì…˜ ë Œë”ë§ í•¨ìˆ˜
def render_model_selection_section(available_models):
    """ëª¨ë¸ ì„ íƒ ì„¹ì…˜ì„ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜"""
    st.write("**ëª¨ë¸ ì„ íƒ**")

    if available_models and len(available_models) > 0:
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ ì ìš©)
        current_selected_model = get_setting_value(
            key="selected_model",
            default_value=available_models[0],
            setting_path=["llm", "model"]  # ë°±ì—”ë“œ ê²½ë¡œ
        )

        # ë°±ì—”ë“œì—ì„œ ì§ì ‘ ollama_modelë„ í™•ì¸
        try:
            backend_settings = api_client.get_settings()
            if 'ollama_model' in backend_settings and backend_settings['ollama_model']:
                if backend_settings['ollama_model'] in available_models:
                    current_selected_model = backend_settings['ollama_model']
        except:
            pass

        # í˜„ì¬ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
        if current_selected_model not in available_models:
            current_selected_model = available_models[0]
            st.warning(f"ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ë¡œ ë³€ê²½: {current_selected_model}")

        # í˜„ì¬ ì¸ë±ìŠ¤ ê³„ì‚°
        try:
            current_index = available_models.index(current_selected_model)
        except ValueError:
            current_index = 0
            current_selected_model = available_models[0]

        # selectbox ë Œë”ë§ (key ì´ë¦„ ë³€ê²½)
        selected_model = st.selectbox(
            "ì‚¬ìš©í•  ëª¨ë¸",
            available_models,
            index=current_index,
            help="ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  LLM ëª¨ë¸",
            key="llm_model_selector"  # â† key ì´ë¦„ ë³€ê²½
        )

        # ëª¨ë¸ ë³€ê²½ ìƒíƒœ í‘œì‹œ
        if current_selected_model != selected_model:
            st.info(f"ì €ì¥ëœ ëª¨ë¸: `{current_selected_model}` â†’ ë³€ê²½ë¨: `{selected_model}`")
        else:
            st.success(f"í˜„ì¬ ëª¨ë¸: `{current_selected_model}`")

        # ë³„ë„ì˜ ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ì— ì €ì¥
        st.session_state.current_selected_model = selected_model

        return selected_model

    else:
        ErrorDisplay.render_error_with_suggestions(
            "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤",
            [
                "Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸",
                "ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (`ollama list`)",
                "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸",
                "API ì„œë²„ ë¡œê·¸ í™•ì¸"
            ]
        )
        st.session_state.current_selected_model = None
        return None


# 3. ìˆ˜ì •ëœ ì„¤ì • ì €ì¥ í•¨ìˆ˜ì˜ ì¼ë¶€ (UI ê°’ ìˆ˜ì§‘ ë¶€ë¶„)
def get_ui_values_for_saving():
    """ì„¤ì • ì €ì¥ì„ ìœ„í•œ UI ê°’ë“¤ì„ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜"""
    return {
        'ollama_host': st.session_state.get('ollama_host_input', '').strip(),
        'selected_model': st.session_state.get('current_selected_model'),  # â˜… ìˆ˜ì •ëœ ë³€ìˆ˜ëª… â˜…
        'auto_refresh': st.session_state.get('auto_refresh_models', False),
        'api_timeout': st.session_state.get('api_timeout_slider', config.api.timeout),
        'rag_timeout': st.session_state.get('rag_timeout_slider', config.api.timeout),
        'temperature': st.session_state.get('temperature_slider', Constants.Defaults.TEMPERATURE),
        'max_tokens': st.session_state.get('max_tokens_input', Constants.Defaults.MAX_TOKENS),
        'top_p': st.session_state.get('top_p_slider', 0.9),
        'frequency_penalty': st.session_state.get('frequency_penalty_slider', 0.0),
        'system_prompt': st.session_state.get('system_prompt_area', Constants.Defaults.SYSTEM_PROMPT),
        'rag_top_k': st.session_state.get('rag_top_k_slider', Constants.Defaults.TOP_K),
        'min_similarity': st.session_state.get('min_similarity_slider', Constants.Defaults.MIN_SIMILARITY),
        'context_window': st.session_state.get('context_window_input', Constants.Defaults.CONTEXT_WINDOW),
        'chunk_size': st.session_state.get('chunk_size_input', Constants.Defaults.CHUNK_SIZE),
        'chunk_overlap': st.session_state.get('chunk_overlap_input', Constants.Defaults.CHUNK_OVERLAP),
        'embedding_model': st.session_state.get('embedding_model_select', Constants.Defaults.EMBEDDING_MODEL),
        'keyword_method': st.session_state.get('current_keyword_method', 'keybert')
    }


# 4. ìˆ˜ì •ëœ ì„¤ì • ì €ì¥ í›„ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_session_after_save(settings_data):
    """ì„¤ì • ì €ì¥ í›„ ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    # LLM ì„¤ì • ì—…ë°ì´íŠ¸
    for key, value in settings_data["llm"].items():
        st.session_state[key] = value

    # RAG ì„¤ì • ì—…ë°ì´íŠ¸
    rag_mapping = {
        "top_k": "rag_top_k",
        "min_score": "min_similarity",
        "context_window": "context_window",
        "chunk_size": "chunk_size",
        "chunk_overlap": "chunk_overlap",
        "embed_model": "embedding_model"
    }
    for rag_key, session_key in rag_mapping.items():
        st.session_state[session_key] = settings_data["rag"][rag_key]

    # â˜… ëª¨ë¸ ë° Ontology ì„¤ì • ì—…ë°ì´íŠ¸ ìˆ˜ì • â˜…
    st.session_state.current_selected_model = settings_data["ollama_model"]
    st.session_state.backend_selected_model = settings_data["ollama_model"]
    st.session_state.current_keyword_method = settings_data["ontology"]["keyword_method"]
    st.session_state.backend_keyword_method = settings_data["ontology"]["keyword_method"]

    # ê¸°ë³¸ ì„¤ì • ì—…ë°ì´íŠ¸
    st.session_state.ollama_host = settings_data["ollama_host"]


# 5. ê°œì„ ëœ ê¸°ë³¸ê°’ íšë“ í•¨ìˆ˜
def get_setting_value(key, default_value, setting_path=None):
    """ì„¤ì • ê°’ì„ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

    ìš°ì„ ìˆœìœ„:
    1. ì„¸ì…˜ ìƒíƒœì˜ backend_ ê°’
    2. í˜„ì¬ ë°±ì—”ë“œ ì„¤ì •
    3. ì„¸ì…˜ ìƒíƒœ ê°’
    4. ê¸°ë³¸ê°’
    """
    # 1. ì„¸ì…˜ ìƒíƒœì˜ backend_ ê°’
    backend_key = f"backend_{key}"
    if backend_key in st.session_state:
        return st.session_state[backend_key]

    # 2. í˜„ì¬ ë°±ì—”ë“œ ì„¤ì • (ì‹¤ì‹œê°„)
    try:
        backend_settings = api_client.get_settings()
        if setting_path and backend_settings:
            nested_value = backend_settings
            for path_key in setting_path:
                if isinstance(nested_value, dict) and path_key in nested_value:
                    nested_value = nested_value[path_key]
                else:
                    nested_value = None
                    break
            if nested_value is not None:
                return nested_value
    except:
        pass

    # 3. ì„¸ì…˜ ìƒíƒœ ê°’
    if key in st.session_state:
        return st.session_state[key]

    # 4. ê¸°ë³¸ê°’
    return default_value


# 6. ìˆ˜ì •ëœ í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì„¤ì • í•¨ìˆ˜
def render_keyword_extractor_settings():
    """í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì„¤ì • UIë¥¼ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜"""
    st.subheader("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì„¤ì •")

    # ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜
    keyword_options = ["keybert", "llm", "keybert,llm"]

    # í˜„ì¬ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ ì ìš©)
    current_keyword_method = get_setting_value(
        key="keyword_method",
        default_value="keybert",
        setting_path=["ontology", "keyword_method"]
    )

    # í˜„ì¬ ê°’ì´ ì˜µì…˜ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¸ë±ìŠ¤ ê³„ì‚°
    try:
        current_index = keyword_options.index(current_keyword_method)
    except ValueError:
        # í˜„ì¬ ê°’ì´ ì˜µì…˜ì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        current_index = 0
        current_keyword_method = keyword_options[0]

    # selectbox ë Œë”ë§ (key ì´ë¦„ ë³€ê²½)
    selected_method = st.selectbox(
        "ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë°©ì‹",
        keyword_options,
        index=current_index,
        help="ì˜¨í†¨ë¡œì§€ ì¶”ì¶œ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤.",
        key="keyword_method_selector"  # â† key ì´ë¦„ ë³€ê²½
    )

    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    if current_keyword_method != selected_method:
        st.info(f"í˜„ì¬ ì €ì¥ëœ ì„¤ì •: `{current_keyword_method}` â†’ ë³€ê²½ë¨: `{selected_method}`")
    else:
        st.success(f"í˜„ì¬ ì„¤ì •: `{current_keyword_method}`")

    # ë³„ë„ì˜ ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ì— ì €ì¥
    st.session_state.current_keyword_method = selected_method

    # ì„¤ì • ì„¤ëª…
    with st.expander("í‚¤ì›Œë“œ ì¶”ì¶œ ë°©ì‹ ì„¤ëª…"):
        st.write("**keybert**: KeyBERT ëª¨ë¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¹ ë¦„, ì•ˆì •ì )")
        st.write("**llm**: LLM ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (ì •í™•í•¨, ëŠë¦¼)")
        st.write("**keybert,llm**: ë‘ ë°©ì‹ì„ ë³‘í•©í•˜ì—¬ ì‚¬ìš© (ê°€ì¥ ì •í™•í•¨, ê°€ì¥ ëŠë¦¼)")


# 7. ê°œì„ ëœ ì„¤ì • ì €ì¥ í•¨ìˆ˜
def save_all_settings_optimized():
    """ëª¨ë“  ì„¤ì •ì„ ì„œë²„ì— ì €ì¥í•˜ëŠ” ìµœì í™”ëœ í•¨ìˆ˜"""
    try:
        ui_values = get_ui_values_for_saving()

        # Config.py êµ¬ì¡°ì— ë§ì¶˜ ì„¤ì • ë°ì´í„° êµ¬ì„±
        settings_data = {
            "ollama_host": ui_values['ollama_host'],
            "ollama_model": ui_values['selected_model'],
            "llm": {
                "model": ui_values['selected_model'],
                "auto_refresh": ui_values['auto_refresh'],
                "api_timeout": ui_values['api_timeout'],
                "rag_timeout": ui_values['rag_timeout'],
                "temperature": ui_values['temperature'],
                "max_tokens": ui_values['max_tokens'],
                "top_p": ui_values['top_p'],
                "frequency_penalty": ui_values['frequency_penalty'],
                "system_prompt": ui_values['system_prompt']
            },
            "rag": {
                "top_k": ui_values['rag_top_k'],
                "min_score": ui_values['min_similarity'],
                "context_window": ui_values['context_window'],
                "chunk_size": ui_values['chunk_size'],
                "chunk_overlap": ui_values['chunk_overlap'],
                "embed_model": ui_values['embedding_model']
            },
            "ontology": {  # â˜… ontology ì„¹ì…˜ ì¶”ê°€ â˜…
                "keyword_method": ui_values['keyword_method']
            }
        }

        # ì„œë²„ì— ì„¤ì • ì €ì¥
        with st.spinner("ì„¤ì •ì„ ì €ì¥í•˜ëŠ” ì¤‘..."):
            st.info("ì„œë²„ì— ì„¤ì •ì„ ì €ì¥í•˜ëŠ” ì¤‘...")
            resp = api_client.update_settings(settings_data)

            if resp.get("status") == "ok":
                st.success("âœ… ì„œë²„ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")

                # ë¡œì»¬ ì„¸ì…˜ ìƒíƒœë„ ì—…ë°ì´íŠ¸
                st.info("ë¡œì»¬ ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì¤‘...")

                # LLM ì„¤ì • ì—…ë°ì´íŠ¸
                update_session_after_save(settings_data)

                st.success("âœ… ë¡œì»¬ ì„¸ì…˜ ìƒíƒœë„ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤")
                return True, "ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"

            elif resp.get("status") == "error":
                error_msg = f"ì„œë²„ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {resp.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                st.error(f"âŒ {error_msg}")
                return False, error_msg
            else:
                warning_msg = f"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ: {resp}"
                st.warning(f"âš ï¸ {warning_msg}")
                return False, warning_msg

    except Exception as e:
        error_msg = f"ì„¤ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        st.error(f"âŒ {error_msg}")
        return False, error_msg


# 8. ë©”ì¸ ì„¤ì • ë™ê¸°í™” ì‹¤í–‰ í•¨ìˆ˜ (í˜ì´ì§€ ë¡œë”© ì‹œ)
def initialize_settings_sync():
    """í˜ì´ì§€ ë¡œë”© ì‹œ ì„¤ì • ë™ê¸°í™”ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    if 'settings_loaded' not in st.session_state:
        with st.spinner("ì €ì¥ëœ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            settings, error_msg = sync_backend_settings_to_session()

            if settings:
                st.success(f"âœ… ì €ì¥ëœ ì„¤ì •ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ ({len(settings)}ê°œ ì¹´í…Œê³ ë¦¬)")

                # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ì„ íƒì )
                if st.checkbox("ë¶ˆëŸ¬ì˜¨ ì„¤ì • ìƒì„¸ë³´ê¸°", key="show_loaded_settings"):
                    with st.expander("ë¶ˆëŸ¬ì˜¨ ì„¤ì • ë‚´ìš©"):
                        st.json(settings)
            else:
                if error_msg:
                    st.warning(f"âš ï¸ {error_msg}")
                st.info("ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")

            # ë¡œë”© ì™„ë£Œ í‘œì‹œ
            st.session_state.settings_loaded = True


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=f"{config.ui.page_title} - ì„¤ì •",
    page_icon=Constants.Icons.SETTINGS,
    layout=config.ui.layout
)

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if HAS_API_CLIENT:
    api_client = ClientManager.get_client()
else:
    st.error("API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    st.stop()

# í—¤ë”
st.title(f"{Constants.Icons.SETTINGS} ì‹œìŠ¤í…œ ì„¤ì •")
st.markdown("GTOne RAG ì‹œìŠ¤í…œì˜ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")

# ì„¤ì • íƒ­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    f"{Constants.Icons.AI} AI ì„¤ì •",
    f"{Constants.Icons.STATUS_INFO} ì‹œìŠ¤í…œ ìƒíƒœ",
    f"{Constants.Icons.SETTINGS} ê³ ê¸‰ ì„¤ì •",
    f"{Constants.Icons.DOWNLOAD} ë°±ì—…/ë³µì›",
    f"{Constants.Icons.STATUS_INFO} ì •ë³´"
])

# ===============================
# AI ì„¤ì • íƒ­ - í†µí•©ëœ LLM ì„¤ì •
# ===============================
with tab1:
    st.header(f"AI ì„¤ì •")

    # ===============================
    # í˜ì´ì§€ ë¡œë”© ì‹œ ë°±ì—”ë“œ ì„¤ì • ë™ê¸°í™”
    # ===============================

    # í˜ì´ì§€ ë¡œë”© ì‹œ ì„¤ì • ë™ê¸°í™” - ê°œì„ ëœ ë²„ì „
    initialize_settings_sync()

    # ì„¤ì • ë™ê¸°í™” ìƒíƒœ í‘œì‹œ
    with st.expander("ğŸ”„ ì„¤ì • ë™ê¸°í™” ìƒíƒœ", expanded=False):
        col_sync1, col_sync2 = st.columns(2)

        with col_sync1:
            if st.button("ğŸ”„ ì„¤ì • ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key="reload_settings_btn"):
                with st.spinner("ì„¤ì •ì„ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    try:
                        current_settings = api_client.get_settings()
                        st.success(f"âœ… ì„¤ì • ì¬ë¡œë”© ì™„ë£Œ")

                        with st.expander("ë¶ˆëŸ¬ì˜¨ ì„¤ì • ë‚´ìš©"):
                            st.json(current_settings)

                        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í›„ ë‹¤ì‹œ ë¡œë”©
                        st.session_state.settings_loaded = False
                        st.info("ğŸ”„ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì„¤ì •ì„ ì ìš©í•˜ì„¸ìš”")

                    except Exception as e:
                        st.error(f"âŒ ì„¤ì • ì¬ë¡œë”© ì‹¤íŒ¨: {str(e)}")

        with col_sync2:
            if st.button("ğŸ” ì„¤ì • íŒŒì¼ ìƒíƒœ", key="check_settings_file"):
                with st.spinner("ì„¤ì • íŒŒì¼ ìƒíƒœ í™•ì¸ ì¤‘..."):
                    try:
                        import requests
                        import os

                        # ë¡œì»¬ íŒŒì¼ ìƒíƒœ í™•ì¸
                        settings_file = "./data/rag_settings.json"
                        file_exists = os.path.exists(settings_file)

                        st.write("**ë¡œì»¬ íŒŒì¼ ìƒíƒœ:**")
                        st.write(f"- íŒŒì¼ ê²½ë¡œ: `{settings_file}`")
                        st.write(f"- íŒŒì¼ ì¡´ì¬: {'âœ…' if file_exists else 'âŒ'}")

                        if file_exists:
                            file_size = os.path.getsize(settings_file)
                            st.write(f"- íŒŒì¼ í¬ê¸°: {file_size} bytes")

                            # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                            try:
                                with open(settings_file, 'r', encoding='utf-8') as f:
                                    content = f.read()

                                with st.expander("íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                                    st.code(content, language="json")

                            except Exception as e:
                                st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")

                        # ë°±ì—”ë“œ API í™•ì¸
                        st.write("**ë°±ì—”ë“œ API ìƒíƒœ:**")
                        current_settings = api_client.get_settings()
                        st.success("âœ… ë°±ì—”ë“œ API ì •ìƒ ì‘ë™")
                        st.write(f"ë°˜í™˜ëœ ì„¤ì • ì¹´í…Œê³ ë¦¬: {list(current_settings.keys())}")

                    except Exception as e:
                        st.error(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

    # ì—°ê²° ìƒíƒœ í™•ì¸ ì„¹ì…˜
    st.subheader(f"{Constants.Icons.STATUS_OK} ì—°ê²° ìƒíƒœ")

    # ì—°ê²° í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    if st.button(f"{Constants.Icons.REFRESH} ì—°ê²° í…ŒìŠ¤íŠ¸", key="connection_test_btn"):
        with st.spinner("ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘..."):
            if HAS_SYSTEM_HEALTH:
                with ErrorContext("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸") as ctx:
                    try:
                        health_report = SystemHealthManager.check_full_system_status(api_client, force_refresh=True)
                        st.session_state.connection_status = health_report
                        st.session_state.last_connection_check = datetime.now()
                    except Exception as e:
                        ctx.add_error(e)
            else:
                # Fallback: ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
                with ErrorContext("ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸") as ctx:
                    try:
                        response = api_client.health_check()
                        st.session_state.connection_status = response
                        st.session_state.last_connection_check = datetime.now()
                    except Exception as e:
                        ctx.add_error(e)

    # ì—°ê²° ìƒíƒœ í‘œì‹œ
    if 'connection_status' in st.session_state:
        check_time = st.session_state.get('last_connection_check')

        if HAS_SYSTEM_HEALTH and hasattr(st.session_state.connection_status, 'overall_status'):
            health_report = st.session_state.connection_status
            emoji, message, _ = SystemHealthManager.get_status_display_info(health_report.overall_status)

            if health_report.overall_status == SystemStatus.HEALTHY:
                StatusIndicator.render_status("success", f"{message} ({check_time.strftime('%H:%M:%S')})")
            elif health_report.overall_status == SystemStatus.DEGRADED:
                StatusIndicator.render_status("warning", f"{message} ({check_time.strftime('%H:%M:%S')})")
            else:
                StatusIndicator.render_status("error", f"{message} ({check_time.strftime('%H:%M:%S')})")

            # ì„œë¹„ìŠ¤ ìš”ì•½
            services_summary = []
            for service_name, service_info in list(health_report.services.items())[:3]:
                emoji_svc, status_text = SystemHealthManager.get_service_display_info(service_info.status)
                services_summary.append(f"{emoji_svc} {service_name}: {status_text}")

            if services_summary:
                st.caption(" | ".join(services_summary))

        else:
            # Fallback ìƒíƒœ í‘œì‹œ
            status = st.session_state.connection_status
            if status.get('status') == 'healthy':
                StatusIndicator.render_status("success", f"ì—°ê²° ì„±ê³µ ({check_time.strftime('%H:%M:%S')})")
            else:
                StatusIndicator.render_status("error", f"ì—°ê²° ë¬¸ì œ ({check_time.strftime('%H:%M:%S')})")
    else:
        StatusIndicator.render_status("info", "ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")

    st.divider()

    # í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì„¤ì • - ê°œì„ ëœ ë²„ì „
    render_keyword_extractor_settings()

    # ===============================
    # í†µí•©ëœ LLM ì„¤ì • ì„¹ì…˜
    # ===============================
    st.subheader("LLM (ì–¸ì–´ ëª¨ë¸) ì„¤ì •")

    # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸° - ë°±ì—”ë“œì™€ ì„¸ì…˜ ìƒíƒœ ë³‘í•©
    try:
        backend_settings = api_client.get_settings()
    except:
        backend_settings = {}

    col1, col2 = st.columns(2)

    with col1:
        # === ì„œë²„ ì„¤ì • ===
        st.write("**ì„œë²„ ì„¤ì •**")

        # ë°±ì—”ë“œ ì„¤ì • ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        default_ollama_host = (
                st.session_state.get("backend_ollama_host") or
                backend_settings.get("ollama_host") or
                "http://localhost:11434"
        )

        ollama_host = st.text_input(
            "Ollama Host",
            value=default_ollama_host,
            help="Ollama LLM ì„œë²„ ì£¼ì†Œ",
            key="ollama_host_input"
        )

        # === ë¹ ë¥¸ ì§„ë‹¨ ì„¹ì…˜ ===
        st.write("**ë¹ ë¥¸ ì§„ë‹¨**")
        col_debug1, col_debug2, col_debug3 = st.columns(3)

        with col_debug1:
            if st.button("ğŸ” API ìƒíƒœ", key="quick_debug_api"):
                try:
                    import requests

                    response = requests.get(f"{api_client.base_url}/v1/models", timeout=10)

                    if response.status_code == 200:
                        data = response.json()
                        if isinstance(data, list) and len(data) > 0:
                            st.success(f"âœ… API ì •ìƒ: {len(data)}ê°œ ëª¨ë¸")
                            st.write("ëª¨ë¸:", ", ".join(data[:3]) + ("..." if len(data) > 3 else ""))
                        elif isinstance(data, list) and len(data) == 0:
                            st.warning("âš ï¸ API ì •ìƒì´ì§€ë§Œ ëª¨ë¸ ì—†ìŒ")
                        else:
                            st.info(f"ğŸ“Š ì‘ë‹µ: {type(data)}")
                    else:
                        st.error(f"âŒ API ì˜¤ë¥˜: HTTP {response.status_code}")

                except Exception as e:
                    st.error(f"âŒ API ì—°ê²° ì‹¤íŒ¨: {str(e)}")

        with col_debug2:
            if st.button("ğŸ¤– Ollama", key="quick_debug_ollama"):
                try:
                    import requests

                    response = requests.get("http://localhost:11434/api/tags", timeout=5)

                    if response.status_code == 200:
                        data = response.json()
                        models = data.get("models", [])
                        if models:
                            st.success(f"âœ… Ollama: {len(models)}ê°œ ëª¨ë¸")
                            for model in models[:3]:
                                st.write(f"â€¢ {model.get('name', 'Unknown')}")
                            if len(models) > 3:
                                st.write(f"... ì™¸ {len(models) - 3}ê°œ")
                        else:
                            st.warning("âš ï¸ Ollama ì •ìƒ, ëª¨ë¸ ì—†ìŒ")
                    else:
                        st.error(f"âŒ Ollama ì˜¤ë¥˜: HTTP {response.status_code}")

                except requests.exceptions.ConnectionError:
                    st.error("âŒ Ollama ì„œë²„ ë¯¸ì‹¤í–‰")
                    st.info("í•´ê²°: `ollama serve`")
                except Exception as e:
                    st.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {str(e)}")

        with col_debug3:
            if st.button("ğŸ”§ Backend", key="quick_debug_backend"):
                try:
                    settings = api_client.get_settings()
                    st.success("âœ… Backend ì •ìƒ")

                    models_resp = api_client.get_available_models()
                    if models_resp:
                        st.success(f"âœ… {len(models_resp)}ê°œ ëª¨ë¸ ê°ì§€")
                    else:
                        st.warning("âš ï¸ ëª¨ë¸ ëª©ë¡ ë¹„ì–´ìˆìŒ")

                except Exception as e:
                    st.error(f"âŒ Backend ì˜¤ë¥˜: {str(e)}")

        st.divider()

        # === ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨ ===
        refresh_col, auto_col = st.columns([2, 1])

        with refresh_col:
            if st.button(f"{Constants.Icons.REFRESH} ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨",
                         help="ì„œë²„ì—ì„œ ìµœì‹  ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤", key="refresh_models_btn"):
                with st.spinner("ëª¨ë¸ ëª©ë¡ ë¡œë”© ì¤‘..."):
                    with ErrorContext("ëª¨ë¸ ëª©ë¡ ë¡œë”©") as ctx:
                        try:
                            available_models = api_client.get_available_models()

                            if available_models:
                                st.session_state.available_models = available_models
                                st.session_state.models_last_updated = datetime.now()
                                st.success(f"{Constants.Icons.STATUS_OK} {len(available_models)}ê°œ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤")
                            else:
                                StatusIndicator.render_status("error", "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤",
                                                              "Ollama ì„œë²„ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                                st.session_state.available_models = []

                        except Exception as e:
                            ctx.add_error(e)
                            st.session_state.available_models = []

        with auto_col:
            auto_refresh = st.checkbox("ìë™", help="í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤",
                                       key="auto_refresh_models")

        # ìë™ ë¡œë”© ì²˜ë¦¬
        if 'available_models' not in st.session_state or auto_refresh:
            if auto_refresh or 'available_models' not in st.session_state:
                with st.spinner("ëª¨ë¸ ëª©ë¡ ì´ˆê¸° ë¡œë”© ì¤‘..."):
                    with ErrorContext("ëª¨ë¸ ëª©ë¡ ì´ˆê¸° ë¡œë”©", show_errors=False) as ctx:
                        try:
                            available_models = api_client.get_available_models()
                            st.session_state.available_models = available_models
                            st.session_state.models_last_updated = datetime.now()

                            if not available_models:
                                StatusIndicator.render_status("warning", "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")

                        except Exception as e:
                            ctx.add_error(e)
                            st.session_state.available_models = []

        available_models = st.session_state.get('available_models', [])

        # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ í‘œì‹œ
        if 'models_last_updated' in st.session_state:
            last_updated = st.session_state.models_last_updated
            st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {last_updated.strftime('%H:%M:%S')}")

        selected_model = render_model_selection_section(available_models)

        st.divider()

        # === ì—°ê²° ë° íƒ€ì„ì•„ì›ƒ ì„¤ì • ===
        st.write("**ì—°ê²° ë° íƒ€ì„ì•„ì›ƒ ì„¤ì •**")

        # ë°±ì—”ë“œ ì„¤ì • ìš°ì„  ì‚¬ìš©
        default_api_timeout = (
                backend_settings.get("llm", {}).get("api_timeout") or
                st.session_state.get('api_timeout') or
                config.api.timeout
        )

        default_rag_timeout = (
                backend_settings.get("llm", {}).get("rag_timeout") or
                st.session_state.get('rag_timeout') or
                config.api.timeout
        )

        api_timeout = st.slider(
            "API íƒ€ì„ì•„ì›ƒ (ì´ˆ)",
            min_value=30,
            max_value=600,
            value=int(default_api_timeout),
            step=30,
            help="API ìš”ì²­ì˜ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„",
            key="api_timeout_slider"
        )

        rag_timeout = st.slider(
            "RAG ìƒì„± íƒ€ì„ì•„ì›ƒ (ì´ˆ)",
            min_value=60,
            max_value=900,
            value=int(default_rag_timeout),
            step=30,
            help="ë‹µë³€ ìƒì„±ì˜ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„",
            key="rag_timeout_slider"
        )

        # íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ìš©
        st.session_state.api_timeout = api_timeout
        st.session_state.rag_timeout = rag_timeout
        api_client.set_timeout(api_timeout)

        st.divider()

        # === ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì • ===
        if selected_model:
            st.write("**ëª¨ë¸ íŒŒë¼ë¯¸í„°**")

            # ë°±ì—”ë“œ ì„¤ì •ê³¼ ì„¸ì…˜ ìƒíƒœ ë³‘í•©í•˜ì—¬ ê¸°ë³¸ê°’ ì„¤ì •
            default_temperature = (
                    st.session_state.get("backend_temperature") or
                    backend_settings.get("llm", {}).get("temperature") or
                    st.session_state.get('temperature') or
                    Constants.Defaults.TEMPERATURE
            )

            default_max_tokens = (
                    st.session_state.get("backend_max_tokens") or
                    backend_settings.get("llm", {}).get("max_tokens") or
                    st.session_state.get('max_tokens') or
                    Constants.Defaults.MAX_TOKENS
            )

            temperature = st.slider(
                "Temperature (ì°½ì˜ì„±)",
                min_value=Constants.Limits.MIN_TEMPERATURE,
                max_value=Constants.Limits.MAX_TEMPERATURE,
                value=float(default_temperature),
                step=0.1,
                help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€",
                key="temperature_slider"
            )

            max_tokens = st.number_input(
                "ìµœëŒ€ í† í° ìˆ˜",
                min_value=Constants.Limits.MIN_TOKENS,
                max_value=Constants.Limits.MAX_TOKENS,
                value=int(default_max_tokens),
                step=100,
                help="ìƒì„±í•  ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´",
                key="max_tokens_input"
            )
        else:
            StatusIndicator.render_status("warning", "ëª¨ë¸ì„ ì„ íƒí•´ì•¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    with col2:
        # === ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ ===
        if selected_model:
            with st.expander(f"{Constants.Icons.DOCUMENT} ëª¨ë¸ ì •ë³´", expanded=True):
                with st.spinner("ëª¨ë¸ ì •ë³´ ë¡œë”© ì¤‘..."):
                    with ErrorContext("ëª¨ë¸ ì •ë³´ ë¡œë”©", show_errors=False) as ctx:
                        try:
                            model_info = api_client.get_model_info(selected_model)
                            if 'error' not in model_info:
                                st.write(f"**ëª¨ë¸**: {model_info.get('name', selected_model)}")

                                # ëª¨ë¸ í¬ê¸°
                                if 'size' in model_info:
                                    size_bytes = model_info['size']
                                    if size_bytes > 0:
                                        size_gb = size_bytes / (1024 ** 3)
                                        if size_gb >= 1:
                                            st.write(f"**í¬ê¸°**: {size_gb:.1f} GB")
                                        else:
                                            size_mb = size_bytes / (1024 ** 2)
                                            st.write(f"**í¬ê¸°**: {size_mb:.0f} MB")

                                # ìˆ˜ì •ì¼
                                if 'modified_at' in model_info:
                                    modified_at = model_info['modified_at']
                                    if modified_at:
                                        try:
                                            dt = datetime.fromisoformat(modified_at.replace('Z', '+00:00'))
                                            st.write(f"**ìˆ˜ì •ì¼**: {dt.strftime('%Y-%m-%d %H:%M')}")
                                        except:
                                            st.write(f"**ìˆ˜ì •ì¼**: {modified_at}")

                                # ìƒì„¸ ì •ë³´
                                if 'details' in model_info:
                                    details = model_info['details']
                                    if 'parameter_size' in details:
                                        st.write(f"**íŒŒë¼ë¯¸í„°**: {details['parameter_size']}")
                                    if 'quantization_level' in details:
                                        st.write(f"**ì–‘ìí™”**: {details['quantization_level']}")

                                # ëª¨ë¸ íŒ¨ë°€ë¦¬ ì •ë³´
                                if ':' in selected_model:
                                    family, tag = selected_model.split(':', 1)
                                    st.write(f"**íŒ¨ë°€ë¦¬**: {family}")
                                    st.write(f"**íƒœê·¸**: {tag}")

                            else:
                                st.caption("ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                                st.caption(f"ì˜¤ë¥˜: {model_info.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                        except Exception as e:
                            ctx.add_error(e)

        # === ì¶”ê°€ íŒŒë¼ë¯¸í„° ===
        if selected_model:
            st.write("**ê³ ê¸‰ íŒŒë¼ë¯¸í„°**")

            # ë°±ì—”ë“œ ì„¤ì • ìš°ì„  ì‚¬ìš©
            default_top_p = (
                    st.session_state.get("backend_top_p") or
                    backend_settings.get("llm", {}).get("top_p") or
                    st.session_state.get('top_p') or
                    0.9
            )

            default_frequency_penalty = (
                    st.session_state.get("backend_frequency_penalty") or
                    backend_settings.get("llm", {}).get("frequency_penalty") or
                    st.session_state.get('frequency_penalty') or
                    0.0
            )

            default_system_prompt = (
                    st.session_state.get("backend_system_prompt") or
                    backend_settings.get("llm", {}).get("system_prompt") or
                    st.session_state.get('system_prompt') or
                    Constants.Defaults.SYSTEM_PROMPT
            )

            top_p = st.slider(
                "Top P",
                min_value=0.0,
                max_value=1.0,
                value=float(default_top_p),
                step=0.05,
                help="í™•ë¥  ë¶„í¬ ìƒìœ„ P%ë§Œ ê³ ë ¤",
                key="top_p_slider"
            )

            frequency_penalty = st.slider(
                "Frequency Penalty",
                min_value=0.0,
                max_value=2.0,
                value=float(default_frequency_penalty),
                step=0.1,
                help="ë°˜ë³µ ë‹¨ì–´ ì‚¬ìš© ì–µì œ",
                key="frequency_penalty_slider"
            )

            system_prompt = st.text_area(
                "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
                value=str(default_system_prompt),
                height=150,
                help="AIì˜ ê¸°ë³¸ í–‰ë™ ì§€ì¹¨",
                key="system_prompt_area"
            )
        else:
            StatusIndicator.render_status("info", "ëª¨ë¸ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”")

    st.divider()

    # ===============================
    # RAG ì„¤ì • (ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ)
    # ===============================
    if selected_model:
        st.subheader("RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            # ë°±ì—”ë“œ RAG ì„¤ì • ì‚¬ìš©
            rag_backend = backend_settings.get("rag", {})

            # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
            default_rag_top_k = (
                    st.session_state.get("backend_rag_top_k") or
                    rag_backend.get("top_k") or
                    st.session_state.get('rag_top_k') or
                    Constants.Defaults.TOP_K
            )

            rag_top_k = st.slider(
                "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜",
                min_value=Constants.Limits.MIN_TOP_K,
                max_value=Constants.Limits.MAX_TOP_K,
                value=int(default_rag_top_k),
                help="ë‹µë³€ ìƒì„± ì‹œ ì°¸ì¡°í•  ë¬¸ì„œì˜ ê°œìˆ˜",
                key="rag_top_k_slider"
            )

            # ìµœì†Œ ìœ ì‚¬ë„
            default_min_similarity = (
                    st.session_state.get("backend_min_similarity") or
                    rag_backend.get("min_score") or
                    st.session_state.get('min_similarity') or
                    Constants.Defaults.MIN_SIMILARITY
            )

            min_similarity = st.slider(
                "ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’",
                min_value=Constants.Limits.MIN_SIMILARITY,
                max_value=Constants.Limits.MAX_SIMILARITY,
                value=float(default_min_similarity),
                step=0.05,
                help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¬¸ì„œë§Œ ì‚¬ìš©",
                key="min_similarity_slider"
            )

            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
            default_context_window = (
                    st.session_state.get("backend_context_window") or
                    rag_backend.get("context_window") or
                    st.session_state.get('context_window') or
                    Constants.Defaults.CONTEXT_WINDOW
            )

            context_window = st.number_input(
                "ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°",
                min_value=500,
                max_value=8000,
                value=int(default_context_window),
                step=500,
                help="LLMì— ì œê³µí•  ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´",
                key="context_window_input"
            )

        with col2:
            # ì²­í¬ ì„¤ì •
            default_chunk_size = (
                    st.session_state.get("backend_chunk_size") or
                    rag_backend.get("chunk_size") or
                    st.session_state.get('chunk_size') or
                    Constants.Defaults.CHUNK_SIZE
            )

            default_chunk_overlap = (
                    st.session_state.get("backend_chunk_overlap") or
                    rag_backend.get("chunk_overlap") or
                    st.session_state.get('chunk_overlap') or
                    Constants.Defaults.CHUNK_OVERLAP
            )

            chunk_size = st.number_input(
                "ì²­í¬ í¬ê¸°",
                min_value=100,
                max_value=2000,
                value=int(default_chunk_size),
                step=100,
                help="ë¬¸ì„œë¥¼ ë¶„í• í•˜ëŠ” ê¸°ë³¸ í¬ê¸°",
                key="chunk_size_input"
            )

            chunk_overlap = st.number_input(
                "ì²­í¬ ì¤‘ì²©",
                min_value=0,
                max_value=500,
                value=int(default_chunk_overlap),
                step=50,
                help="ì²­í¬ ê°„ ì¤‘ì²©ë˜ëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´",
                key="chunk_overlap_input"
            )

            # ì„ë² ë”© ëª¨ë¸
            embedding_options = ["intfloat/multilingual-e5-large-instruct", "intfloat/e5-large-v2"]
            default_embedding_model = (
                    st.session_state.get("backend_embedding_model") or
                    rag_backend.get("embed_model") or
                    st.session_state.get('embedding_model') or
                    Constants.Defaults.EMBEDDING_MODEL
            )

            try:
                embedding_index = embedding_options.index(default_embedding_model)
            except ValueError:
                embedding_index = 0

            embedding_model = st.selectbox(
                "ì„ë² ë”© ëª¨ë¸",
                embedding_options,
                index=embedding_index,
                help="ë¬¸ì„œ ë²¡í„°í™”ì— ì‚¬ìš©í•  ëª¨ë¸",
                key="embedding_model_select"
            )
    else:
        StatusIndicator.render_status("warning", "ëª¨ë¸ì„ ì„ íƒí•´ì•¼ RAG ì„¤ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    # ===============================
    # í†µí•©ëœ ì„¤ì • ì €ì¥ ë²„íŠ¼
    # ===============================
    col_save, col_reset, col_test = st.columns([2, 1, 1])

    with col_save:
        if selected_model:
            if st.button(f"{Constants.Icons.DOWNLOAD} ì „ì²´ ì„¤ì • ì €ì¥", type="primary", key="save_all_settings"):
                success, message = save_all_settings_optimized()

                if success:
                    st.success(f"{Constants.Icons.STATUS_OK} {message}")
                    st.info("ğŸ’¡ ì„¤ì •ì´ ./data/rag_settings.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
                else:
                    st.error(f"âŒ {message}")
        else:
            st.button(f"{Constants.Icons.DOWNLOAD} ì „ì²´ ì„¤ì • ì €ì¥", disabled=True,
                      help="ëª¨ë¸ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”", key="save_all_settings_disabled")

    with col_reset:
        if st.button(f"{Constants.Icons.REFRESH} ê¸°ë³¸ê°’ ë³µì›", key="reset_all_settings"):
            if st.session_state.get('confirm_reset_all') != True:
                st.session_state.confirm_reset_all = True
                StatusIndicator.render_status("warning", "ë‹¤ì‹œ í´ë¦­í•˜ë©´ ëª¨ë“  ì„¤ì •ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›ë©ë‹ˆë‹¤")
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›
                defaults = {
                    "temperature": Constants.Defaults.TEMPERATURE,
                    "max_tokens": Constants.Defaults.MAX_TOKENS,
                    "top_p": 0.9,
                    "frequency_penalty": 0.0,
                    "system_prompt": Constants.Defaults.SYSTEM_PROMPT,
                    "rag_top_k": Constants.Defaults.TOP_K,
                    "min_similarity": Constants.Defaults.MIN_SIMILARITY,
                    "context_window": Constants.Defaults.CONTEXT_WINDOW,
                    "chunk_size": Constants.Defaults.CHUNK_SIZE,
                    "chunk_overlap": Constants.Defaults.CHUNK_OVERLAP,
                    "embedding_model": Constants.Defaults.EMBEDDING_MODEL,
                    "api_timeout": config.api.timeout,
                    "rag_timeout": config.api.timeout
                }

                for key, value in defaults.items():
                    st.session_state[key] = value

                # ë°±ì—”ë“œ ì„¤ì • ìºì‹œë„ ì´ˆê¸°í™”
                for key in list(st.session_state.keys()):
                    if key.startswith('backend_'):
                        del st.session_state[key]

                del st.session_state.confirm_reset_all
                st.session_state.settings_loaded = False  # ë‹¤ì‹œ ë¡œë”©í•˜ë„ë¡
                st.success(f"{Constants.Icons.STATUS_OK} ì„¤ì •ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤")
                st.rerun()

    with col_test:
        if selected_model:
            if st.button(f"{Constants.Icons.AI} ëª¨ë¸ í…ŒìŠ¤íŠ¸", key="test_model"):
                with st.spinner("ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘..."):
                    with ErrorContext("ëª¨ë¸ í…ŒìŠ¤íŠ¸") as ctx:
                        try:
                            test_result = api_client.generate_answer(
                                query="ì•ˆë…•í•˜ì„¸ìš”",
                                top_k=1,
                                model=selected_model,
                                timeout=60
                            )

                            if 'error' not in test_result:
                                st.success(f"{Constants.Icons.STATUS_OK} ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                                st.info(f"ì‚¬ìš©ëœ ëª¨ë¸: {selected_model}")

                                # í…ŒìŠ¤íŠ¸ ì‘ë‹µ í‘œì‹œ
                                if 'answer' in test_result:
                                    with st.expander("í…ŒìŠ¤íŠ¸ ì‘ë‹µ ë³´ê¸°"):
                                        st.write(test_result['answer'])
                            else:
                                ErrorDisplay.render_error_with_suggestions(
                                    f"ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_result.get('error')}",
                                    ["ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”", "Ollama ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”"]
                                )
                        except Exception as e:
                            ctx.add_error(e)
        else:
            st.button(f"{Constants.Icons.AI} ëª¨ë¸ í…ŒìŠ¤íŠ¸", disabled=True,
                      help="ëª¨ë¸ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”", key="test_model_disabled")

# ===============================
# ì‹œìŠ¤í…œ ìƒíƒœ íƒ­ - ê°œì„ ëœ ë²„ì „
# ===============================
with tab2:
    st.header(f"{Constants.Icons.STATUS_INFO} ì‹œìŠ¤í…œ ìƒíƒœ")

    # ìƒíƒœ í™•ì¸ ë²„íŠ¼ë“¤
    actions = [
        {
            "label": f"{Constants.Icons.REFRESH} ìƒíƒœ ìƒˆë¡œê³ ì¹¨",
            "key": "refresh_status_main",
            "type": "primary"
        },
        {
            "label": "ìë™ ìƒˆë¡œê³ ì¹¨",
            "key": "auto_refresh_toggle",
            "type": "secondary"
        },
        {
            "label": f"{Constants.Icons.DELETE} ìºì‹œ ì´ˆê¸°í™”",
            "key": "clear_cache_main",
            "type": "secondary"
        }
    ]

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button(actions[0]["label"], type=actions[0]["type"], key=actions[0]["key"]):
            with st.spinner("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘..."):
                if HAS_SYSTEM_HEALTH:
                    with ErrorContext("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸") as ctx:
                        try:
                            health_report = SystemHealthManager.check_full_system_status(api_client, force_refresh=True)
                            st.session_state.last_health_check = health_report
                            st.session_state.health_check_time = datetime.now()
                            st.success(f"{Constants.Icons.STATUS_OK} ìƒíƒœ í™•ì¸ ì™„ë£Œ")
                        except Exception as e:
                            ctx.add_error(e)

    with col2:
        auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨", help="30ì´ˆë§ˆë‹¤ ìë™ìœ¼ë¡œ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤")

    with col3:
        if st.button(actions[2]["label"], key=actions[2]["key"]):
            if HAS_SYSTEM_HEALTH:
                SystemHealthManager.clear_cache()
            # ì„¸ì…˜ ìºì‹œë„ ì´ˆê¸°í™”
            cache_keys = ['system_health_cache', 'last_health_check', 'health_check_time']
            for key in cache_keys:
                if key in st.session_state:
                    del st.session_state[key]
            st.info("ìƒíƒœ ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    if HAS_SYSTEM_HEALTH:
        cached_report = SystemHealthManager.get_cached_status()
        health_report = cached_report or st.session_state.get('last_health_check')

        if health_report and hasattr(health_report, 'overall_status'):
            check_time = health_report.last_updated if cached_report else st.session_state.get('health_check_time', datetime.now())
            st.caption(f"ë§ˆì§€ë§‰ í™•ì¸: {check_time.strftime('%Y-%m-%d %H:%M:%S')}")

            # ì „ì²´ ìƒíƒœ
            emoji, message, _ = SystemHealthManager.get_status_display_info(health_report.overall_status)

            if health_report.overall_status == SystemStatus.HEALTHY:
                StatusIndicator.render_status("success", message)
            elif health_report.overall_status == SystemStatus.DEGRADED:
                StatusIndicator.render_status("warning", message)
            elif health_report.overall_status == SystemStatus.INITIALIZING:
                StatusIndicator.render_status("info", message)
            else:
                StatusIndicator.render_status("error", message)

            # ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
            if health_report.errors:
                st.subheader(f"{Constants.Icons.STATUS_WARNING} ê°ì§€ëœ ë¬¸ì œ")
                ErrorDisplay.render_validation_errors(health_report.errors)

            # ì„œë¹„ìŠ¤ë³„ ìƒíƒœ - ìƒì„¸ í‘œì‹œ
            st.divider()
            st.subheader(f"{Constants.Icons.SETTINGS} ì„œë¹„ìŠ¤ ìƒíƒœ")

            service_display_names = {
                'api_server': f'{Constants.Icons.STATUS_OK} API ì„œë²„',
                'qdrant': f'{Constants.Icons.STATUS_OK} Qdrant ë²¡í„° DB',
                'ollama': f'{Constants.Icons.AI} Ollama LLM',
                'embedder': 'ğŸ”¤ ì„ë² ë”© ëª¨ë¸',
                'celery': 'ğŸ“¨ Celery ì‘ì—… í'
            }

            for service_key, display_name in service_display_names.items():
                if service_key in health_report.services:
                    service_info = health_report.services[service_key]
                    emoji, status_text = SystemHealthManager.get_service_display_info(service_info.status)

                    with st.expander(f"{emoji} {display_name}: {status_text}",
                                   expanded=(service_info.status != ServiceStatus.CONNECTED)):
                        col1, col2 = st.columns([2, 1])

                        with col1:
                            st.write(f"**ìƒíƒœ**: {service_info.status.value}")
                            if service_info.message:
                                st.write(f"**ë©”ì‹œì§€**: {service_info.message}")
                            st.write(f"**í™•ì¸ ì‹œê°„**: {service_info.last_check.strftime('%H:%M:%S')}")

                        with col2:
                            # ì„œë¹„ìŠ¤ë³„ ì„¸ë¶€ ì •ë³´ í‘œì‹œ
                            if service_info.details:
                                st.write("**ì„¸ë¶€ ì •ë³´**:")
                                for key, value in service_info.details.items():
                                    if isinstance(value, list) and len(value) > 3:
                                        st.caption(f"â€¢ {key}: {len(value)}ê°œ ({', '.join(value[:3])}...)")
                                    elif isinstance(value, (int, float)) and key.endswith('_ratio'):
                                        st.caption(f"â€¢ {key}: {value:.1%}")
                                    else:
                                        st.caption(f"â€¢ {key}: {value}")

            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            st.divider()
            st.subheader(f"{Constants.Icons.STATUS_INFO} ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­")

            metrics = []

            # Qdrant ì»¬ë ‰ì…˜ ìˆ˜
            qdrant_info = health_report.services.get('qdrant')
            if qdrant_info and qdrant_info.details:
                collections = qdrant_info.details.get('collections', [])
                metrics.append({"title": "Qdrant ì»¬ë ‰ì…˜", "value": len(collections)})
            else:
                metrics.append({"title": "Qdrant ì»¬ë ‰ì…˜", "value": "N/A"})

            # Ollama ëª¨ë¸ ìˆ˜
            ollama_info = health_report.services.get('ollama')
            if ollama_info and ollama_info.details:
                total_models = ollama_info.details.get('total_models', 0)
                metrics.append({"title": "Ollama ëª¨ë¸", "value": total_models})
            else:
                metrics.append({"title": "Ollama ëª¨ë¸", "value": "N/A"})

            # í•œêµ­ì–´ ì»¨í…ì¸  ë¹„ìœ¨
            if qdrant_info and qdrant_info.details:
                korean_ratio = qdrant_info.details.get('korean_content_ratio', 0)
                metrics.append({"title": "í•œêµ­ì–´ ë¹„ìœ¨", "value": f"{korean_ratio:.1%}"})
            else:
                metrics.append({"title": "í•œêµ­ì–´ ë¹„ìœ¨", "value": "N/A"})

            # ìºì‹œ ë§Œë£Œ ì‹œê°„
            if cached_report:
                expires_in = (cached_report.cache_expires - datetime.now()).total_seconds()
                if expires_in > 0:
                    metrics.append({"title": "ìºì‹œ ë§Œë£Œ", "value": f"{int(expires_in)}ì´ˆ í›„"})
                else:
                    metrics.append({"title": "ìºì‹œ ë§Œë£Œ", "value": "ë§Œë£Œë¨"})
            else:
                metrics.append({"title": "ìºì‹œ ë§Œë£Œ", "value": "N/A"})

            MetricCard.render_metric_grid(metrics)

        else:
            StatusIndicator.render_status("info", "ìƒíƒœ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")

            if st.button("ìë™ ìƒíƒœ í™•ì¸", key="auto_health_check"):
                with st.spinner("ì‹œìŠ¤í…œ ìƒíƒœ ìë™ í™•ì¸ ì¤‘..."):
                    with ErrorContext("ìë™ ìƒíƒœ í™•ì¸") as ctx:
                        try:
                            health_report = SystemHealthManager.check_full_system_status(api_client)
                            st.session_state.last_health_check = health_report
                            st.session_state.health_check_time = datetime.now()
                            st.rerun()
                        except Exception as e:
                            ctx.add_error(e)
    else:
        StatusIndicator.render_status("warning", "ì‹œìŠ¤í…œ ìƒíƒœ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ìë™ ìƒˆë¡œê³ ì¹¨ ì²˜ë¦¬
    if auto_refresh and HAS_SYSTEM_HEALTH:
        cached_report = SystemHealthManager.get_cached_status()
        if cached_report:
            expires_in = (cached_report.cache_expires - datetime.now()).total_seconds()
            if expires_in <= 0:
                st.rerun()

# ===============================
# ê³ ê¸‰ ì„¤ì • íƒ­
# ===============================
with tab3:
    st.header(f"{Constants.Icons.SETTINGS} ê³ ê¸‰ ì„¤ì •")

    # ë²¡í„° DB ì„¤ì •
    st.subheader("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        # Qdrant ì„¤ì •
        qdrant_host = st.text_input(
            "Qdrant í˜¸ìŠ¤íŠ¸",
            value="qdrant",
            help="Qdrant ì„œë²„ ì£¼ì†Œ"
        )

        qdrant_port = st.number_input(
            "Qdrant í¬íŠ¸",
            value=6333,
            help="Qdrant ì„œë²„ í¬íŠ¸"
        )

        collection_name = st.text_input(
            "ì»¬ë ‰ì…˜ ì´ë¦„",
            value="chunks",
            help="ë¬¸ì„œë¥¼ ì €ì¥í•  ì»¬ë ‰ì…˜"
        )

    with col2:
        # ì¸ë±ì‹± ì„¤ì •
        vector_size = st.number_input(
            "ë²¡í„° ì°¨ì›",
            value=1024,
            help="ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› ìˆ˜"
        )

        distance_metric = st.selectbox(
            "ê±°ë¦¬ ì¸¡ì • ë°©ë²•",
            ["Cosine", "Euclidean", "Dot Product"],
            help="ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚° ë°©ë²•"
        )

        index_threshold = st.number_input(
            "ì¸ë±ìŠ¤ ì„ê³„ê°’",
            value=10000,
            help="ì¸ë±ìŠ¤ ìµœì í™” ì„ê³„ê°’"
        )

    st.divider()

    # íŒŒì¼ ì„¤ì • - config ì‚¬ìš©
    st.subheader("íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        # íŒŒì¼ í¬ê¸° ì„¤ì •
        max_file_size = st.number_input(
            "ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB)",
            min_value=1,
            max_value=200,
            value=config.file.max_file_size_mb,
            help="ê°œë³„ íŒŒì¼ì˜ ìµœëŒ€ í¬ê¸°"
        )

        max_archive_size = st.number_input(
            "ìµœëŒ€ ì••ì¶• íŒŒì¼ í¬ê¸° (MB)",
            min_value=1,
            max_value=500,
            value=config.file.max_archive_size_mb,
            help="ì••ì¶• íŒŒì¼ì˜ ìµœëŒ€ í¬ê¸°"
        )

    with col2:
        # ì§€ì› í™•ì¥ì
        st.write("**ì§€ì› íŒŒì¼ í™•ì¥ì**")

        # ë¬¸ì„œ íŒŒì¼
        doc_extensions = st.multiselect(
            "ë¬¸ì„œ íŒŒì¼",
            ['pdf', 'txt', 'docx', 'doc', 'md', 'rtf'],
            default=['pdf', 'txt', 'docx', 'doc'],
            help="ì§€ì›í•  ë¬¸ì„œ íŒŒì¼ í˜•ì‹"
        )

        # ì´ë¯¸ì§€ íŒŒì¼
        img_extensions = st.multiselect(
            "ì´ë¯¸ì§€ íŒŒì¼",
            ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff'],
            default=['png', 'jpg', 'jpeg'],
            help="ì§€ì›í•  ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹"
        )

    # ê³ ê¸‰ ì„¤ì • ì €ì¥
    if st.button(f"{Constants.Icons.DOWNLOAD} ê³ ê¸‰ ì„¤ì • ì €ì¥", type="primary"):
        advanced_settings = {
            "vector_db": {
                "host": qdrant_host,
                "port": qdrant_port,
                "collection": collection_name,
                "vector_size": vector_size,
                "distance_metric": distance_metric,
                "index_threshold": index_threshold
            },
            "file": {
                "max_file_size_mb": max_file_size,
                "max_archive_size_mb": max_archive_size,
                "allowed_extensions": doc_extensions + img_extensions
            }
        }

        st.session_state.advanced_settings = advanced_settings
        st.success(f"{Constants.Icons.STATUS_OK} ê³ ê¸‰ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")

# ===============================
# ë°±ì—…/ë³µì› íƒ­
# ===============================
with tab4:
    st.header(f"{Constants.Icons.DOWNLOAD} ë°±ì—… ë° ë³µì›")

    # ë°±ì—…
    st.subheader(f"{Constants.Icons.UPLOAD} ë°±ì—…")

    backup_options = st.multiselect(
        "ë°±ì—…í•  í•­ëª© ì„ íƒ",
        ["ì„¤ì •", "ëŒ€í™” ê¸°ë¡", "ê²€ìƒ‰ ê¸°ë¡", "ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡"],
        default=["ì„¤ì •", "ëŒ€í™” ê¸°ë¡"]
    )

    if st.button(f"{Constants.Icons.DOWNLOAD} ë°±ì—… ìƒì„±", type="primary"):
        backup_data = {
            "created_at": datetime.now().isoformat(),
            "version": "1.0.0"
        }

        if "ì„¤ì •" in backup_options:
            backup_data["settings"] = {
                "ai": st.session_state.get("ai_settings", {}),
                "advanced": st.session_state.get("advanced_settings", {})
            }

        if "ëŒ€í™” ê¸°ë¡" in backup_options:
            backup_data["messages"] = st.session_state.get("messages", [])

        if "ê²€ìƒ‰ ê¸°ë¡" in backup_options:
            backup_data["search_history"] = st.session_state.get("search_history", [])

        if "ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡" in backup_options:
            backup_data["uploaded_files"] = st.session_state.get("uploaded_files", [])

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label=f"{Constants.Icons.DOWNLOAD} ë°±ì—… ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(backup_data, ensure_ascii=False, indent=2),
            file_name=f"gtone_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

    st.divider()

    # ë³µì›
    st.subheader(f"{Constants.Icons.UPLOAD} ë³µì›")

    uploaded_backup = st.file_uploader(
        "ë°±ì—… íŒŒì¼ ì„ íƒ",
        type=["json"],
        help="ì´ì „ì— ìƒì„±í•œ ë°±ì—… íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )

    if uploaded_backup is not None:
        with ErrorContext("ë°±ì—… íŒŒì¼ ì²˜ë¦¬") as ctx:
            try:
                backup_data = json.loads(uploaded_backup.read())

                st.info(f"ë°±ì—… ìƒì„± ì‹œê°„: {backup_data.get('created_at', 'N/A')}")

                # ë³µì› ê°€ëŠ¥í•œ í•­ëª© í‘œì‹œ
                available_items = []
                if "settings" in backup_data:
                    available_items.append("ì„¤ì •")
                if "messages" in backup_data:
                    available_items.append(f"ëŒ€í™” ê¸°ë¡ ({len(backup_data['messages'])}ê°œ)")
                if "search_history" in backup_data:
                    available_items.append(f"ê²€ìƒ‰ ê¸°ë¡ ({len(backup_data['search_history'])}ê°œ)")
                if "uploaded_files" in backup_data:
                    available_items.append(f"ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡ ({len(backup_data['uploaded_files'])}ê°œ)")

                restore_items = st.multiselect(
                    "ë³µì›í•  í•­ëª© ì„ íƒ",
                    available_items,
                    default=available_items
                )

                if st.button(f"{Constants.Icons.REFRESH} ë³µì› ì‹¤í–‰", type="secondary"):
                    # ë³µì› ì‹¤í–‰
                    if "ì„¤ì •" in restore_items and "settings" in backup_data:
                        st.session_state.ai_settings = backup_data["settings"].get("ai", {})
                        st.session_state.advanced_settings = backup_data["settings"].get("advanced", {})

                    if any("ëŒ€í™” ê¸°ë¡" in item for item in restore_items) and "messages" in backup_data:
                        st.session_state.messages = backup_data["messages"]

                    if any("ê²€ìƒ‰ ê¸°ë¡" in item for item in restore_items) and "search_history" in backup_data:
                        st.session_state.search_history = backup_data["search_history"]

                    if any("ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡" in item for item in restore_items) and "uploaded_files" in backup_data:
                        st.session_state.uploaded_files = backup_data["uploaded_files"]

                    st.success(f"{Constants.Icons.STATUS_OK} ë³µì›ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                    rerun()

            except Exception as e:
                ctx.add_error(e)

# ===============================
# ì •ë³´ íƒ­
# ===============================
with tab5:
    st.header(f"{Constants.Icons.STATUS_INFO} ì‹œìŠ¤í…œ ì •ë³´")

    # ì‹œìŠ¤í…œ ì •ë³´
    st.subheader("ì‹œìŠ¤í…œ ì •ë³´")

    col1, col2 = st.columns(2)

    with col1:
        st.write("**ë²„ì „**")
        st.code("GTOne RAG System v1.0.0")

        st.write("**Python ë²„ì „**")
        st.code("Python 3.11+")

        st.write("**í”„ë ˆì„ì›Œí¬**")
        st.code("FastAPI + Streamlit")

    with col2:
        st.write("**ë²¡í„° DB**")
        st.code("Qdrant v1.9.3")

        st.write("**ì„ë² ë”© ëª¨ë¸**")
        st.code("E5-large-instruct")

        st.write("**LLM ì„œë²„**")
        st.code("Ollama (External)")

    st.divider()

    # ì„¤ì • ì •ë³´ - config ì‚¬ìš©
    st.subheader("í˜„ì¬ ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        st.write("**í™˜ê²½ ì„¤ì •**")
        st.write(f"â€¢ í™˜ê²½: {config.environment.value}")
        st.write(f"â€¢ API URL: {config.api.base_url}")
        st.write(f"â€¢ API íƒ€ì„ì•„ì›ƒ: {config.api.timeout}ì´ˆ")

    with col2:
        st.write("**íŒŒì¼ ì„¤ì •**")
        st.write(f"â€¢ ìµœëŒ€ íŒŒì¼ í¬ê¸°: {config.file.max_file_size_mb}MB")
        st.write(f"â€¢ ìµœëŒ€ ì••ì¶• íŒŒì¼: {config.file.max_archive_size_mb}MB")
        st.write(f"â€¢ ì§€ì› í™•ì¥ì: {len(config.file.allowed_extensions)}ê°œ")

    st.divider()

    # ë¼ì´ì„ ìŠ¤
    st.subheader("ë¼ì´ì„ ìŠ¤")
    st.text("""
    MIT License
    
    Copyright (c) 2024 GTOne
    
    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction...
    """)

    st.divider()

    # ë„ì›€ë§
    st.subheader("ë„ì›€ë§ ë° ì§€ì›")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(f"[{Constants.Icons.DOCUMENT} ì‚¬ìš©ì ê°€ì´ë“œ]({Constants.URLs.GITHUB}/wiki)")

    with col2:
        st.markdown(f"[{Constants.Icons.STATUS_ERROR} ë²„ê·¸ ë¦¬í¬íŠ¸]({Constants.URLs.GITHUB}/issues)")

    with col3:
        st.markdown(f"[{Constants.Icons.AI} ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/selmo)")

    # ì—°ë½ì²˜ - ìƒìˆ˜ ì‚¬ìš©
    st.divider()
    st.caption(f"ë¬¸ì˜: {Constants.URLs.SUPPORT_EMAIL} | ê¸°ìˆ  ì§€ì›: tech@gtone.com")

# í‘¸í„°
st.divider()
st.caption(f"{Constants.Icons.STATUS_INFO} ì„¤ì • ë³€ê²½ í›„ì—ëŠ” ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìƒˆë¡œê³ ì¹¨ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")