import streamlit as st
import requests
import json
import time
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GTOne RAG System",
    page_icon="ğŸ“š",
    layout="wide"
)

# API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
import os

API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ“š GTOne RAG System")

    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    if st.button("ğŸ”„ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"):
        try:
            response = requests.get(f"{API_BASE_URL}/v1/health")
            health_data = response.json()

            st.success("âœ… ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘")

            # Qdrant ìƒíƒœ
            qdrant_status = health_data['services']['qdrant']
            st.write(f"**Qdrant**: {qdrant_status['status']}")
            if qdrant_status['collections']:
                st.write(f"ì»¬ë ‰ì…˜: {', '.join(qdrant_status['collections'])}")

            # Ollama ìƒíƒœ
            ollama_status = health_data['services']['ollama']
            st.write(f"**Ollama**: {ollama_status['status']}")
            if ollama_status['status'] == 'connected':
                st.write(f"í˜¸ìŠ¤íŠ¸: {ollama_status['host']}")
                if ollama_status.get('models'):
                    st.write(f"ëª¨ë¸: {', '.join(ollama_status['models'])}")

        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {str(e)}")

    st.divider()

    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['pdf', 'txt', 'png', 'jpg', 'jpeg', 'docx'],
        help="PDF, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    if uploaded_file is not None:
        if st.button("ğŸ“¤ ì—…ë¡œë“œ", type="primary"):
            with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
                try:
                    files = {"file": (uploaded_file.name, uploaded_file, uploaded_file.type)}
                    response = requests.post(f"{API_BASE_URL}/v1/documents", files=files)

                    if response.status_code == 200:
                        result = response.json()
                        st.success(f"âœ… ì„±ê³µ! {result['uploaded']}ê°œ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.uploaded_files.append({
                            'name': uploaded_file.name,
                            'time': datetime.now().strftime("%Y-%m-%d %H:%M"),
                            'chunks': result['uploaded']
                        })
                    else:
                        st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {response.text}")

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
    if st.session_state.uploaded_files:
        st.divider()
        st.header("ğŸ“ ì—…ë¡œë“œëœ ë¬¸ì„œ")
        for file in st.session_state.uploaded_files[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            st.write(f"â€¢ {file['name']}")
            st.caption(f"  {file['time']} | {file['chunks']} chunks")

# ë©”ì¸ ì˜ì—­
st.title("ğŸ¤– GTOne RAG Assistant")
st.markdown("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì±„íŒ…", "ğŸ” ë¬¸ì„œ ê²€ìƒ‰", "âš™ï¸ ì„¤ì •"])

with tab1:
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ
            if message["role"] == "assistant" and "sources" in message:
                with st.expander("ğŸ“Œ ì°¸ì¡° ë¬¸ì„œ"):
                    for idx, source in enumerate(message["sources"], 1):
                        st.write(f"**[ë¬¸ì„œ {idx}]** (ìœ ì‚¬ë„: {source['score']:.3f})")
                        st.text(source['content'])
                        st.divider()

    # ì±„íŒ… ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    # RAG ë‹µë³€ ìš”ì²­
                    response = requests.post(
                        f"{API_BASE_URL}/v1/rag/answer",
                        params={"q": prompt, "top_k": 3}
                    )

                    if response.status_code == 200:
                        result = response.json()

                        # ë‹µë³€ í‘œì‹œ
                        st.markdown(result['answer'])

                        # ë©”ì‹œì§€ ì €ì¥
                        message_data = {
                            "role": "assistant",
                            "content": result['answer']
                        }

                        # ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                        if 'sources' in result and result['sources']:
                            message_data['sources'] = result['sources']

                            with st.expander("ğŸ“Œ ì°¸ì¡° ë¬¸ì„œ"):
                                for idx, source in enumerate(result['sources'], 1):
                                    st.write(f"**[ë¬¸ì„œ {idx}]** (ìœ ì‚¬ë„: {source['score']:.3f})")
                                    st.text(source['content'])
                                    st.divider()

                        st.session_state.messages.append(message_data)

                    else:
                        error_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                        st.error(error_msg)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_msg
                        })

                except Exception as e:
                    error_msg = f"ì˜¤ë¥˜: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": error_msg
                    })

with tab2:
    st.header("ğŸ” ë¬¸ì„œ ê²€ìƒ‰")

    col1, col2 = st.columns([3, 1])

    with col1:
        search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê³„ì•½ ì¡°ê±´")

    with col2:
        top_k = st.number_input("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=10, value=5)

    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        if search_query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                try:
                    response = requests.get(
                        f"{API_BASE_URL}/v1/search",
                        params={"q": search_query, "top_k": top_k}
                    )

                    if response.status_code == 200:
                        results = response.json()

                        if results:
                            st.success(f"{len(results)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

                            for idx, hit in enumerate(results, 1):
                                with st.container():
                                    col1, col2 = st.columns([4, 1])

                                    with col1:
                                        st.markdown(f"**ê²€ìƒ‰ ê²°ê³¼ {idx}**")

                                    with col2:
                                        st.metric("ìœ ì‚¬ë„", f"{hit['score']:.3f}")

                                    st.text_area(
                                        "ë‚´ìš©",
                                        value=hit['content'],
                                        height=150,
                                        disabled=True,
                                        key=f"search_result_{idx}"
                                    )

                                    st.divider()
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        else:
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("âš™ï¸ ì„¤ì •")

    # RAG ì„¤ì •
    st.subheader("RAG ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        rag_top_k = st.slider(
            "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜",
            min_value=1,
            max_value=10,
            value=3,
            help="ë‹µë³€ ìƒì„± ì‹œ ì°¸ì¡°í•  ë¬¸ì„œì˜ ê°œìˆ˜"
        )

    with col2:
        temperature = st.slider(
            "ë‹µë³€ ì°½ì˜ì„± (Temperature)",
            min_value=0.0,
            max_value=1.0,
            value=0.3,
            step=0.1,
            help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€"
        )

    # ëª¨ë¸ ì„ íƒ
    st.subheader("LLM ëª¨ë¸")

    available_models = ["llama3:8b-instruct", "llama3:70b-instruct", "mistral:7b-instruct"]
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
        available_models,
        help="ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  LLM ëª¨ë¸"
    )

    if st.button("ğŸ’¾ ì„¤ì • ì €ì¥"):
        st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ëŒ€í™” ì´ˆê¸°í™”
    st.divider()

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”", type="secondary"):
        st.session_state.messages = []
        st.success("ëŒ€í™” ë‚´ì—­ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.experimental_rerun()

# í‘¸í„°
st.divider()
st.caption("GTOne RAG System - Powered by Qdrant + Ollama")